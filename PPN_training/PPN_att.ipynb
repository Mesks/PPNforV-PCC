{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c57c6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 6\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,2,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "plot_model(model,to_file='FeaturesPlots/model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebfe9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1722 - acc: 0.8613 - val_loss: 0.1544 - val_acc: 0.8611\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1533 - acc: 0.8613 - val_loss: 0.1218 - val_acc: 0.8611\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1313 - acc: 0.8613 - val_loss: 0.0971 - val_acc: 0.8611\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1088 - acc: 0.8616 - val_loss: 0.0791 - val_acc: 0.8637\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0899 - acc: 0.9008 - val_loss: 0.0674 - val_acc: 0.9559\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0755 - acc: 0.9549 - val_loss: 0.0598 - val_acc: 0.9524\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0647 - acc: 0.9439 - val_loss: 0.0552 - val_acc: 0.9290\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0567 - acc: 0.9287 - val_loss: 0.0527 - val_acc: 0.9283\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0508 - acc: 0.9275 - val_loss: 0.0511 - val_acc: 0.9266\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0463 - acc: 0.9263 - val_loss: 0.0497 - val_acc: 0.9261\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0426 - acc: 0.9260 - val_loss: 0.0482 - val_acc: 0.9259\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0395 - acc: 0.9260 - val_loss: 0.0463 - val_acc: 0.9259\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0367 - acc: 0.9281 - val_loss: 0.0444 - val_acc: 0.9396\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0342 - acc: 0.9440 - val_loss: 0.0426 - val_acc: 0.9455\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0321 - acc: 0.9483 - val_loss: 0.0411 - val_acc: 0.9496\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0303 - acc: 0.9498 - val_loss: 0.0401 - val_acc: 0.9498\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0289 - acc: 0.9497 - val_loss: 0.0395 - val_acc: 0.9493\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0277 - acc: 0.9494 - val_loss: 0.0391 - val_acc: 0.9494\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0268 - acc: 0.9494 - val_loss: 0.0389 - val_acc: 0.9494\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0261 - acc: 0.9495 - val_loss: 0.0387 - val_acc: 0.9495\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0255 - acc: 0.9495 - val_loss: 0.0387 - val_acc: 0.9495\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0251 - acc: 0.9496 - val_loss: 0.0386 - val_acc: 0.9496\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0247 - acc: 0.9498 - val_loss: 0.0386 - val_acc: 0.9500\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0244 - acc: 0.9503 - val_loss: 0.0386 - val_acc: 0.9504\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0242 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9506\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0240 - acc: 0.9507 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0238 - acc: 0.9509 - val_loss: 0.0387 - val_acc: 0.9510\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0237 - acc: 0.9510 - val_loss: 0.0387 - val_acc: 0.9510\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0235 - acc: 0.9510 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0390 - val_acc: 0.9511\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9510\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9511\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9511\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0230 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9511\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0230 - acc: 0.9510 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0229 - acc: 0.9510 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0229 - acc: 0.9511 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0229 - acc: 0.9511 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0229 - acc: 0.9511 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0393 - val_acc: 0.9512\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0228 - acc: 0.9512 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0228 - acc: 0.9512 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0228 - acc: 0.9512 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0228 - acc: 0.9512 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0227 - acc: 0.9513 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9513 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9513 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9513 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0227 - acc: 0.9514 - val_loss: 0.0392 - val_acc: 0.9514\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9514 - val_loss: 0.0392 - val_acc: 0.9514\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9514 - val_loss: 0.0392 - val_acc: 0.9515\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9515 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9515 - val_loss: 0.0391 - val_acc: 0.9516\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9515 - val_loss: 0.0391 - val_acc: 0.9515\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9515 - val_loss: 0.0390 - val_acc: 0.9515\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9515 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9515 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9516 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9516 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9516 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9516 - val_loss: 0.0390 - val_acc: 0.9516\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0223 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0223 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9516\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0223 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9516\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0223 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9516\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0223 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9516\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0222 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9516\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0222 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9516\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0222 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9516\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0222 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0222 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0222 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0221 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0221 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0221 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0221 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0221 - acc: 0.9510 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0221 - acc: 0.9510 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0220 - acc: 0.9507 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0220 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0220 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0220 - acc: 0.9507 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0220 - acc: 0.9507 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0220 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0219 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0218 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0218 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0218 - acc: 0.9509 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0218 - acc: 0.9508 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0218 - acc: 0.9509 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0218 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0218 - acc: 0.9509 - val_loss: 0.0387 - val_acc: 0.9509\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9509\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0217 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0216 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0216 - acc: 0.9509 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0386 - val_acc: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0386 - val_acc: 0.9510\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0216 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9511 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9511\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9510\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9510\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0385 - val_acc: 0.9510\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0215 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9511 - val_loss: 0.0384 - val_acc: 0.9511\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9510 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0214 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0214 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0213 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9511\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0213 - acc: 0.9511 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9512 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0213 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0380 - val_acc: 0.9515\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9513 - val_loss: 0.0380 - val_acc: 0.9515\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9514 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9517 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9516 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9517 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9517 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9517 - val_loss: 0.0380 - val_acc: 0.9518\n",
      "Epoch 177/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9519 - val_loss: 0.0380 - val_acc: 0.9522\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9521 - val_loss: 0.0380 - val_acc: 0.9522\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9520 - val_loss: 0.0379 - val_acc: 0.9522\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9521 - val_loss: 0.0379 - val_acc: 0.9522\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0212 - acc: 0.9520 - val_loss: 0.0379 - val_acc: 0.9522\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0212 - acc: 0.9522 - val_loss: 0.0379 - val_acc: 0.9524\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0379 - val_acc: 0.9524\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0379 - val_acc: 0.9524\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9522 - val_loss: 0.0379 - val_acc: 0.9525\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0379 - val_acc: 0.9524\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0379 - val_acc: 0.9525\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0379 - val_acc: 0.9525\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0379 - val_acc: 0.9525\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9523 - val_loss: 0.0378 - val_acc: 0.9525\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9525\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9525\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9524 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0378 - val_acc: 0.9526\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9526\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9526\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0211 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9526\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0210 - acc: 0.9525 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0210 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0375 - val_acc: 0.9527\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0209 - acc: 0.9526 - val_loss: 0.0374 - val_acc: 0.9527\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9526\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0373 - val_acc: 0.9527\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 293/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9526\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0208 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0207 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0207 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0207 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0207 - acc: 0.9526 - val_loss: 0.0372 - val_acc: 0.9527\n",
      "15396/15396 [==============================] - 12s 756us/step - loss: 0.0372 - acc: 0.9527\n",
      "\n",
      "Test Accuracy: 0.9527\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_allFeatures_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd52512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_allFeatures_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670776d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-2.1095662,-2.159209,-2.51972,0.29016927,-2.0382051,-0.77479863,-2.2325509,-1.8578652,-1.0599688,-2.2450185,-9.816983,-9.85152,-3.6130433,1.3817818,-2.7175672,-1.1617019,-0.5252332,-3.5527856,-0.5005699,-3.769177,-1.8587321,-1.8539385,-0.43848947,-1.698926,-1.0197548,-2.6354125,-0.12451699,-1.5142912,-1.6910163,-0.9330596,-0.45474607,-0.5086948,-1.3383667,0.9709808,-0.95867985,-0.1089984,-0.18093315,-0.71510166,-0.021761239,-1.0369492,0.7523155,0.7339047,-0.3511233,-2.2335403,-0.7770228,-1.3005433,-2.9519691,-0.37962297,-1.9855602,-0.33923012,0.42476094,0.4215061,0.0936193,-2.5338855,-0.48233932,-0.99384475,0.11303166,-0.42611918,-0.6140396,-0.12954515,\n",
      "\n",
      "a_bias1: \n",
      "1.0353637,1.1218994,0.8137333,1.4358728,0.980739,0.8959781,1.1579281,0.95284426,1.1658161,0.90403193,\n",
      "\n",
      "a_weight2: \n",
      "-3.0585058,-3.165357,-2.3281388,-2.2885113,-1.9403934,-1.7498333,-2.2122128,-2.0468612,-2.0176458,-2.2064018,\n",
      "\n",
      "a_bias2: \n",
      "4.1650133,"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")\n",
    "\n",
    "# print(\"\\n\\na_weight3: \")\n",
    "# for a in a_weight3:\n",
    "#     for b in a:\n",
    "#         print(b,end=\",\")\n",
    "        \n",
    "# print(\"\\n\\na_bias3: \")\n",
    "# for a in a_bias3:\n",
    "#         print(a,end=\",\")\n",
    "        \n",
    "# g_weight1=model.get_layer(index=0).get_weights()\n",
    "# g_weight2=model.get_layer(index=1).get_weights()\n",
    "        \n",
    "# print(g_weight1)\n",
    "# print(g_weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17b196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# x=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "# av = np.average(x)\n",
    "# print(av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2cb32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.1788 - acc: 0.7083 - val_loss: 0.1671 - val_acc: 0.8611\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1545 - acc: 0.8613 - val_loss: 0.1277 - val_acc: 0.8611\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1330 - acc: 0.8613 - val_loss: 0.1018 - val_acc: 0.8611\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1106 - acc: 0.8613 - val_loss: 0.0822 - val_acc: 0.8611\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0911 - acc: 0.9182 - val_loss: 0.0691 - val_acc: 0.9552\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0761 - acc: 0.9525 - val_loss: 0.0608 - val_acc: 0.9497\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0650 - acc: 0.9314 - val_loss: 0.0560 - val_acc: 0.9295\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0570 - acc: 0.9291 - val_loss: 0.0535 - val_acc: 0.9292\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0511 - acc: 0.9249 - val_loss: 0.0522 - val_acc: 0.9238\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0469 - acc: 0.9221 - val_loss: 0.0514 - val_acc: 0.9222\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0437 - acc: 0.9220 - val_loss: 0.0506 - val_acc: 0.9222\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0411 - acc: 0.9220 - val_loss: 0.0497 - val_acc: 0.9222\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9211 - val_loss: 0.0486 - val_acc: 0.9188\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0372 - acc: 0.9187 - val_loss: 0.0472 - val_acc: 0.9190\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0356 - acc: 0.9191 - val_loss: 0.0457 - val_acc: 0.9242\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0341 - acc: 0.9240 - val_loss: 0.0441 - val_acc: 0.9244\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0329 - acc: 0.9384 - val_loss: 0.0426 - val_acc: 0.9462\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0317 - acc: 0.9457 - val_loss: 0.0414 - val_acc: 0.9462\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0308 - acc: 0.9467 - val_loss: 0.0406 - val_acc: 0.9502\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0300 - acc: 0.9506 - val_loss: 0.0400 - val_acc: 0.9509\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0294 - acc: 0.9506 - val_loss: 0.0397 - val_acc: 0.9508\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0289 - acc: 0.9505 - val_loss: 0.0394 - val_acc: 0.9508\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0285 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9508\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0281 - acc: 0.9505 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0279 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0276 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0274 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0272 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0271 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0269 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0268 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0267 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0266 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0265 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9505 - val_loss: 0.0387 - val_acc: 0.9508\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0261 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9505 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9505 - val_loss: 0.0389 - val_acc: 0.9508\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9505 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9505 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9499 - val_loss: 0.0390 - val_acc: 0.9501\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9499 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9499 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9499 - val_loss: 0.0390 - val_acc: 0.9501\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9499 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9499 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9500 - val_loss: 0.0392 - val_acc: 0.9501\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9500 - val_loss: 0.0391 - val_acc: 0.9501\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9503 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0392 - val_acc: 0.9507\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9505 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9504 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9504 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9503 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9499 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9499 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9499 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9498 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9497 - val_loss: 0.0393 - val_acc: 0.9500\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9497 - val_loss: 0.0394 - val_acc: 0.9500\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9497 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9494 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9495 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 21s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0394 - val_acc: 0.9493\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 177/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0393 - val_acc: 0.9493\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0392 - val_acc: 0.9493\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9493 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9492 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9504 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9497 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9502 - val_loss: 0.0391 - val_acc: 0.9528\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9500 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9511 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9516 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9513 - val_loss: 0.0391 - val_acc: 0.9528\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9518 - val_loss: 0.0391 - val_acc: 0.9493\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9503 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9523 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9522 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9526 - val_loss: 0.0391 - val_acc: 0.9528\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0390 - val_acc: 0.9528\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 293/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0388 - val_acc: 0.9528\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0389 - val_acc: 0.9528\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9526 - val_loss: 0.0388 - val_acc: 0.9528\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9527 - val_loss: 0.0388 - val_acc: 0.9529\n",
      "15396/15396 [==============================] - 12s 748us/step - loss: 0.0388 - acc: 0.9529\n",
      "\n",
      "Test Accuracy: 0.9529\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-3.9931302,-2.6650257,-1.7715513,-3.1090755,-1.4152541,-2.273971,-3.4510772,-2.123933,-0.25978026,-0.9992292,-1.8437262,-1.6335757,-0.827061,-1.5249261,-0.52787906,-1.3884159,-2.0487819,-0.9749957,0.3655498,-0.4117879,0.0054404424,-0.019226471,-0.13586833,-0.13274279,-0.047048867,-0.008667083,0.0944489,-0.12878409,0.1242766,0.20453158,-1.3096448,-1.5472984,-1.6260796,-1.5922724,-1.7056574,-1.5413712,-1.3546981,-1.6771679,-1.5794203,-1.5544312,1.1233628,0.3248339,-0.25776616,0.63608366,-0.67766124,0.19373254,0.8928638,-0.041108835,-1.8305179,-1.0680988,\n",
      "\n",
      "a_bias1: \n",
      "0.33224753,0.8189223,0.78683674,0.79837453,1.2444384,0.5835176,0.39983886,0.895633,0.8715698,1.1463834,\n",
      "\n",
      "a_weight2: \n",
      "-2.172799,-1.9367733,-1.5400078,-2.139479,-1.8747907,-1.5941752,-2.123101,-1.7456464,-1.4710727,-1.8249818,\n",
      "\n",
      "a_bias2: \n",
      "3.8646355,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[1,2,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noMPD_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noMPD_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff15bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.1760 - acc: 0.8301 - val_loss: 0.1644 - val_acc: 0.8613\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1593 - acc: 0.8613 - val_loss: 0.1366 - val_acc: 0.8613\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1395 - acc: 0.8613 - val_loss: 0.1144 - val_acc: 0.8613\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1155 - acc: 0.8694 - val_loss: 0.0953 - val_acc: 0.8877\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0927 - acc: 0.9121 - val_loss: 0.0810 - val_acc: 0.9257\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0745 - acc: 0.9204 - val_loss: 0.0714 - val_acc: 0.9159\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0615 - acc: 0.9101 - val_loss: 0.0658 - val_acc: 0.9076\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0529 - acc: 0.9056 - val_loss: 0.0637 - val_acc: 0.9048\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0479 - acc: 0.9033 - val_loss: 0.0638 - val_acc: 0.9026\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0454 - acc: 0.9015 - val_loss: 0.0643 - val_acc: 0.9008\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0442 - acc: 0.9006 - val_loss: 0.0649 - val_acc: 0.9009\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0436 - acc: 0.9007 - val_loss: 0.0651 - val_acc: 0.9011\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0432 - acc: 0.9010 - val_loss: 0.0652 - val_acc: 0.9014\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0429 - acc: 0.9015 - val_loss: 0.0651 - val_acc: 0.9022\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0427 - acc: 0.9021 - val_loss: 0.0650 - val_acc: 0.9026\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9025 - val_loss: 0.0648 - val_acc: 0.9031\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9029 - val_loss: 0.0647 - val_acc: 0.9034\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0422 - acc: 0.9033 - val_loss: 0.0645 - val_acc: 0.9038\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0421 - acc: 0.9036 - val_loss: 0.0643 - val_acc: 0.9042\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0419 - acc: 0.9040 - val_loss: 0.0642 - val_acc: 0.9046\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0418 - acc: 0.9043 - val_loss: 0.0640 - val_acc: 0.9048\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0417 - acc: 0.9048 - val_loss: 0.0639 - val_acc: 0.9063\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0416 - acc: 0.9060 - val_loss: 0.0638 - val_acc: 0.9083\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0415 - acc: 0.9085 - val_loss: 0.0637 - val_acc: 0.9091\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0414 - acc: 0.9092 - val_loss: 0.0636 - val_acc: 0.9097\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0413 - acc: 0.9097 - val_loss: 0.0636 - val_acc: 0.9103\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0412 - acc: 0.9102 - val_loss: 0.0636 - val_acc: 0.9105\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0412 - acc: 0.9106 - val_loss: 0.0635 - val_acc: 0.9111\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0411 - acc: 0.9109 - val_loss: 0.0635 - val_acc: 0.9114\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0411 - acc: 0.9112 - val_loss: 0.0635 - val_acc: 0.9115\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0410 - acc: 0.9113 - val_loss: 0.0635 - val_acc: 0.9116\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0410 - acc: 0.9115 - val_loss: 0.0635 - val_acc: 0.9118\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0409 - acc: 0.9116 - val_loss: 0.0635 - val_acc: 0.9119\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0409 - acc: 0.9117 - val_loss: 0.0634 - val_acc: 0.9121\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0409 - acc: 0.9118 - val_loss: 0.0634 - val_acc: 0.9121\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0408 - acc: 0.9119 - val_loss: 0.0634 - val_acc: 0.9122\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0408 - acc: 0.9120 - val_loss: 0.0635 - val_acc: 0.9123\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0408 - acc: 0.9121 - val_loss: 0.0635 - val_acc: 0.9124\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0408 - acc: 0.9121 - val_loss: 0.0635 - val_acc: 0.9124\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9122 - val_loss: 0.0634 - val_acc: 0.9125\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9123 - val_loss: 0.0635 - val_acc: 0.9125\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9123 - val_loss: 0.0635 - val_acc: 0.9125\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9124 - val_loss: 0.0635 - val_acc: 0.9126\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9124 - val_loss: 0.0635 - val_acc: 0.9126\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9124 - val_loss: 0.0634 - val_acc: 0.9127\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9125 - val_loss: 0.0634 - val_acc: 0.9129\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9127 - val_loss: 0.0635 - val_acc: 0.9130\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9128 - val_loss: 0.0635 - val_acc: 0.9132\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9128 - val_loss: 0.0635 - val_acc: 0.9132\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9128 - val_loss: 0.0634 - val_acc: 0.9132\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9129 - val_loss: 0.0635 - val_acc: 0.9132\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0406 - acc: 0.9129 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0406 - acc: 0.9129 - val_loss: 0.0635 - val_acc: 0.9132\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9129 - val_loss: 0.0635 - val_acc: 0.9133\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9129 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9129 - val_loss: 0.0635 - val_acc: 0.9132\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9129 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0636 - val_acc: 0.9132\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0635 - val_acc: 0.9134\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0635 - val_acc: 0.9134\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9131 - val_loss: 0.0636 - val_acc: 0.9134\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9130 - val_loss: 0.0635 - val_acc: 0.9135\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9131 - val_loss: 0.0635 - val_acc: 0.9135\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9131 - val_loss: 0.0636 - val_acc: 0.9134\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9131 - val_loss: 0.0636 - val_acc: 0.9134\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0404 - acc: 0.9131 - val_loss: 0.0636 - val_acc: 0.9134\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0636 - val_acc: 0.9135\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0635 - val_acc: 0.9135\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0636 - val_acc: 0.9135\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0635 - val_acc: 0.9135\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0636 - val_acc: 0.9135\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0636 - val_acc: 0.9135\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9133 - val_loss: 0.0637 - val_acc: 0.9135\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9132 - val_loss: 0.0635 - val_acc: 0.9136\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9133 - val_loss: 0.0636 - val_acc: 0.9136\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9133 - val_loss: 0.0636 - val_acc: 0.9136\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0404 - acc: 0.9134 - val_loss: 0.0636 - val_acc: 0.9136\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9133 - val_loss: 0.0635 - val_acc: 0.9137\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9134 - val_loss: 0.0635 - val_acc: 0.9137\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9134 - val_loss: 0.0636 - val_acc: 0.9137\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9134 - val_loss: 0.0636 - val_acc: 0.9137\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9134 - val_loss: 0.0635 - val_acc: 0.9138\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9135 - val_loss: 0.0635 - val_acc: 0.9138\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0403 - acc: 0.9135 - val_loss: 0.0635 - val_acc: 0.9138\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9135 - val_loss: 0.0635 - val_acc: 0.9138\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9135 - val_loss: 0.0635 - val_acc: 0.9138\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9135 - val_loss: 0.0634 - val_acc: 0.9139\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0403 - acc: 0.9136 - val_loss: 0.0634 - val_acc: 0.9140\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9136 - val_loss: 0.0634 - val_acc: 0.9140\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0403 - acc: 0.9136 - val_loss: 0.0633 - val_acc: 0.9140\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0633 - val_acc: 0.9140\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0635 - val_acc: 0.9139\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0634 - val_acc: 0.9141\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0634 - val_acc: 0.9140\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0634 - val_acc: 0.9141\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9137 - val_loss: 0.0634 - val_acc: 0.9141\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9138 - val_loss: 0.0633 - val_acc: 0.9142\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9139 - val_loss: 0.0633 - val_acc: 0.9142\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9138 - val_loss: 0.0632 - val_acc: 0.9143\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0401 - acc: 0.9139 - val_loss: 0.0632 - val_acc: 0.9143\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9139 - val_loss: 0.0631 - val_acc: 0.9143\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9140 - val_loss: 0.0632 - val_acc: 0.9143\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9140 - val_loss: 0.0632 - val_acc: 0.9143\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9140 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0401 - acc: 0.9141 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9141 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9142 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0400 - acc: 0.9142 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9142 - val_loss: 0.0630 - val_acc: 0.9145\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9143 - val_loss: 0.0631 - val_acc: 0.9145\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9143 - val_loss: 0.0630 - val_acc: 0.9147\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9144 - val_loss: 0.0629 - val_acc: 0.9147\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9144 - val_loss: 0.0629 - val_acc: 0.9147\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9144 - val_loss: 0.0628 - val_acc: 0.9148\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0399 - acc: 0.9145 - val_loss: 0.0629 - val_acc: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9146 - val_loss: 0.0629 - val_acc: 0.9149\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9145 - val_loss: 0.0627 - val_acc: 0.9150\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9146 - val_loss: 0.0628 - val_acc: 0.9149\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9146 - val_loss: 0.0626 - val_acc: 0.9151\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9147 - val_loss: 0.0627 - val_acc: 0.9151\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9148 - val_loss: 0.0627 - val_acc: 0.9151\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9148 - val_loss: 0.0627 - val_acc: 0.9152\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9148 - val_loss: 0.0626 - val_acc: 0.9152\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9149 - val_loss: 0.0626 - val_acc: 0.9152\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9149 - val_loss: 0.0625 - val_acc: 0.9153\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9150 - val_loss: 0.0626 - val_acc: 0.9153\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9150 - val_loss: 0.0625 - val_acc: 0.9154\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9151 - val_loss: 0.0625 - val_acc: 0.9154\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9152 - val_loss: 0.0625 - val_acc: 0.9155\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9152 - val_loss: 0.0624 - val_acc: 0.9155\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9152 - val_loss: 0.0623 - val_acc: 0.9155\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9153 - val_loss: 0.0624 - val_acc: 0.9155\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0395 - acc: 0.9153 - val_loss: 0.0623 - val_acc: 0.9157\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9154 - val_loss: 0.0622 - val_acc: 0.9157\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9154 - val_loss: 0.0622 - val_acc: 0.9159\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9155 - val_loss: 0.0622 - val_acc: 0.9158\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9155 - val_loss: 0.0622 - val_acc: 0.9159\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9156 - val_loss: 0.0622 - val_acc: 0.9159\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9156 - val_loss: 0.0622 - val_acc: 0.9159\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9157 - val_loss: 0.0622 - val_acc: 0.9159\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9157 - val_loss: 0.0621 - val_acc: 0.9161\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9158 - val_loss: 0.0621 - val_acc: 0.9162\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9158 - val_loss: 0.0620 - val_acc: 0.9162\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9159 - val_loss: 0.0621 - val_acc: 0.9162\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9160 - val_loss: 0.0620 - val_acc: 0.9163\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9160 - val_loss: 0.0620 - val_acc: 0.9163\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9160 - val_loss: 0.0621 - val_acc: 0.9163\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9161 - val_loss: 0.0620 - val_acc: 0.9165\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9161 - val_loss: 0.0619 - val_acc: 0.9165\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9162 - val_loss: 0.0620 - val_acc: 0.9165\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9161 - val_loss: 0.0619 - val_acc: 0.9165\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9161 - val_loss: 0.0619 - val_acc: 0.9165\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9162 - val_loss: 0.0619 - val_acc: 0.9165\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9162 - val_loss: 0.0619 - val_acc: 0.9166\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9163 - val_loss: 0.0619 - val_acc: 0.9166\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9163 - val_loss: 0.0619 - val_acc: 0.9166\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9163 - val_loss: 0.0618 - val_acc: 0.9167\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9164 - val_loss: 0.0618 - val_acc: 0.9168\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9164 - val_loss: 0.0617 - val_acc: 0.9168\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9165 - val_loss: 0.0618 - val_acc: 0.9168\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9165 - val_loss: 0.0617 - val_acc: 0.9169\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9166 - val_loss: 0.0618 - val_acc: 0.9169\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9166 - val_loss: 0.0617 - val_acc: 0.9169\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9166 - val_loss: 0.0617 - val_acc: 0.9170\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9167 - val_loss: 0.0618 - val_acc: 0.9170\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9167 - val_loss: 0.0617 - val_acc: 0.9170\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9167 - val_loss: 0.0617 - val_acc: 0.9171\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9168 - val_loss: 0.0617 - val_acc: 0.9172\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9168 - val_loss: 0.0617 - val_acc: 0.9171\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9168 - val_loss: 0.0616 - val_acc: 0.9172\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9169 - val_loss: 0.0615 - val_acc: 0.9173\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9170 - val_loss: 0.0616 - val_acc: 0.9173\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9170 - val_loss: 0.0617 - val_acc: 0.9173\n",
      "Epoch 177/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9170 - val_loss: 0.0616 - val_acc: 0.9173\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9171 - val_loss: 0.0617 - val_acc: 0.9173\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9170 - val_loss: 0.0616 - val_acc: 0.9174\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9171 - val_loss: 0.0616 - val_acc: 0.9174\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9172 - val_loss: 0.0616 - val_acc: 0.9174\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9172 - val_loss: 0.0616 - val_acc: 0.9174\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 15s 995us/step - loss: 0.0389 - acc: 0.9172 - val_loss: 0.0616 - val_acc: 0.9175\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9173 - val_loss: 0.0616 - val_acc: 0.9175\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9173 - val_loss: 0.0616 - val_acc: 0.9175\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9173 - val_loss: 0.0616 - val_acc: 0.9175\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9173 - val_loss: 0.0616 - val_acc: 0.9175\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9174 - val_loss: 0.0615 - val_acc: 0.9176\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9174 - val_loss: 0.0615 - val_acc: 0.9176\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9174 - val_loss: 0.0615 - val_acc: 0.9176\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9174 - val_loss: 0.0615 - val_acc: 0.9177\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9175 - val_loss: 0.0615 - val_acc: 0.9177\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9175 - val_loss: 0.0615 - val_acc: 0.9177\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9175 - val_loss: 0.0615 - val_acc: 0.9178\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9175 - val_loss: 0.0614 - val_acc: 0.9178\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0389 - acc: 0.9176 - val_loss: 0.0615 - val_acc: 0.9179\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9176 - val_loss: 0.0614 - val_acc: 0.9179\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9176 - val_loss: 0.0615 - val_acc: 0.9179\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9176 - val_loss: 0.0615 - val_acc: 0.9179\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9176 - val_loss: 0.0614 - val_acc: 0.9179\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9176 - val_loss: 0.0614 - val_acc: 0.9179\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0614 - val_acc: 0.9180\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0615 - val_acc: 0.9180\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0614 - val_acc: 0.9180\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0614 - val_acc: 0.9180\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0614 - val_acc: 0.9180\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0615 - val_acc: 0.9180\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0388 - acc: 0.9177 - val_loss: 0.0614 - val_acc: 0.9181\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0614 - val_acc: 0.9181\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0614 - val_acc: 0.9181\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0614 - val_acc: 0.9181\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0614 - val_acc: 0.9181\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9178 - val_loss: 0.0613 - val_acc: 0.9182\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9179 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9179 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9179 - val_loss: 0.0613 - val_acc: 0.9182\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0613 - val_acc: 0.9182\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9179 - val_loss: 0.0613 - val_acc: 0.9182\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0613 - val_acc: 0.9183\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9182\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9184\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9185\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9180 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0388 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9185\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9180 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9182\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9183\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9180 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9180 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9183\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9184\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9185\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9181 - val_loss: 0.0613 - val_acc: 0.9185\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0614 - val_acc: 0.9184\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9185\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9182 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0614 - val_acc: 0.9186\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9186\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0614 - val_acc: 0.9186\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0614 - val_acc: 0.9186\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0613 - val_acc: 0.9187\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9183 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0614 - val_acc: 0.9188\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0612 - val_acc: 0.9188\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9184 - val_loss: 0.0612 - val_acc: 0.9190\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0612 - val_acc: 0.9190\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0614 - val_acc: 0.9188\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0613 - val_acc: 0.9188\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0613 - val_acc: 0.9190\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0614 - val_acc: 0.9188\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9185 - val_loss: 0.0614 - val_acc: 0.9189\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0614 - val_acc: 0.9189\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9189\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9189\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9189\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9189\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0612 - val_acc: 0.9190\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0612 - val_acc: 0.9190\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9190\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9190\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0614 - val_acc: 0.9189\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0613 - val_acc: 0.9190\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0612 - val_acc: 0.9191\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9190\n",
      "Epoch 293/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9186 - val_loss: 0.0612 - val_acc: 0.9191\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9191\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9191\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0614 - val_acc: 0.9191\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0614 - val_acc: 0.9191\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9191\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9191\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0387 - acc: 0.9187 - val_loss: 0.0613 - val_acc: 0.9191\n",
      "15396/15396 [==============================] - 12s 783us/step - loss: 0.0613 - acc: 0.9191\n",
      "\n",
      "Test Accuracy: 0.9191\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAJoCAYAAACa8MCMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWbElEQVR4nO3de1xUdf7H8fdhYAYQARVFvAHm/Z6XTKy0i7hallqr2a5pd9duZrc1d73VL1tLSy1t20prM7VSq12tpFKzvKSmW6uumOItMUVTFBFk+P7+QEZGQECBwcPr+Xicx8x8z/ec85nvjM6bc5mxjDFGAAAANuHn6wIAAABKE+EGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGKMTs2bNlWZbWr1/v61JKrHv37urevbuvy7CNo0ePKiIiQvPmzStw/siRI2VZlm666aYC569atUrjxo3T0aNH882bMWOGZs+eXYrVeouJiSm0rgv1/vvv65VXXrmodVxzzTUaMWJEqdQDnItwA9jQjBkzNGPGDF+XYRvjx49XnTp1NHDgwHzzTp8+rffee0+S9Pnnn+uXX37J12fVqlUaP368T8JNWSiNcPPss89qxowZ2rZtW+kUBeRBuAEqOGOM0tPTS7RMixYt1KJFizKqyLdOnz6trKysctvekSNH9Pe//10PPvigLMvKN/+TTz7RoUOHdOONN8rtduudd94ps1rK+7mXpW7duqlp06aaPHmyr0uBDRFugIu0fft23XHHHapVq5ZcLpeaN2+u1157zavPqVOn9Pjjj6tdu3YKCwtT9erV1aVLF33yySf51mdZlh566CG9/vrrat68uVwul9555x3PYbJly5bpT3/6kyIiIlSjRg31799f+/fv91rHuYeldu3aJcuy9NJLL2nKlCmKjY1VSEiIunTpojVr1uSr4R//+IeaNGkil8ulFi1a6P3339fQoUMVExNTrDF5//331aVLF4WEhCgkJETt2rXTW2+95ZkfExOjoUOH5lvu3LqXL18uy7L0z3/+U48//rjq1q0rl8ulzZs3y7Isr3Xm+uyzz2RZlj799FNPW3Feo8LMnj1bWVlZBe61kaS33npLTqdTs2bNUv369TVr1izl/T3icePG6cknn5QkxcbGyrIsWZal5cuXKyYmRps3b9aKFSs87bljXNhz//nnnzVu3LgCg1bue2TXrl355i1atEht2rRRYGCgGjZsqGnTphVr2dw6li9fLinnNVq8eLF2797tqTlvLZmZmXruuefUrFkzuVwu1axZU3fddZcOHTqUr6bBgwfr/fff1/HjxwscW+BC+fu6AOBStmXLFsXFxalBgwaaPHmyateurS+++EKPPPKIUlJSNHbsWElSRkaGjhw5oieeeEJ169ZVZmamvvzyS/Xv31+zZs3SnXfe6bXejz/+WCtXrtSYMWNUu3Zt1apVS+vWrZMk3Xvvvbrxxhv1/vvva+/evXryySf1xz/+UV9//XWR9b722mtq1qyZ55DCX//6V/Xu3VtJSUkKCwuTJL3xxht64IEHdOutt+rll1/WsWPHNH78eGVkZBRrTMaMGaNnn31W/fv31+OPP66wsDD997//1e7du4s7rPmMGjVKXbp00euvvy4/Pz/Vr19fl19+uWbNmqV77rnHq+/s2bNVq1Yt9e7dW1LxX6PCLF68WJdffrnCw8Pzzdu3b5+WLl2qW2+9VTVr1tSQIUP03HPP6ZtvvlG3bt0k5bxeR44c0fTp07Vw4UJFRUVJytm7tmjRIt12220KCwvzHEZ0uVznfe61atUq8fht2rRJI0aM0Lhx41S7dm3NmTNHjz76qDIzM/XEE0+UaF0zZszQ/fffrx07dmjRokVe87Kzs3XLLbdo5cqVeuqppxQXF6fdu3dr7Nix6t69u9avX6+goCBP/+7du+vpp5/W8uXL1adPnxI/L6BQBkCBZs2aZSSZdevWFdqnZ8+epl69eubYsWNe7Q899JAJDAw0R44cKXC5rKwsc/r0aXPPPfeYyy+/3GueJBMWFpZv2dx6hg8f7tU+adIkI8kkJyd72rp162a6devmeZyUlGQkmdatW5usrCxP+/fff28kmblz5xpjjHG73aZ27dqmc+fOXtvYvXu3CQgIMNHR0YWOhTHG7Ny50zgcDvOHP/zhvP2io6PNkCFD8rWfW/eyZcuMJHPNNdfk6ztt2jQjyWzbts3TduTIEeNyuczjjz/uabvQ1yhXcHCwGTZsWIHzJkyYYCSZzz//3BiT8/wtyzKDBw/26vfiiy8aSSYpKSnfOlq2bOn1nHOd77mPHTvWFPTfd+57JO92oqOjjWVZZtOmTV59e/ToYUJDQ01aWlqhy+atY9myZZ62G2+8scD3wty5c40ks2DBAq/2devWGUlmxowZXu2ZmZnGsizz9NNP51sXcDE4LAVcoFOnTumrr75Sv379FBwcrKysLM/Uu3dvnTp1yuuQz4cffqiuXbsqJCRE/v7+CggI0FtvvaWtW7fmW/d1112natWqFbjdm2++2etxmzZtJKlYe0ZuvPFGORyOQpfdtm2bDhw4oAEDBngt16BBA3Xt2rXI9SckJMjtduvBBx8ssm9J3Hrrrfna/vCHP8jlcnmdjDt37lxlZGTorrvuklTy1+hcR48e1cmTJwvcW2KM8RyK6tGjh6Scw07du3fXggULlJqaepHPOkdBz72kWrZsqbZt23q13XHHHUpNTdUPP/xw0evP9e9//1vh4eHq06eP11i3a9dOtWvX9hzayhUQEKDw8PACT8IGLgbhBrhAhw8fVlZWlqZPn66AgACvKfeQSEpKiiRp4cKFGjBggOrWrav33ntPq1ev1rp163T33Xfr1KlT+dade+iiIDVq1PB6nHsYozgnHRe17OHDhyVJkZGR+ZYtqO1cuedV1KtXr8i+JVHQeFSvXl0333yz3n33Xbndbkk5h6SuuOIKtWzZUlLJXqOC5I5LYGBgvnlff/21kpKS9Pvf/16pqak6evSojh49qgEDBujkyZOaO3fuRT9v6fzvheKqXbt2oW25r3lp+PXXX3X06FE5nc58433gwIECxzowMLDEJ8wDReGcG+ACVatWTQ6HQ4MHDy50T0VsbKwk6b333lNsbKzmz5/vdfJlYeexFHSyaHnIDT+//vprvnkHDhwocvmaNWtKyjkXpX79+oX2CwwMLPC5p6SkKCIiIl97YeNx11136cMPP1RCQoIaNGigdevWaebMmZ75JXmNCpI7HkeOHMk3L/dk5ilTpmjKlCkFzn/ggQcKXXdxFfTcc8NWRkaG1zk6hQW1gl673Lbc55h3nXmdL/ydK/ck988//7zA+VWrVs3X9ttvvxX4mgMXg3ADXKDg4GBde+212rhxo9q0aSOn01loX8uy5HQ6vT6oDhw4UODVUr7UtGlT1a5dWx988IFGjhzpad+zZ49WrVqlOnXqnHf5+Ph4ORwOzZw5U126dCm0X0xMjH788UevtsTERG3btq1EH3Tx8fGqW7euZs2apQYNGigwMFCDBg3yzC/Ja1QQp9Ophg0baseOHV7tv/32mxYtWqSuXbvqueeey7fcm2++qTlz5ui///2vWrVqdd69ay6Xq8R7LnKvqPrxxx/VqVMnT/u//vWvAvtv3rxZ//nPf7wOTb3//vuqWrWq2rdvn2+dTZs29fTLe9VZUTXfdNNNmjdvntxutzp37lzk89i/f79OnTpl268tgO8QboAifP311wVeWtu7d29NnTpVV111la6++mr96U9/UkxMjI4fP66ff/5Z//rXvzxXMN10001auHChhg8frttuu0179+7Vs88+q6ioKG3fvr2cn1Hh/Pz8NH78eD3wwAO67bbbdPfdd+vo0aMaP368oqKi5Od3/iPZMTExeuaZZ/Tss88qPT1dgwYNUlhYmLZs2aKUlBSNHz9eUs4lwH/84x81fPhw3Xrrrdq9e7cmTZrk2fNTXA6HQ3feeaemTJmi0NBQ9e/f33PVV67ivkaF6d69uz777DOvtjlz5ujUqVN65JFHCvwm6Bo1amjOnDl666239PLLL6t169aeWoYMGaKAgAA1bdpUVatWVevWrTVv3jzNnz9fDRs2VGBgoKd/YXr37q3q1avrnnvu0YQJE+Tv76/Zs2dr7969BfavU6eObr75Zo0bN05RUVF67733lJCQoL/97W8KDg6WJHXq1ElNmzbVE088oaysLFWrVk2LFi3St99+m299rVu31sKFCzVz5kx16NBBfn5+6tixo26//XbNmTNHvXv31qOPPqorrrhCAQEB2rdvn5YtW6ZbbrlF/fr186wn93yna6+99rzPFygxX5/RDFRUuVePFDblXlWSlJRk7r77blO3bl0TEBBgatasaeLi4sxzzz3ntb4XXnjBxMTEGJfLZZo3b27+8Y9/FHjViyTz4IMPFlrPuVdvFXQ1S2FXS7344ov51ivJjB071qvtjTfeMI0aNTJOp9M0adLEvP322+aWW27Jd2VXYd59913TqVMnExgYaEJCQszll19uZs2a5ZmfnZ1tJk2aZBo2bGgCAwNNx44dzddff13o1VIffvhhodtKTEz0vCYJCQkF9inua1SQr776ykgy33//vaetXbt2platWiYjI6PQ5a688koTERHh6TNq1ChTp04d4+fn5/V67dq1y8THx5uqVasaSZ6rkIp67t9//72Ji4szVapUMXXr1jVjx441b775ZoFXS914443mo48+Mi1btjROp9PExMSYKVOm5FtnYmKiiY+PN6GhoaZmzZrm4YcfNosXL873/jpy5Ii57bbbTHh4uLEsy+s9fPr0afPSSy+Ztm3bel7/Zs2amQceeMBs377da3uDBw82rVu3LnQMgQtlGZPn26YAoABHjx5VkyZN1LdvX73xxhu+LqfctWnTRl27dvU6nwcXJzU1VXXq1NHLL7+s++67z9flwGYINwC8HDhwQP/3f/+na6+9VjVq1NDu3bv18ssv63//+5/Wr1/vuRKpMvn888/Vr18/bd++vdSvBKusxo8fr/nz5+vHH3+Uvz9nSKB08Y4C4MXlcmnXrl0aPny4jhw5ouDgYF155ZV6/fXXK2WwkaTf/e53evHFF5WUlES4KSWhoaGaPXs2wQZlgj03AADAVvgSPwAAYCuEGwAAYCuEGwAAYCuV7kyu7Oxs7d+/X1WrVvXZV9wDAICSMcbo+PHjqlOnTpFfKFrpws3+/fvP+5s3AACg4tq7d2+RVy1WunCT+8Nte/fuVWhoqI+rAQAAxZGamqr69esX+AOs56p04Sb3UFRoaCjhBgCAS0xxTinhhGIAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhJtykJGRoZMnT/q6DAAAKgXCTRk7ffq0mjdvrssvv1ynTp3ydTkAANge4aaM7dmzR0lJSUpMTNSsWR/6uhwAAGzP39cF2N0vv/ziuT98+N8VEDBY997rw4IA+IQxRtnZ2TLGeE3ntmVnZ3smt9vtuZ87z+3O1unT2XK7jbKych7nTsYYz/3cvtnZ5pzH3v2zs43ntrD7ubUVtExJbnPvS/Kalzs+Rc3Pux5jlGdM3HK73crKypTLVUUhIdXzrDNbUvaZ24LHvaDXIO/jjIx0ZWamKzg4TP7+rnz9zvbPPlNj/vaCH5+9X1ifwtuN/Pwc8vMLkJ+fv7KyMmRMtgICgs+MnzvPlJ37LvSMW+74lPw2Zx0F3ebtW7VqNa1f/1Yp/espOcJNGcsbbqTv9NxzP+mee1rLsnxWEiqxcz8Mcqdz27Ky3MrMdOv06ZwpKyvbcz/nsfe8rKyzbbn3c6bscx6fnXK2k7Pd06ezlJWVM+U+drvPPs47z+3OOqf+rDPPIWdyu91nPmSyve7nfDjk3j/bnvNhkXvf7dXmPbkLbT/74Xm2Ped+zrzc//iBysLPL8qn2yfclDHvcCPt3j1V3333pq66ykcFFYMxRllZWcrMzMzzweJWRoZbp05lKTPTrYwM71vv+1meD77c++e25XwQ5rTl/XByu7POfPCYM39tFP1Xbt6/+Ar6yzjvXzqFraewtsKWP996vWvO/9dWwX/N5X7Aen+AFvRBm/cD1PsD1i1jss5MOfdz2nLm5XzIZhf+wqMCs5RzFkHudO7jkrTlbbe8JsuyztPmV2C/wu/n7+89X+fM1zl9888/dz05zQ5Zlp8syyE/P6fc7lS53b+d2X7Bzze3trzPzbLyrtd7vp9foPz8AuV2p8qYzDN9/c7pe/Y273oK6uvnd3b95y53vuXPLucny9KZf/unZUyW/Pycsiw/ud0nzyzjkJ+f48xt7nPPHUOd6ZM75t7txe13vmVCQ4PlS4SbMrZv3/4z9+IkrZL0rqZNG6urrqpf5ts+efKk/ve/bVq/foe2b/9NSUnJ2r37Zx07dkxpaSeUnn5Cp0+fUFbWSbndp5SdnaHs7FMyJkN8CFZmjgImv0Lac+ZZVs79vLe5U+78vFPuf7pnP5Rydq3nzst57PC0ORz+nsd+fnkfO848zpnncOTe9yvg1q/AW3//s/MLmnLn+/uf2352vvdj79uAAIccDkv+/n7y87Pk72+dmW952h0OyzM5nY4zy+Wsw9/fkp+f5HCowFu/M2dO5nzwFG8C7I5wU8Z27MjZc+Pn93u1aePUpk3LtXDhi9qwYZo6dCjdbWVmZurdd9/VvHmfae3aH3XixA6V7u7w3A84f539YMu5b1m5tzn3cz7U/M98iPnn+VDz99ye/XDKWTb3Nqfv2b+mvP9SO/sXVt553n/teLed29/7r6azff38zi7v51f4OnLm+53z2Ltv3vl+fn6e+X5+1pkP1Zxby8r9UHPk+5At7EM1/4dr7oeov/z9/RUQkLMup9Nf/v4Oz+OcD0qHnE6Hp/1s35z5AQF+5/0gzXvLhySAiopwU8b27s0JN+HhdfXii39Rjx7L5Xa/pmuuCdeKFX9Vx44BF7Te7OxsHTp0SAcOHND+/b/ps8++0bx5b+nQoT3n9IyQ1FjBwREKC4tQRERj1agRoerVQxQREaKwsBCFhASrSpVAVaniUkhIzm1oaKCqVHEqONihKlX8FRzsUGCgpYAAyd8/Z+IDDgBQERFuylhyck64qVWrrq6/vovuuusBzZr1d508+aw6dZqv66//P02f3k/Nmzs8yxhjlJycrB9++FFbt+7Tzz8na9eu/UpOTlZKyn4dO7Zf6em/njmn4ly1JT2sq6/urGHDWqtTp1qKjpaczvJ5vgAA+BrhpgwZY3TkSM45N3Xq1JVlWXr77dfVuXN3PfroI8rISNRXX/1eLVrEKiiolvz9Tyoz84ROnz6k7OwTxdiCpZw9MzXkcMSqVq3b1avX7zV4cJC6dy/DJwYAQAVGuClDKSkpysrKlCRFR5+9LO6BB27XoEG99cgjL+n996fr9OkkpacnnbO0n6RmsqwYBQfXUXh4HdWsGaW6desoJiZKjRvXUfPmtdSgQYDq1pWqVi2/5wUAQEVGuClDZy8Dr6m6db2PC4WGhmr27Al69dWntGjR19qyRcrICFb16sGqV6+mGjeuq0aNglWz5tmrIQAAQNEIN2XobLipq9q1C+4TEhKiwYNvLreaAACwO/YJlKHihBsAAFC6CDdliHADAED5I9yUod27d5+5V59wAwBAOSHclKEtW7aduddEkZE+LQUAgEqDcFOGtm9PlCQFBjZRSIiPiwEAoJIg3JSRlJQUHT16RJIUFdXYx9UAAFB5EG7KSGJi4pl79VWnThWf1gIAQGVCuCkj27adPd+Gk4kBACg/hJsycjbcNCXcAABQjgg3ZWTbttzDUk3UrJlPSwEAoFIh3JSRdety9tyEhDTVkCE+LgYAgEqE35YqJSkpKfrd736ntDRp3z7pxImccHPPPU34xW4AAMoR4aaUZGVlacOGDV5tlhWlv/wl2kcVAQBQOXFYqpRUq1ZNixcvVsuWiyUt1q23LtaaNesVEeHwdWkAAFQqljHG+LqI8pSamqqwsDAdO3ZMoaGhpb7++vVzDkutWiV16VLqqwcAoFIqyec3e25KUWamlPtD4LGxvq0FAIDKinBTivbskYyRgoLED2UCAOAjhJtSlJSUcxsTI1mWT0sBAKDSItyUol27cm5jYnxZBQAAlRvhphTl7rnhfBsAAHyHcFOKCDcAAPge4aYU5R6WItwAAOA7hJtSxJ4bAAB8j3BTSk6elH79Nec+JxQDAOA7hJtSsmdPzm1oqFStmm9rAQCgMuOHM0tJs2bSb79JBw7wHTcAAPgS4aYUhYfnTAAAwHc4LAUAAGyFcAMAAGyFcAMAAGyFcAMAAGzF5+FmxowZio2NVWBgoDp06KCVK1eet/+cOXPUtm1bBQcHKyoqSnfddZcOHz5cTtUCAICKzqfhZv78+RoxYoRGjx6tjRs36uqrr1avXr20J/dLY87x7bff6s4779Q999yjzZs368MPP9S6det07733lnPlAACgovJpuJkyZYruuece3XvvvWrevLleeeUV1a9fXzNnziyw/5o1axQTE6NHHnlEsbGxuuqqq/TAAw9o/fr15Vw5AACoqHwWbjIzM7VhwwbFx8d7tcfHx2vVqlUFLhMXF6d9+/ZpyZIlMsbo119/1UcffaQbb7yx0O1kZGQoNTXVawIAAPbls3CTkpIit9utyMhIr/bIyEgdOHCgwGXi4uI0Z84cDRw4UE6nU7Vr11Z4eLimT59e6HYmTpyosLAwz1S/fv1SfR4AAKBi8fkJxdY5v1VgjMnXlmvLli165JFHNGbMGG3YsEGff/65kpKSNGzYsELXP2rUKB07dswz7d27t1TrBwAAFYvPfn4hIiJCDocj316agwcP5tubk2vixInq2rWrnnzySUlSmzZtVKVKFV199dV67rnnFBUVlW8Zl8sll8tV+k8AAABUSD7bc+N0OtWhQwclJCR4tSckJCguLq7AZU6ePCk/P++SHQ6HpJw9PgAAAD49LDVy5Ei9+eabevvtt7V161Y99thj2rNnj+cw06hRo3TnnXd6+vfp00cLFy7UzJkztXPnTn333Xd65JFHdMUVV6hOnTq+ehoAAKAC8emvgg8cOFCHDx/WhAkTlJycrFatWmnJkiWKjo6WJCUnJ3t9583QoUN1/Phxvfrqq3r88ccVHh6u6667Tn/729989RQAAEAFY5lKdjwnNTVVYWFhOnbsmEJDQ31dDgAAKIaSfH77/GopAACA0kS4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtuLzcDNjxgzFxsYqMDBQHTp00MqVK8/bPyMjQ6NHj1Z0dLRcLpcuu+wyvf322+VULQAAqOj8fbnx+fPna8SIEZoxY4a6du2qv//97+rVq5e2bNmiBg0aFLjMgAED9Ouvv+qtt95So0aNdPDgQWVlZZVz5QAAoKKyjDHGVxvv3Lmz2rdvr5kzZ3ramjdvrr59+2rixIn5+n/++ee6/fbbtXPnTlWvXv2CtpmamqqwsDAdO3ZMoaGhF1w7AAAoPyX5/PbZYanMzExt2LBB8fHxXu3x8fFatWpVgct8+umn6tixoyZNmqS6deuqSZMmeuKJJ5Senl7odjIyMpSamuo1AQAA+/LZYamUlBS53W5FRkZ6tUdGRurAgQMFLrNz5059++23CgwM1KJFi5SSkqLhw4fryJEjhZ53M3HiRI0fP77U6wcAABWTz08otizL67ExJl9bruzsbFmWpTlz5uiKK65Q7969NWXKFM2ePbvQvTejRo3SsWPHPNPevXtL/TkAAICKw2d7biIiIuRwOPLtpTl48GC+vTm5oqKiVLduXYWFhXnamjdvLmOM9u3bp8aNG+dbxuVyyeVylW7xAACgwvLZnhun06kOHTooISHBqz0hIUFxcXEFLtO1a1ft379fJ06c8LQlJibKz89P9erVK9N6AQDApcGnh6VGjhypN998U2+//ba2bt2qxx57THv27NGwYcMk5RxSuvPOOz3977jjDtWoUUN33XWXtmzZom+++UZPPvmk7r77bgUFBfnqaQAAgArEp99zM3DgQB0+fFgTJkxQcnKyWrVqpSVLlig6OlqSlJycrD179nj6h4SEKCEhQQ8//LA6duyoGjVqaMCAAXruued89RQAAEAF49PvufEFvucGAIBLzyXxPTcAAABlgXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABs5YLCzTvvvKPFixd7Hj/11FMKDw9XXFycdu/eXWrFAQAAlNQFhZvnn39eQUFBkqTVq1fr1Vdf1aRJkxQREaHHHnusVAsEAAAoCf8LWWjv3r1q1KiRJOnjjz/Wbbfdpvvvv19du3ZV9+7dS7M+AACAErmgPTchISE6fPiwJGnp0qW64YYbJEmBgYFKT08vveoAAABK6IL23PTo0UP33nuvLr/8ciUmJurGG2+UJG3evFkxMTGlWR8AAECJXNCem9dee01dunTRoUOHtGDBAtWoUUOStGHDBg0aNKhUCwQAACgJyxhjfF1EeUpNTVVYWJiOHTum0NBQX5cDAACKoSSf3xe05+bzzz/Xt99+63n82muvqV27drrjjjv022+/XcgqAQAASsUFhZsnn3xSqampkqSffvpJjz/+uHr37q2dO3dq5MiRpVogAABASVzQCcVJSUlq0aKFJGnBggW66aab9Pzzz+uHH35Q7969S7VAAACAkrigPTdOp1MnT56UJH355ZeKj4+XJFWvXt2zRwcAAMAXLmjPzVVXXaWRI0eqa9eu+v777zV//nxJUmJiourVq1eqBQIAAJTEBe25efXVV+Xv76+PPvpIM2fOVN26dSVJn332mX73u9+VaoEAAAAlwaXgAACgwivJ5/cFHZaSJLfbrY8//lhbt26VZVlq3ry5brnlFjkcjgtdJQAAwEW7oHDz888/q3fv3vrll1/UtGlTGWOUmJio+vXra/HixbrssstKu04AAIBiuaBzbh555BFddtll2rt3r3744Qdt3LhRe/bsUWxsrB555JHSrhEAAKDYLmjPzYoVK7RmzRpVr17d01ajRg298MIL6tq1a6kVBwAAUFIXtOfG5XLp+PHj+dpPnDghp9N50UUBAABcqAsKNzfddJPuv/9+rV27VsYYGWO0Zs0aDRs2TDfffHNp1wgAAFBsFxRupk2bpssuu0xdunRRYGCgAgMDFRcXp0aNGumVV14p5RIBAACK74LOuQkPD9cnn3yin3/+WVu3bpUxRi1atFCjRo1Kuz4AAIASKXa4KerXvpcvX+65P2XKlAsuCAAA4GIUO9xs3LixWP0sy7rgYgAAAC5WscPNsmXLyrIOAACAUnFBJxQDAABUVIQbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgK4QbAABgKz4PNzNmzFBsbKwCAwPVoUMHrVy5sljLfffdd/L391e7du3KtkAAAHBJ8Wm4mT9/vkaMGKHRo0dr48aNuvrqq9WrVy/t2bPnvMsdO3ZMd955p66//vpyqhQAAFwqLGOM8dXGO3furPbt22vmzJmetubNm6tv376aOHFiocvdfvvtaty4sRwOhz7++GNt2rSp2NtMTU1VWFiYjh07ptDQ0IspHwAAlJOSfH77bM9NZmamNmzYoPj4eK/2+Ph4rVq1qtDlZs2apR07dmjs2LHF2k5GRoZSU1O9JgAAYF8+CzcpKSlyu92KjIz0ao+MjNSBAwcKXGb79u3685//rDlz5sjf379Y25k4caLCwsI8U/369S+6dgAAUHH5/IRiy7K8Hhtj8rVJktvt1h133KHx48erSZMmxV7/qFGjdOzYMc+0d+/ei64ZAABUXMXb/VEGIiIi5HA48u2lOXjwYL69OZJ0/PhxrV+/Xhs3btRDDz0kScrOzpYxRv7+/lq6dKmuu+66fMu5XC65XK6yeRIAAKDC8dmeG6fTqQ4dOighIcGrPSEhQXFxcfn6h4aG6qefftKmTZs807Bhw9S0aVNt2rRJnTt3Lq/SAQBABeazPTeSNHLkSA0ePFgdO3ZUly5d9MYbb2jPnj0aNmyYpJxDSr/88oveffdd+fn5qVWrVl7L16pVS4GBgfnaAQBA5eXTcDNw4EAdPnxYEyZMUHJyslq1aqUlS5YoOjpakpScnFzkd94AAADk5dPvufEFvucGAIBLzyXxPTcAAABlgXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABsxefhZsaMGYqNjVVgYKA6dOiglStXFtp34cKF6tGjh2rWrKnQ0FB16dJFX3zxRTlWCwAAKjqfhpv58+drxIgRGj16tDZu3Kirr75avXr10p49ewrs/80336hHjx5asmSJNmzYoGuvvVZ9+vTRxo0by7lyAABQUVnGGOOrjXfu3Fnt27fXzJkzPW3NmzdX3759NXHixGKto2XLlho4cKDGjBlTrP6pqakKCwvTsWPHFBoaekF1AwCA8lWSz2+f7bnJzMzUhg0bFB8f79UeHx+vVatWFWsd2dnZOn78uKpXr15on4yMDKWmpnpNAADAvnwWblJSUuR2uxUZGenVHhkZqQMHDhRrHZMnT1ZaWpoGDBhQaJ+JEycqLCzMM9WvX/+i6gYAABWbz08otizL67ExJl9bQebOnatx48Zp/vz5qlWrVqH9Ro0apWPHjnmmvXv3XnTNAACg4vL31YYjIiLkcDjy7aU5ePBgvr0555o/f77uueceffjhh7rhhhvO29flcsnlcl10vQAA4NLgsz03TqdTHTp0UEJCgld7QkKC4uLiCl1u7ty5Gjp0qN5//33deOONZV0mAAC4xPhsz40kjRw5UoMHD1bHjh3VpUsXvfHGG9qzZ4+GDRsmKeeQ0i+//KJ3331XUk6wufPOOzV16lRdeeWVnr0+QUFBCgsL89nzAAAAFYdPw83AgQN1+PBhTZgwQcnJyWrVqpWWLFmi6OhoSVJycrLXd978/e9/V1ZWlh588EE9+OCDnvYhQ4Zo9uzZ5V0+AACogHz6PTe+wPfcAABw6bkkvufGdoyRdu2Sli3zdSUAAFRqPj0sZSsbN0odOkjVqkkpKZIfuREAAF/gE7i0tGkjVaki/fabtGWLr6sBAKDSItyUFn9/qUuXnPvn+WVzAABQtgg3penqq3NuCTcAAPgM4aaUJP2WpKuqfqjLH1BOuKlcF6EBAFBhEG5KSXhguL5L/a82RUlpv+6Tdu/2dUkAAFRKhJtSUi2omqoHVZck7aguDk0BAOAjhJtS1Lh6Y0nS9uqS1qzxbTEAAFRShJtS1Kh6I0nS9hqSNmzwbTEAAFRShJtSlLvn5ufqkjZtkk6f9mk9AABURoSbUtS4xpnDUrUcUkYGX+YHAIAPEG5KUe5hqZ9rOnIa1q/3YTUAAFROhJtSlHtYar8rU2kB4rwbAAB8gHBTiqoFVVONoBqSzlwOzp4bAADKHeGmlHmumKou6T//4aRiAADKGeGmlOWeVJwY5ZQyM6Wff/ZxRQAAVC6Em1LWIqKFJGnzZVVzGjZv9mE1AABUPoSbUtYmso0k6cea2TkN//2vD6sBAKDyIdyUstxws9V5TJkOsecGAIByRrgpZfVC6yk8MFxZytb/IsSeGwAAyhnhppRZluXZe/OfSEnbt+d8WzEAACgXhJsy0KbWmfNuGrgkt1vats3HFQEAUHkQbsqA56Ti2KCcBg5NAQBQbgg3ZcBzWCr8zOEoTioGAKDcEG7KQKtareRn+elXR7qSQ8SeGwAAyhHhpgxUcVZR84jmkqR1dUW4AQCgHBFuysgVda+QJK2rIykpSUpL821BAABUEoSbMtKpTidJ0rqYAMkYaetWH1cEAEDlQLgpI53qngk3dYyMxEnFAACUE8JNGWkT2UZOh1NHArK0s5o47wYAgHJCuCkjTodT7Wq3k8RJxQAAlCfCTRm6ok7OScXf1ReHpQAAKCeEmzJ0fcPrJUlfNJK0d690+LBvCwIAoBIg3JSh62Kvk7+fv7bXUM55N99/7+uSAACwPcJNGQp1hSqufpwk6YvLJK1Z49uCAACoBAg3ZaznZT0lSZ83EuEGAIByQLgpY79r9DtJ0lcNpbQNa6TsbB9XBACAvRFuyli72u3UMLyh0pzSvAap0rZtvi4JAABbI9yUMT/LT8M6DpMkzegkmdWrfVwRAAD2RrgpB3ddfpdcxqEf6kjffzff1+UAAGBrhJtyEBEcoYF1ekiSHvP/SlkZ6T6uCAAA+7KMMcbXRZSn1NRUhYWF6dixYwoNDS237e4+vFNtJzfSMZfRqPp36P/uek+WZXnmp2WmKeVkitJOpyktM03ZJlsuf5dcDpcC/QPl8j9z63DJ5e+Sv59/udUOAICvleTzm0/IchJdo6Fmpl6tO2p+o4l739dnb2xRTHiMDqYd1I4jO/Rr2q8lWp/Dcpw3/BR0P8ARID/5ybIsWbLOe+tn+XnuS5IxRmd+31y5edjIFHq/oGUKvF/IfEmeOvzkJz/Leydj3mBoySqw/Xzz8raX9/qKGntLZ8a/mH2Lsw4/y6/QyeHnOO98Tz/L4Xleuc8p9/G5/Rx+Dq9bfz9/r7a8/fPWnHeduY+9+lrnfy5537MAKi/CTTkadP0I7XvpG42/1tKmA5u06cAmr/mB/oGqElBFwQHBcvg5lJGVoVNZp5ThzrnNNmcvI3cbt06ePqmTp0+W87MAKr68YSfXuYEzbxgsqO18t7nrK+4yhW2zKOeG5oKeS3GXKYvlynNb51uO8fDdtgpbLiI4QgsGLCh0mbJGuClPPXroyT8Ga8h/TuqT10cou1kzVQuqpsuqXaaG1RqqWlC18y6elZ3lFXhKev+0+7SMjLJNtmdPyflus022jEy+/8xz70tSQf95594vaJmSrMvIyJ3tltu4lffoae4eHkmFtp9v3rlHYstzfcUZ9xLdFvKaFfZ6nju5jbvA9nz9zrwOuc/p3D1uuevPXV9u/9zbrOwsz/2C1n++PYAXIne9AHwjKiTKp9sn3JSnkBDp3ntVa9o03ffOf6WEl0u0uL+fv/yd/qrirFJGBQIVT97QljcMFRnIzoSxgtaXN/gV1Ha+W6lkQbWwbea2F/q8Cwl3F7JMWSxXnts633KMh++2db7lAv0DC12mPHBCcXnbtUtq1Ehyu6X166UOHcq/BgAALjEl+fzmUvDyFhMj3X57zv1775VOcs4MAACliXDjCy+8INWsKW3aJA0ZIqWl+boiAABsg3DjC/XqSR9+KDkc0kcfSS1bSn/7W86vhh84wI9rAgBwETjnxpeWLpXuv1/avdu73eWSIiOl0FCpalXv2ypVpMDA808u19n7Tqfk758TpByOwu8XNM/PT7Is7wkAAB/gS/wuFfHx0n//K/3zn9K//y39+KO0f7+UkSHt2ePr6gp2btgp7encQHXuNguqoThtpdXnUl23r7dfWNv52itrn3MV1FZYe1ksb9dtlWethSmrvhWhjoAAqVmz4q+3lLHnpqI5fVrat086dEhKTZWOH/e+TUvLCT+nTnlPBbWdOiVlZuZcmZWVlXNb2H0AAEpLVFTOH+uliD03l7KAACk2NmcqT9nZ3qEndzIm/5SdXXB7aU2565fyzzu3rTh9Lqatoq7rUq+1qPbKOv9cBbUV1l4Wy9t1W+VZa2HKqm9FqaNmzeL3LQOEG+Tw88s5PwcAgEscV0sBAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABb8Xm4mTFjhmJjYxUYGKgOHTpo5cqV5+2/YsUKdejQQYGBgWrYsKFef/31cqoUAABcCnwabubPn68RI0Zo9OjR2rhxo66++mr16tVLewr50cikpCT17t1bV199tTZu3KhnnnlGjzzyiBYsWFDOlQMAgIrKpz+c2blzZ7Vv314zZ870tDVv3lx9+/bVxIkT8/V/+umn9emnn2rr1q2etmHDhuk///mPVq9eXaxtVvgfzgQAAPmU5PPbZ3tuMjMztWHDBsXHx3u1x8fHa9WqVQUus3r16nz9e/bsqfXr1+v06dNlVisAALh0+OyHM1NSUuR2uxUZGenVHhkZqQMHDhS4zIEDBwrsn5WVpZSUFEVFReVbJiMjQxkZGZ7HqamppVA9AACoqHx+QrFlWV6PjTH52orqX1B7rokTJyosLMwz1a9f/yIrBgAAFZnP9txERETI4XDk20tz8ODBfHtnctWuXbvA/v7+/qpRo0aBy4waNUojR470PD527JgaNGjAHhwAAC4huZ/bxTlV2Gfhxul0qkOHDkpISFC/fv087QkJCbrlllsKXKZLly7617/+5dW2dOlSdezYUQEBAQUu43K55HK5PI9zB4c9OAAAXHqOHz+usLCw8/bx6dVS8+fP1+DBg/X666+rS5cueuONN/SPf/xDmzdvVnR0tEaNGqVffvlF7777rqScS8FbtWqlBx54QPfdd59Wr16tYcOGae7cubr11luLtc3s7Gzt379fVatWPe/hrwuRmpqq+vXra+/evVyJVQTGqmQYr+JjrEqG8So+xqr4ymKsjDE6fvy46tSpIz+/859V47M9N5I0cOBAHT58WBMmTFBycrJatWqlJUuWKDo6WpKUnJzs9Z03sbGxWrJkiR577DG99tprqlOnjqZNm1bsYCNJfn5+qlevXqk/l7xCQ0N54xcTY1UyjFfxMVYlw3gVH2NVfKU9VkXtscnl0z03dsN36BQfY1UyjFfxMVYlw3gVH2NVfL4eK59fLQUAAFCaCDelyOVyaezYsV4nMKNgjFXJMF7Fx1iVDONVfIxV8fl6rDgsBQAAbIU9NwAAwFYINwAAwFYINwAAwFYINwAAwFYIN6VkxowZio2NVWBgoDp06KCVK1f6uqQKYdy4cbIsy2uqXbu2Z74xRuPGjVOdOnUUFBSk7t27a/PmzT6suPx888036tOnj+rUqSPLsvTxxx97zS/O2GRkZOjhhx9WRESEqlSpoptvvln79u0rx2dRPooaq6FDh+Z7n1155ZVefSrLWE2cOFGdOnVS1apVVatWLfXt21fbtm3z6sN766zijBfvrxwzZ85UmzZtPF/M16VLF3322Wee+RXpfUW4KQXz58/XiBEjNHr0aG3cuFFXX321evXq5fXtypVZy5YtlZyc7Jl++uknz7xJkyZpypQpevXVV7Vu3TrVrl1bPXr00PHjx31YcflIS0tT27Zt9eqrrxY4vzhjM2LECC1atEjz5s3Tt99+qxMnTuimm26S2+0ur6dRLooaK0n63e9+5/U+W7Jkidf8yjJWK1as0IMPPqg1a9YoISFBWVlZio+PV1pamqcP762zijNeEu8vSapXr55eeOEFrV+/XuvXr9d1112nW265xRNgKtT7yuCiXXHFFWbYsGFebc2aNTN//vOffVRRxTF27FjTtm3bAudlZ2eb2rVrmxdeeMHTdurUKRMWFmZef/31cqqwYpBkFi1a5HlcnLE5evSoCQgIMPPmzfP0+eWXX4yfn5/5/PPPy6328nbuWBljzJAhQ8wtt9xS6DKVdayMMebgwYNGklmxYoUxhvdWUc4dL2N4f51PtWrVzJtvvlnh3lfsublImZmZ2rBhg+Lj473a4+PjtWrVKh9VVbFs375dderUUWxsrG6//Xbt3LlTUs4PoR44cMBr7Fwul7p161bpx644Y7NhwwadPn3aq0+dOnXUqlWrSjl+y5cvV61atdSkSRPdd999OnjwoGdeZR6rY8eOSZKqV68uifdWUc4dr1y8v7y53W7NmzdPaWlp6tKlS4V7XxFuLlJKSorcbrciIyO92iMjI3XgwAEfVVVxdO7cWe+++66++OIL/eMf/9CBAwcUFxenw4cPe8aHscuvOGNz4MABOZ1OVatWrdA+lUWvXr00Z84cff3115o8ebLWrVun6667ThkZGZIq71gZYzRy5EhdddVVatWqlSTeW+dT0HhJvL/y+umnnxQSEiKXy6Vhw4Zp0aJFatGiRYV7X/n0V8HtxLIsr8fGmHxtlVGvXr0891u3bq0uXbrosssu0zvvvOM5IY+xK9yFjE1lHL+BAwd67rdq1UodO3ZUdHS0Fi9erP79+xe6nN3H6qGHHtKPP/6ob7/9Nt883lv5FTZevL/Oatq0qTZt2qSjR49qwYIFGjJkiFasWOGZX1HeV+y5uUgRERFyOBz5UufBgwfzJVhIVapUUevWrbV9+3bPVVOMXX7FGZvatWsrMzNTv/32W6F9KquoqChFR0dr+/btkirnWD388MP69NNPtWzZMtWrV8/TznurYIWNV0Eq8/vL6XSqUaNG6tixoyZOnKi2bdtq6tSpFe59Rbi5SE6nUx06dFBCQoJXe0JCguLi4nxUVcWVkZGhrVu3KioqSrGxsapdu7bX2GVmZmrFihWVfuyKMzYdOnRQQECAV5/k5GT997//rfTjd/jwYe3du1dRUVGSKtdYGWP00EMPaeHChfr6668VGxvrNZ/3lreixqsglfn9dS5jjDIyMire+6pUT0+upObNm2cCAgLMW2+9ZbZs2WJGjBhhqlSpYnbt2uXr0nzu8ccfN8uXLzc7d+40a9asMTfddJOpWrWqZ2xeeOEFExYWZhYuXGh++uknM2jQIBMVFWVSU1N9XHnZO378uNm4caPZuHGjkWSmTJliNm7caHbv3m2MKd7YDBs2zNSrV898+eWX5ocffjDXXXedadu2rcnKyvLV0yoT5xur48ePm8cff9ysWrXKJCUlmWXLlpkuXbqYunXrVsqx+tOf/mTCwsLM8uXLTXJysmc6efKkpw/vrbOKGi/eX2eNGjXKfPPNNyYpKcn8+OOP5plnnjF+fn5m6dKlxpiK9b4i3JSS1157zURHRxun02nat2/vdRlhZTZw4EATFRVlAgICTJ06dUz//v3N5s2bPfOzs7PN2LFjTe3atY3L5TLXXHON+emnn3xYcflZtmyZkZRvGjJkiDGmeGOTnp5uHnroIVO9enUTFBRkbrrpJrNnzx4fPJuydb6xOnnypImPjzc1a9Y0AQEBpkGDBmbIkCH5xqGyjFVB4yTJzJo1y9OH99ZZRY0X76+z7r77bs/nXM2aNc3111/vCTbGVKz3lWWMMaW7LwgAAMB3OOcGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGQKW3fPlyWZalo0eP+roUAKWAcAMAAGyFcAMAAGyFcAPA54wxmjRpkho2bKigoCC1bdtWH330kaSzh4wWL16stm3bKjAwUJ07d9ZPP/3ktY4FCxaoZcuWcrlciomJ0eTJk73mZ2Rk6KmnnlL9+vXlcrnUuHFjvfXWW159NmzYoI4dOyo4OFhxcXHatm1b2T5xAGWCcAPA5/7yl79o1qxZmjlzpjZv3qzHHntMf/zjH7VixQpPnyeffFIvvfSS1q1bp1q1aunmm2/W6dOnJeWEkgEDBuj222/XTz/9pHHjxumvf/2rZs+e7Vn+zjvv1Lx58zRt2jRt3bpVr7/+ukJCQrzqGD16tCZPnqz169fL399fd999d7k8fwClix/OBOBTaWlpioiI0Ndff60uXbp42u+9916dPHlS999/v6699lrNmzdPAwcOlCQdOXJE9erV0+zZszVgwAD94Q9/0KFDh7R06VLP8k899ZQWL16szZs3KzExUU2bNlVCQoJuuOGGfDUsX75c1157rb788ktdf/31kqQlS5boxhtvVHp6ugIDA8t4FACUJvbcAPCpLVu26NSpU+rRo4dCQkI807vvvqsdO3Z4+uUNPtWrV1fTpk21detWSdLWrVvVtWtXr/V27dpV27dvl9vt1qZNm+RwONStW7fz1tKmTRvP/aioKEnSwYMHL/o5Aihf/r4uAEDllp2dLUlavHix6tat6zXP5XJ5BZxzWZYlKeecndz7ufLulA4KCipWLQEBAfnWnVsfgEsHe24A+FSLFi3kcrm0Z88eNWrUyGuqX7++p9+aNWs893/77TclJiaqWbNmnnV8++23XutdtWqVmjRpIofDodatWys7O9vrHB4A9sWeGwA+VbVqVT3xxBN67LHHlJ2drauuukqpqalatWqVQkJCFB0dLUmaMGGCatSoocjISI0ePVoRERHq27evJOnxxx9Xp06d9Oyzz2rgwIFavXq1Xn31Vc2YMUOSFBMToyFDhujuu+/WtGnT1LZtW+3evVsHDx7UgAEDfPXUAZQRwg0An3v22WdVq1YtTZw4UTt37lR4eLjat2+vZ555xnNY6IUXXtCjjz6q7du3q23btvr000/ldDolSe3bt9cHH3ygMWPG6Nlnn1VUVJQmTJigoUOHerYxc+ZMPfPMMxo+fLgOHz6sBg0a6JlnnvHF0wVQxrhaCkCFlnsl02+//abw8HBflwPgEsA5NwAAwFYINwAAwFY4LAUAAGyFPTcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBWCDcAAMBW/H1dQEXldrt1+vRpX5eBi+B0OuXnR34HgMqGcHMOY4wOHDigo0eP+roUXCQ/Pz/FxsbK6XT6uhQAQDmyjDHG10VUJMnJyTp69Khq1aql4OBgWZbl65JwAbKzs7V//34FBASoQYMGvI4AUImw5yYPt9vtCTY1atTwdTm4SDVr1tT+/fuVlZWlgIAAX5cDACgnnJCQR+45NsHBwT6uBKUh93CU2+32cSUAgPJEuCkAhzDsgdcRAConwg0AALAVwg3yiYmJ0SuvvFIq61q+fLksy+LqMwBAueGEYpvo3r272rVrVyqhZN26dapSpcrFFwUAgA8QbioJY4zcbrf8/Yt+yWvWrFkOFQEAUDY4LGUDQ4cO1YoVKzR16lRZliXLsjR79mxZlqUvvvhCHTt2lMvl0sqVK7Vjxw7dcsstioyMVEhIiDp16qQvv/zSa33nHpayLEtvvvmm+vXrp+DgYDVu3FiffvrpBde7YMECtWzZUi6XSzExMZo8ebLX/BkzZqhx48YKDAxUZGSkbrvtNs+8jz76SK1bt1ZQUJBq1KihG264QWlpaRdcCwDAfthzUxRjpJMnfbPt4GCpGFf8TJ06VYmJiWrVqpUmTJggSdq8ebMk6amnntJLL72khg0bKjw8XPv27VPv3r313HPPKTAwUO+884769Omjbdu2qUGDBoVuY/z48Zo0aZJefPFFTZ8+XX/4wx+0e/duVa9evURPacOGDRowYIDGjRungQMHatWqVRo+fLhq1KihoUOHav369XrkkUf0z3/+U3FxcTpy5IhWrlwpKecLFgcNGqRJkyapX79+On78uFauXCm+hxIA4MXAIz093WzZssWkp6efbTxxwpiciFP+04kTxa69W7du5tFHH/U8XrZsmZFkPv744yKXbdGihZk+fbrncXR0tHn55Zc9jyWZv/zlL3mG5ISxLMt89tlnRa47t47ffvvNGGPMHXfcYXr06OHV58knnzQtWrQwxhizYMECExoaalJTU/Ota8OGDUaS2bVrV5HbNaaQ1xMAYHsclrK5jh07ej1OS0vTU089pRYtWig8PFwhISH63//+pz179px3PW3atPHcr1KliqpWraqDBw+WuJ6tW7eqa9euXm1du3bV9u3b5Xa71aNHD0VHR6thw4YaPHiw5syZo5Nn9py1bdtW119/vVq3bq3f//73+sc//qHffvutxDUAAOyNcFOU4GDpxAnfTKXwTcnnXvX05JNPasGCBfq///s/rVy5Ups2bVLr1q2VmZl53vWc+/MFlmUpOzu7xPUYY/J9uZ7Jc1ipatWq+uGHHzR37lxFRUVpzJgxatu2rY4ePSqHw6GEhAR99tlnatGihaZPn66mTZsqKSmpxHUAAOyLc26KYlnSJXBZtNPpLNbPDKxcuVJDhw5Vv379JEknTpzQrl27yri6s1q0aKFvv/3Wq23VqlVq0qSJHA6HJMnf31833HCDbrjhBo0dO1bh4eH6+uuv1b9/f1mWpa5du6pr164aM2aMoqOjtWjRIo0cObLcngMAoGIj3NhETEyM1q5dq127dikkJKTQvSqNGjXSwoUL1adPH1mWpb/+9a8XtAfmQj3++OPq1KmTnn32WQ0cOFCrV6/Wq6++qhkzZkiS/v3vf2vnzp265pprVK1aNS1ZskTZ2dlq2rSp1q5dq6+++krx8fGqVauW1q5dq0OHDql58+blVj8AoOLjsJRNPPHEE3I4HGrRooVq1qxZ6Dk0L7/8sqpVq6a4uDj16dNHPXv2VPv27cutzvbt2+uDDz7QvHnz1KpVK40ZM0YTJkzQ0KFDJUnh4eFauHChrrvuOjVv3lyvv/665s6dq5YtWyo0NFTffPONevfurSZNmugvf/mLJk+erF69epVb/QCAis8yeU94qOROnTqlpKQkxcbGKjAw0Nfl4CLxegJA5cSeGwAAYCuEG1yUYcOGKSQkpMBp2LBhvi4PAFAJcVgqDw5jlNzBgweVmppa4LzQ0FDVqlWrnCs6i9cTAConrpbCRalVq5ZPAwwAAOfisBQAALAVwg0AALAVwg0AALAVwg0AALAVwg0AALAVwg0AALAVwg1Kxa5du2RZljZt2uTrUgAAlRzhxia6d++uESNGlNr6hg4dqr59+5ba+gAAKC+EGwAAYCuEmyIYY5SWmeaTqbi/jDF06FCtWLFCU6dOlWVZsixLu3bt0pYtW9S7d2+FhIQoMjJSgwcPVkpKime5jz76SK1bt1ZQUJBq1KihG264QWlpaRo3bpzeeecdffLJJ571LV++vMRjt2LFCl1xxRVyuVyKiorSn//8Z2VlZRW5fUlavny5rrjiClWpUkXh4eHq2rWrdu/eXeIaAACVDz+/UISTp08qZGKIT7Z9YtQJVXFWKbLf1KlTlZiYqFatWmnChAmSJLfbrW7duum+++7TlClTlJ6erqeffloDBgzQ119/reTkZA0aNEiTJk1Sv379dPz4ca1cuVLGGD3xxBPaunWrUlNTNWvWLElS9erVS1T7L7/8ot69e2vo0KF699139b///U/33XefAgMDNW7cuPNuPysrS3379tV9992nuXPnKjMzU99//70syyr5IAIAKh3CjQ2EhYXJ6XQqODhYtWvXliSNGTNG7du31/PPP+/p9/bbb6t+/fpKTEzUiRMnlJWVpf79+ys6OlqS1Lp1a0/foKAgZWRkeNZXUjNmzFD9+vX16quvyrIsNWvWTPv379fTTz+tMWPGKDk5udDtHzlyRMeOHdNNN92kyy67TJLUvHnzC6oDAFD5EG6KEBwQrBOjTvhs2xdqw4YNWrZsmUJC8u912rFjh+Lj43X99derdevW6tmzp+Lj43XbbbepWrVqF1Oyx9atW9WlSxevvS1du3bViRMntG/fPrVt27bQ7VevXl1Dhw5Vz5491aNHD91www0aMGCAoqKiSqU2AIC9cc5NESzLUhVnFZ9MF3MYJjs7W3369NGmTZu8pu3bt+uaa66Rw+FQQkKCPvvsM7Vo0ULTp09X06ZNlZSUVCrjZozJV3/uOUSWZRW5/VmzZmn16tWKi4vT/Pnz1aRJE61Zs6ZUagMA2BvhxiacTqfcbrfncfv27bV582bFxMSoUaNGXlOVKjnn8ViWpa5du2r8+PHauHGjnE6nFi1aVOD6SqpFixZatWqV10nRq1atUtWqVVW3bt0ity9Jl19+uUaNGqVVq1apVatWev/99y+4HgBA5UG4sYmYmBitXbtWu3btUkpKih588EEdOXJEgwYN0vfff6+dO3dq6dKluvvuu+V2u7V27Vo9//zzWr9+vfbs2aOFCxfq0KFDnnNbYmJi9OOPP2rbtm1KSUnR6dOnS1TP8OHDtXfvXj388MP63//+p08++URjx47VyJEj5efnd97tJyUladSoUVq9erV2796tpUuXKjExkfNuAADFY+CRnp5utmzZYtLT031dSolt27bNXHnllSYoKMhIMklJSSYxMdH069fPhIeHm6CgINOsWTMzYsQIk52dbbZs2WJ69uxpatasaVwul2nSpImZPn26Z30HDx40PXr0MCEhIUaSWbZs2Xm3n5SUZCSZjRs3etqWL19uOnXqZJxOp6ldu7Z5+umnzenTp40x5rzbP3DggOnbt6+JiooyTqfTREdHmzFjxhi3212iMbmUX08AwIWzjCnml6lUAqdOnVJSUpJiY2MVGBjo63JwkXg9AaBy4rAUAACwFcINiuX5559XSEhIgVOvXr18XR4AAB58zw2KZdiwYRowYECB84KCgsq5GgAACke4QbFUr169xD/BAACAL3BYCgAA2ArhBgAA2ArhBgAA2ArhBgAA2ArhBgAA2ArhBvnExMTolVde8XUZAABcEC4Ft4nu3burXbt2pRJK1q1b5/nlcAAALjWEm0rCGCO32y1//6Jf8po1a5ZDRQAAlA0OSxXBGCktzTdTcX/SdOjQoVqxYoWmTp0qy7JkWZZmz54ty7L0xRdfqGPHjnK5XFq5cqV27NihW265RZGRkQoJCVGnTp305Zdfeq3v3MNSlmXpzTffVL9+/RQcHKzGjRvr008/LVZtbrdb99xzj2JjYxUUFKSmTZtq6tSp+fq9/fbbatmypVwul6KiovTQQw955h09elT333+/IiMjFRgYqFatWunf//538QYHAFDpsOemCCdPSiEhvtn2iRNScY4OTZ06VYmJiWrVqpUmTJggSdq8ebMk6amnntJLL72khg0bKjw8XPv27VPv3r313HPPKTAwUO+884769Omjbdu2qUGDBoVuY/z48Zo0aZJefPFFTZ8+XX/4wx+0e/fuIr+1ODs7W/Xq1dMHH3ygiIgIrVq1Svfff7+ioqI8P+cwc+ZMjRw5Ui+88IJ69eqlY8eO6bvvvvMs36tXLx0/flzvvfeeLrvsMm3ZskUOh6M4QwgAqIwMPNLT082WLVtMenq6p+3ECWNy9qGU/3TiRPFr79atm3n00Uc9j5ctW2YkmY8//rjIZVu0aGGmT5/ueRwdHW1efvllz2NJ5i9/+UueMTlhLMsyn332WfELzGP48OHm1ltv9TyuU6eOGT16dIF9v/jiC+Pn52e2bdtW4u0U9HoCAOyPPTdFCA7O2YPiq21frI4dO3o9TktL0/jx4/Xvf/9b+/fvV1ZWltLT07Vnz57zrqdNmzae+1WqVFHVqlV18ODBYtXw+uuv680339Tu3buVnp6uzMxMtWvXTpJ08OBB7d+/X9dff32By27atEn16tVTkyZNirUtAAAIN0WwrOIdGqqozr3q6cknn9QXX3yhl156SY0aNVJQUJBuu+02ZWZmnnc9AQEBXo8ty1J2dnaR2//ggw/02GOPafLkyerSpYuqVq2qF198UWvXrpVU9C+K84vjAICSItzYhNPplNvtLrLfypUrNXToUPXr10+SdOLECe3atavM6lq5cqXi4uI0fPhwT9uOHTs896tWraqYmBh99dVXuvbaa/Mt36ZNG+3bt0+JiYnsvQEAFAtXS9lETEyM1q5dq127diklJaXQvSqNGjXSwoULtWnTJv3nP//RHXfcUaw9MBeqUaNGWr9+vb744gslJibqr3/9q9atW+fVZ9y4cZo8ebKmTZum7du364cfftD06dMlSd26ddM111yjW2+9VQkJCUpKStJnn32mzz//vMxqBgBc2gg3NvHEE0/I4XCoRYsWqlmzZqHn0Lz88suqVq2a4uLi1KdPH/Xs2VPt27cvs7qGDRum/v37a+DAgercubMOHz7stRdHkoYMGaJXXnlFM2bMUMuWLXXTTTdp+/btnvkLFixQp06dNGjQILVo0UJPPfVUsfZSAQAqJ8uY4n6biv2dOnVKSUlJio2NVWBgoK/LwUXi9QSAyok9NwAAwFYIN7gow4YNU0hISIHTsGHDfF0eAKAS4rBUHhzGKLmDBw8qNTW1wHmhoaGqVatWOVd0Fq8nAFROXAqOi1KrVi2fBhgAAM7FYSkAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBub6N69u0aMGFFq6xs6dKj69u1bausDAKC8EG4AAICtEG6KYIxRWlqaT6bifnn00KFDtWLFCk2dOlWWZcmyLO3atUtbtmxR7969FRISosjISA0ePFgpKSme5T766CO1bt1aQUFBqlGjhm644QalpaVp3Lhxeuedd/TJJ5941rd8+fIi63j66afVpEkTBQcHq2HDhvrrX/+q06dPe/X59NNP1bFjRwUGBioiIkL9+/f3zMvIyNBTTz2l+vXry+VyqXHjxnrrrbeK90IBAHAG31BchJMnTyokJMQn2z5x4oSqVKlSZL+pU6cqMTFRrVq10oQJEyRJbrdb3bp103333acpU6YoPT1dTz/9tAYMGKCvv/5aycnJGjRokCZNmqR+/frp+PHjWrlypYwxeuKJJ7R161alpqZq1qxZkqTq1asXWUfVqlU1e/Zs1alTRz/99JPuu+8+Va1aVU899ZQkafHixerfv79Gjx6tf/7zn8rMzNTixYs9y995551avXq1pk2bprZt2yopKckrjAEAUBz8tlQeBf0WUVpaWoUPN1LOOTft2rXTK6+8IkkaM2aM1q5dqy+++MLTZ9++fapfv762bdumEydOqEOHDtq1a5eio6PzrW/o0KE6evSoPv744wuu/8UXX9T8+fO1fv16SVJcXJwaNmyo9957L1/fxMRENW3aVAkJCbrhhhsueJt58dtSAFA5seemCMHBwTpx4oTPtn2hNmzYoGXLlhUYzHbs2KH4+Hhdf/31at26tXr27Kn4+Hjddtttqlat2gVv86OPPtIrr7yin3/+WSdOnFBWVpZCQ0M98zdt2qT77ruvwGU3bdokh8Ohbt26XfD2AQCQCDdFsiyr2HtPKpLs7Gz16dNHf/vb3/LNi4qKksPhUEJCglatWqWlS5dq+vTpGj16tNauXavY2NgSb2/NmjW6/fbbNX78ePXs2VNhYWGaN2+eJk+e7OkTFBRU6PLnmwcAQElwQrFNOJ1Oud1uz+P27dtr8+bNiomJUaNGjbym3LBmWZa6du2q8ePHa+PGjXI6nVq0aFGB6yvKd999p+joaI0ePVodO3ZU48aNtXv3bq8+bdq00VdffVXg8q1bt1Z2drZWrFhR0qcOAIAXwo1NxMTEaO3atdq1a5dSUlL04IMP6siRIxo0aJC+//577dy5U0uXLtXdd98tt9uttWvX6vnnn9f69eu1Z88eLVy4UIcOHVLz5s096/vxxx+1bds2paSk5Lvq6VyNGjXSnj17NG/ePO3YsUPTpk3zBKVcY8eO1dy5czV27Fht3bpVP/30kyZNmuTZ3pAhQ3T33Xfr448/VlJSkpYvX64PPvigbAYMAGBfBh7p6elmy5YtJj093dellNi2bdvMlVdeaYKCgowkk5SUZBITE02/fv1MeHi4CQoKMs2aNTMjRoww2dnZZsuWLaZnz56mZs2axuVymSZNmpjp06d71nfw4EHTo0cPExISYiSZZcuWFVnDk08+aWrUqGFCQkLMwIEDzcsvv2zCwsK8+ixYsMC0a9fOOJ1OExERYfr37++Zl56ebh577DETFRVlnE6nadSokXn77bcveEwu5dcTAHDhuFoqD66usRdeTwConDgsBQAAbIVwg2J5/vnnFRISUuDUq1cvX5cHAIAHl4KjWIYNG6YBAwYUOI/LuAEAFQnhBsVSvXr1Yv0EAwAAvsZhqQJwjrU98DoCQOVEuMkjICBAUs6PZeLSl5mZKUlyOBw+rgQAUJ44LJWHw+FQeHi4Dh48KCnnt50sy/JxVbgQ2dnZOnTokIKDg+Xvz9scACoT/tc/R+3atSXJE3Bw6fLz81ODBg0IqABQyfAlfoVwu91F/uQAKjan0yk/P468AkBlQ7gBAAC2wp+1AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVv4fD1gYJqxREqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.6124378,-1.2069638,-1.0079257,-0.86705697,-1.2771977,0.70393896,-1.2866447,-0.48081002,-1.5150118,-1.8707395,-1.4234748,-0.9600467,-0.6695061,-1.601905,-0.28447643,1.3420272,-0.541387,-1.3176425,0.14146905,0.054381017,-0.3423471,-1.3361771,-1.3148606,-1.1648135,-1.4444693,0.38410023,-1.4256774,-0.4851463,-1.5476227,-1.7977825,0.23438033,-2.8760054,-1.3867798,-2.910221,-1.3691807,-0.3890024,-1.8886545,-0.17701381,-1.1616066,-1.7130934,-2.335375,1.4664263,-0.008085084,1.3589816,0.08195285,2.5610237,0.6637673,-1.6393129,-0.003133829,0.5865098,\n",
      "\n",
      "a_bias1: \n",
      "1.1546682,1.0000272,0.7563798,0.8458515,0.7172648,-1.213315,0.72582346,1.0867479,0.6258997,0.7663763,\n",
      "\n",
      "a_weight2: \n",
      "-1.865642,-2.594975,-1.5325016,-2.4117296,-1.5467626,2.8457181,-1.7833017,-1.7122254,-1.5969222,-2.1434517,\n",
      "\n",
      "a_bias2: \n",
      "1.8851511,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,2,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noCBF_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noCBF_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de91bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.1714 - acc: 0.8613 - val_loss: 0.1577 - val_acc: 0.8614\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1463 - acc: 0.8613 - val_loss: 0.1238 - val_acc: 0.8614\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1141 - acc: 0.8853 - val_loss: 0.0952 - val_acc: 0.9561\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0825 - acc: 0.9524 - val_loss: 0.0732 - val_acc: 0.9298\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0591 - acc: 0.9281 - val_loss: 0.0590 - val_acc: 0.9257\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0448 - acc: 0.9255 - val_loss: 0.0520 - val_acc: 0.9250\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0373 - acc: 0.9254 - val_loss: 0.0484 - val_acc: 0.9270\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0333 - acc: 0.9277 - val_loss: 0.0456 - val_acc: 0.9277\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0307 - acc: 0.9278 - val_loss: 0.0432 - val_acc: 0.9321\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0288 - acc: 0.9470 - val_loss: 0.0415 - val_acc: 0.9499\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0274 - acc: 0.9508 - val_loss: 0.0404 - val_acc: 0.9511\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9514 - val_loss: 0.0397 - val_acc: 0.9513\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9515 - val_loss: 0.0394 - val_acc: 0.9516\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9516 - val_loss: 0.0392 - val_acc: 0.9516\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9517 - val_loss: 0.0391 - val_acc: 0.9516\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9517 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9518 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0243 - acc: 0.9518 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9518 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9519 - val_loss: 0.0392 - val_acc: 0.9518\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9519 - val_loss: 0.0392 - val_acc: 0.9518\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9519 - val_loss: 0.0392 - val_acc: 0.9518\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9518\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9519\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9519\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9520 - val_loss: 0.0394 - val_acc: 0.9519\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9520 - val_loss: 0.0394 - val_acc: 0.9519\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9520 - val_loss: 0.0394 - val_acc: 0.9519\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9520 - val_loss: 0.0395 - val_acc: 0.9519\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9520 - val_loss: 0.0395 - val_acc: 0.9519\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9520 - val_loss: 0.0396 - val_acc: 0.9519\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9520 - val_loss: 0.0396 - val_acc: 0.9519\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9519 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0396 - val_acc: 0.9506\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0237 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0237 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9507\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 20s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9507 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0399 - val_acc: 0.9506\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0236 - acc: 0.9508 - val_loss: 0.0398 - val_acc: 0.9506\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9507\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9506\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0397 - val_acc: 0.9507\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9508 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0235 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0396 - val_acc: 0.9507\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9507\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9507\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9507\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9507\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9506\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9506\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0395 - val_acc: 0.9507\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0234 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0394 - val_acc: 0.9507\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9508\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9508\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9508\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9507\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0393 - val_acc: 0.9508\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0232 - acc: 0.9510 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0392 - val_acc: 0.9508\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9509 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0231 - acc: 0.9511 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0390 - val_acc: 0.9508\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0231 - acc: 0.9511 - val_loss: 0.0390 - val_acc: 0.9509\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9510 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9511 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0230 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9510\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9510\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0386 - val_acc: 0.9511\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9512 - val_loss: 0.0386 - val_acc: 0.9511\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9511\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9511\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0387 - val_acc: 0.9511\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9512\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9511\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9512\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9512\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0386 - val_acc: 0.9512\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9513 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0385 - val_acc: 0.9512\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0385 - val_acc: 0.9513\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9514 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0384 - val_acc: 0.9513\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9515\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9516 - val_loss: 0.0381 - val_acc: 0.9514\n",
      "15396/15396 [==============================] - 12s 782us/step - loss: 0.0381 - acc: 0.9514\n",
      "\n",
      "Test Accuracy: 0.9514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-1.6210499,-1.5694121,0.0097347805,-1.0608325,-2.48218,-1.3841894,2.7756517,0.2253463,-1.2883803,-0.8375856,-2.172834,-1.9866847,0.1326684,-1.0695878,-5.278819,-1.6543123,6.4957156,-0.011188636,-1.4411234,-0.85116404,-0.18176246,-0.21360016,-0.53828007,-0.16877474,-0.21141946,-0.23294401,0.16459894,0.6600611,-0.23412251,-0.11283826,-0.51530844,-0.6551925,1.2793139,-1.3093388,0.59700745,-0.8394628,-0.7881947,-1.2283112,-1.0638821,-1.2193747,-0.4465322,-0.5822489,1.1509664,-0.8114368,0.12405985,-0.64780617,-0.27384257,-1.37812,-0.76423806,-0.87234765,\n",
      "\n",
      "a_bias1: \n",
      "0.7955529,0.85837704,-1.362641,0.8985389,0.5387431,0.78205854,-0.41158262,1.3768462,0.8604238,0.8999523,\n",
      "\n",
      "a_weight2: \n",
      "-1.771037,-1.7327331,1.9968512,-1.706908,-2.8595338,-1.729478,2.0824544,-1.8281446,-1.6235805,-1.6034038,\n",
      "\n",
      "a_bias2: \n",
      "1.0859838,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noCUD_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noCUD_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d658d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1745 - acc: 0.8612 - val_loss: 0.1607 - val_acc: 0.8616\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1576 - acc: 0.8612 - val_loss: 0.1317 - val_acc: 0.8616\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 19s 1ms/step - loss: 0.1362 - acc: 0.8612 - val_loss: 0.1067 - val_acc: 0.8616\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 18s 1ms/step - loss: 0.1093 - acc: 0.8715 - val_loss: 0.0842 - val_acc: 0.8931\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0833 - acc: 0.9394 - val_loss: 0.0674 - val_acc: 0.9526\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0629 - acc: 0.9476 - val_loss: 0.0571 - val_acc: 0.9402\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0492 - acc: 0.9278 - val_loss: 0.0522 - val_acc: 0.9223\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0411 - acc: 0.9227 - val_loss: 0.0498 - val_acc: 0.9213\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0363 - acc: 0.9217 - val_loss: 0.0476 - val_acc: 0.9216\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0330 - acc: 0.9229 - val_loss: 0.0451 - val_acc: 0.9333\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0304 - acc: 0.9424 - val_loss: 0.0429 - val_acc: 0.9447\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0285 - acc: 0.9489 - val_loss: 0.0413 - val_acc: 0.9493\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0270 - acc: 0.9503 - val_loss: 0.0404 - val_acc: 0.9501\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0260 - acc: 0.9507 - val_loss: 0.0398 - val_acc: 0.9502\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9507 - val_loss: 0.0395 - val_acc: 0.9500\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9506 - val_loss: 0.0394 - val_acc: 0.9502\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9508 - val_loss: 0.0392 - val_acc: 0.9505\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9510 - val_loss: 0.0391 - val_acc: 0.9507\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9512 - val_loss: 0.0391 - val_acc: 0.9508\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9509\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0236 - acc: 0.9514 - val_loss: 0.0391 - val_acc: 0.9510\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9515 - val_loss: 0.0391 - val_acc: 0.9511\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9516 - val_loss: 0.0391 - val_acc: 0.9511\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9517 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0232 - acc: 0.9517 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9517 - val_loss: 0.0392 - val_acc: 0.9512\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0230 - acc: 0.9517 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9518 - val_loss: 0.0392 - val_acc: 0.9513\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9518 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0229 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9517 - val_loss: 0.0393 - val_acc: 0.9512\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0393 - val_acc: 0.9512\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0393 - val_acc: 0.9512\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 0.9512\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 0.9513\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 0.9513\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9519 - val_loss: 0.0394 - val_acc: 0.9513\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9519 - val_loss: 0.0393 - val_acc: 0.9513\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9515\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9514\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0225 - acc: 0.9520 - val_loss: 0.0393 - val_acc: 0.9515\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9521 - val_loss: 0.0393 - val_acc: 0.9515\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9521 - val_loss: 0.0393 - val_acc: 0.9515\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9521 - val_loss: 0.0392 - val_acc: 0.9515\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9521 - val_loss: 0.0392 - val_acc: 0.9516\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0392 - val_acc: 0.9516\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0392 - val_acc: 0.9516\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0392 - val_acc: 0.9517\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0392 - val_acc: 0.9516\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0392 - val_acc: 0.9517\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9522 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0392 - val_acc: 0.9517\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9517\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9523 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0391 - val_acc: 0.9518\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9519\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9519\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9518\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9519\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9525 - val_loss: 0.0390 - val_acc: 0.9519\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0390 - val_acc: 0.9519\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9518\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9525 - val_loss: 0.0389 - val_acc: 0.9518\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9518\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9518\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9524 - val_loss: 0.0389 - val_acc: 0.9518\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9523 - val_loss: 0.0389 - val_acc: 0.9519\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9523 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0388 - val_acc: 0.9517\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9522 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0389 - val_acc: 0.9517\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9521 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9519 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9519 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9519 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9519 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9519 - val_loss: 0.0389 - val_acc: 0.9514\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9518 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9518 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9517 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9517 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9516 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9510\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9510\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9515 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0389 - val_acc: 0.9509\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0219 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9509\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9513 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9508\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9507\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9507\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9507\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0218 - acc: 0.9514 - val_loss: 0.0388 - val_acc: 0.9507\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0218 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9507\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9517 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9517 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9516 - val_loss: 0.0388 - val_acc: 0.9511\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0217 - acc: 0.9517 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0217 - acc: 0.9518 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0217 - acc: 0.9519 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0217 - acc: 0.9519 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9519 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9519 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9515\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0216 - acc: 0.9520 - val_loss: 0.0388 - val_acc: 0.9514\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9521 - val_loss: 0.0388 - val_acc: 0.9516\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0216 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0216 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9521 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0386 - val_acc: 0.9517\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9522 - val_loss: 0.0386 - val_acc: 0.9517\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9524 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0215 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9523 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9523 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9524 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9520\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0385 - val_acc: 0.9520\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9520\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9520\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0214 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9525 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0384 - val_acc: 0.9521\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9522\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9522\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9522\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0213 - acc: 0.9526 - val_loss: 0.0383 - val_acc: 0.9521\n",
      "15396/15396 [==============================] - 12s 794us/step - loss: 0.0383 - acc: 0.9521\n",
      "\n",
      "Test Accuracy: 0.9521\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.5166746,-2.34801,0.9793843,-1.7526127,-2.3147795,-1.9199976,-2.4302073,0.16906245,-0.45742124,-1.210546,-0.66755205,-9.608646,1.2986376,-1.314109,-5.792112,-2.4086103,-3.5551329,0.24874085,-0.37562245,-0.8917722,-1.1779759,-1.4227533,1.3799026,-0.3813018,-1.0507917,-0.72751546,-0.56904995,-0.70724493,-1.0510459,-0.63055325,-1.1401241,0.8015635,0.8607689,-1.4674582,0.16472988,-0.79142827,-0.46736857,-1.3408438,-1.0849175,-1.350057,-0.6454564,0.6780806,1.1103259,-0.5615935,0.31300697,-0.43147308,-0.009774169,-1.0312908,-0.84521127,-0.7299738,\n",
      "\n",
      "a_bias1: \n",
      "1.2251949,0.80668575,-0.29991695,0.8025599,0.6555983,0.32869768,0.5062176,1.5596902,1.1477704,1.0704854,\n",
      "\n",
      "a_weight2: \n",
      "-1.7727357,-3.2637131,2.7067785,-1.6776357,-2.6042373,-1.4092748,-2.1135283,-2.0777564,-1.718004,-1.748398,\n",
      "\n",
      "a_bias2: \n",
      "2.2187636,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,2,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noOEF_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noOEF_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20dd234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1729 - acc: 0.8613 - val_loss: 0.1630 - val_acc: 0.8611\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1574 - acc: 0.8613 - val_loss: 0.1388 - val_acc: 0.8611\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1340 - acc: 0.8619 - val_loss: 0.1146 - val_acc: 0.8653\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.1055 - acc: 0.9020 - val_loss: 0.0920 - val_acc: 0.9542\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0793 - acc: 0.9502 - val_loss: 0.0738 - val_acc: 0.9453\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0594 - acc: 0.9427 - val_loss: 0.0605 - val_acc: 0.9404\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0460 - acc: 0.9354 - val_loss: 0.0529 - val_acc: 0.9329\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0382 - acc: 0.9327 - val_loss: 0.0487 - val_acc: 0.9354\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0339 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9378\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0313 - acc: 0.9384 - val_loss: 0.0444 - val_acc: 0.9398\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0297 - acc: 0.9398 - val_loss: 0.0432 - val_acc: 0.9406\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0286 - acc: 0.9409 - val_loss: 0.0425 - val_acc: 0.9417\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0279 - acc: 0.9416 - val_loss: 0.0420 - val_acc: 0.9424\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0275 - acc: 0.9422 - val_loss: 0.0418 - val_acc: 0.9428\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0271 - acc: 0.9427 - val_loss: 0.0415 - val_acc: 0.9432\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0269 - acc: 0.9430 - val_loss: 0.0413 - val_acc: 0.9436\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0267 - acc: 0.9433 - val_loss: 0.0412 - val_acc: 0.9437\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0265 - acc: 0.9435 - val_loss: 0.0410 - val_acc: 0.9439\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9437 - val_loss: 0.0409 - val_acc: 0.9441\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9438 - val_loss: 0.0408 - val_acc: 0.9444\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9445 - val_loss: 0.0407 - val_acc: 0.9459\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9455 - val_loss: 0.0406 - val_acc: 0.9463\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9460 - val_loss: 0.0405 - val_acc: 0.9466\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9463 - val_loss: 0.0405 - val_acc: 0.9468\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9464 - val_loss: 0.0404 - val_acc: 0.9470\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9466 - val_loss: 0.0404 - val_acc: 0.9471\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9467 - val_loss: 0.0403 - val_acc: 0.9472\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9468 - val_loss: 0.0403 - val_acc: 0.9473\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9469 - val_loss: 0.0403 - val_acc: 0.9474\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0259 - acc: 0.9470 - val_loss: 0.0403 - val_acc: 0.9475\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9471 - val_loss: 0.0403 - val_acc: 0.9475\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9471 - val_loss: 0.0402 - val_acc: 0.9476\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9472 - val_loss: 0.0402 - val_acc: 0.9477\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9472 - val_loss: 0.0401 - val_acc: 0.9477\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9473 - val_loss: 0.0402 - val_acc: 0.9477\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9473 - val_loss: 0.0401 - val_acc: 0.9479\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9473 - val_loss: 0.0400 - val_acc: 0.9479\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9474 - val_loss: 0.0401 - val_acc: 0.9479\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9474 - val_loss: 0.0401 - val_acc: 0.9479\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9474 - val_loss: 0.0401 - val_acc: 0.9479\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9475 - val_loss: 0.0401 - val_acc: 0.9480\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9475 - val_loss: 0.0401 - val_acc: 0.9480\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9475 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9475 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0401 - val_acc: 0.9481\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9482\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9482\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9482\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9478 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9479 - val_loss: 0.0400 - val_acc: 0.9482\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9479 - val_loss: 0.0400 - val_acc: 0.9492\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9481 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9487 - val_loss: 0.0401 - val_acc: 0.9482\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9485 - val_loss: 0.0400 - val_acc: 0.9492\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9485 - val_loss: 0.0400 - val_acc: 0.9492\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9487 - val_loss: 0.0400 - val_acc: 0.9492\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9487 - val_loss: 0.0400 - val_acc: 0.9492\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9488 - val_loss: 0.0401 - val_acc: 0.9492\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9487 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 15s 996us/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9494\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0401 - val_acc: 0.9492\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9489 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0401 - val_acc: 0.9492\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9488 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9487 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9487 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9484 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9485 - val_loss: 0.0400 - val_acc: 0.9493\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9484 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9483 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0399 - val_acc: 0.9493\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9483 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9480 - val_loss: 0.0400 - val_acc: 0.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0399 - val_acc: 0.9483\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0400 - val_acc: 0.9483\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9483\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0400 - val_acc: 0.9482\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9483\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0399 - val_acc: 0.9483\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9482\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9478 - val_loss: 0.0399 - val_acc: 0.9482\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9482\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0400 - val_acc: 0.9481\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9477 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9481\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0399 - val_acc: 0.9480\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9479\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9475 - val_loss: 0.0399 - val_acc: 0.9480\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9476 - val_loss: 0.0400 - val_acc: 0.9479\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9475 - val_loss: 0.0400 - val_acc: 0.9479\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9475 - val_loss: 0.0400 - val_acc: 0.9479\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9475 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9475 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0400 - val_acc: 0.9478\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9473 - val_loss: 0.0399 - val_acc: 0.9479\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9478\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9474 - val_loss: 0.0399 - val_acc: 0.9478\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9473 - val_loss: 0.0399 - val_acc: 0.9478\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9473 - val_loss: 0.0399 - val_acc: 0.9478\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9473 - val_loss: 0.0399 - val_acc: 0.9477\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9473 - val_loss: 0.0399 - val_acc: 0.9477\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9472 - val_loss: 0.0399 - val_acc: 0.9477\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9473 - val_loss: 0.0400 - val_acc: 0.9476\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9472 - val_loss: 0.0399 - val_acc: 0.9477\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9472 - val_loss: 0.0400 - val_acc: 0.9476\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9472 - val_loss: 0.0399 - val_acc: 0.9477\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9472 - val_loss: 0.0399 - val_acc: 0.9476\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9471 - val_loss: 0.0399 - val_acc: 0.9476\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9471 - val_loss: 0.0399 - val_acc: 0.9476\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9470 - val_loss: 0.0398 - val_acc: 0.9476\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9471 - val_loss: 0.0400 - val_acc: 0.9474\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9470 - val_loss: 0.0399 - val_acc: 0.9474\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9470 - val_loss: 0.0400 - val_acc: 0.9474\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9470 - val_loss: 0.0399 - val_acc: 0.9474\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9469 - val_loss: 0.0399 - val_acc: 0.9473\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9469 - val_loss: 0.0399 - val_acc: 0.9473\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9469 - val_loss: 0.0399 - val_acc: 0.9473\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9469 - val_loss: 0.0400 - val_acc: 0.9473\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9468 - val_loss: 0.0399 - val_acc: 0.9473\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9468 - val_loss: 0.0400 - val_acc: 0.9471\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9468 - val_loss: 0.0400 - val_acc: 0.9471\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9467 - val_loss: 0.0399 - val_acc: 0.9472\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9467 - val_loss: 0.0400 - val_acc: 0.9470\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9466 - val_loss: 0.0400 - val_acc: 0.9470\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9467 - val_loss: 0.0400 - val_acc: 0.9469\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9466 - val_loss: 0.0400 - val_acc: 0.9469\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9464 - val_loss: 0.0400 - val_acc: 0.9469\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9465 - val_loss: 0.0400 - val_acc: 0.9468\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9464 - val_loss: 0.0401 - val_acc: 0.9468\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9464 - val_loss: 0.0400 - val_acc: 0.9468\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9463 - val_loss: 0.0400 - val_acc: 0.9468\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9463 - val_loss: 0.0401 - val_acc: 0.9465\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9461 - val_loss: 0.0401 - val_acc: 0.9463\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9459 - val_loss: 0.0400 - val_acc: 0.9463\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9459 - val_loss: 0.0401 - val_acc: 0.9463\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9458 - val_loss: 0.0400 - val_acc: 0.9463\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9458 - val_loss: 0.0401 - val_acc: 0.9460\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9457 - val_loss: 0.0401 - val_acc: 0.9459\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9455 - val_loss: 0.0401 - val_acc: 0.9459\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9455 - val_loss: 0.0402 - val_acc: 0.9459\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9455 - val_loss: 0.0402 - val_acc: 0.9459\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9454 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9452 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9452 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9450 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9450 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9450 - val_loss: 0.0402 - val_acc: 0.9454\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9449 - val_loss: 0.0403 - val_acc: 0.9447\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9445 - val_loss: 0.0403 - val_acc: 0.9447\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9444 - val_loss: 0.0403 - val_acc: 0.9447\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9443 - val_loss: 0.0403 - val_acc: 0.9447\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9443 - val_loss: 0.0403 - val_acc: 0.9447\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9443 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9446\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9436 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9434 - val_loss: 0.0403 - val_acc: 0.9439\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0405 - val_acc: 0.9438\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0403 - val_acc: 0.9438\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9434 - val_loss: 0.0403 - val_acc: 0.9438\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9438\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9434 - val_loss: 0.0403 - val_acc: 0.9439\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9434 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9439\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9435 - val_loss: 0.0404 - val_acc: 0.9439\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9440\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9436 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9438 - val_loss: 0.0404 - val_acc: 0.9442\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9438 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9439 - val_loss: 0.0404 - val_acc: 0.9443\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9439 - val_loss: 0.0404 - val_acc: 0.9443\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0404 - val_acc: 0.9443\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0404 - val_acc: 0.9443\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9443\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0404 - val_acc: 0.9443\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9439 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9440 - val_loss: 0.0402 - val_acc: 0.9444\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0243 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9444\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9440 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0243 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0243 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9441 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9441 - val_loss: 0.0402 - val_acc: 0.9446\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9442 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9441 - val_loss: 0.0402 - val_acc: 0.9446\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9442 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9442 - val_loss: 0.0403 - val_acc: 0.9445\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9442 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9443 - val_loss: 0.0403 - val_acc: 0.9446\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9443 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9443 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9443 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9443 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9443 - val_loss: 0.0402 - val_acc: 0.9448\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9444 - val_loss: 0.0402 - val_acc: 0.9447\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9446 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9449 - val_loss: 0.0402 - val_acc: 0.9448\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9450 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9450 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9451 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9451 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9451 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9452 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9455 - val_loss: 0.0402 - val_acc: 0.9455\n",
      "15396/15396 [==============================] - 12s 759us/step - loss: 0.0402 - acc: 0.9455\n",
      "\n",
      "Test Accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "0.12422844,2.1722813,-2.7424471,0.27706152,-1.7281861,-0.71165144,1.5237622,-2.0214732,-0.15805633,-1.9952041,-0.76654726,1.5269986,-2.0584462,-0.84367245,-1.5400312,-0.80645764,1.0431442,-4.3246017,-0.8557564,-5.203639,-0.6686125,0.5128012,-0.1035518,-0.57978064,-0.99686754,-1.2579911,0.93344957,-1.1048361,-0.530084,-1.3639923,0.44074535,0.7175232,-1.008314,0.5716381,-0.5822218,0.094713844,0.18408804,-0.8899316,0.40140465,-0.76890326,-1.8106934,0.6532719,-0.15085113,-1.9378635,-0.61461574,-1.385558,1.1551249,1.0000432,-1.7907073,1.2431179,\n",
      "\n",
      "a_bias1: \n",
      "1.6211717,-0.70532924,0.45557737,1.703618,0.7289663,1.355676,-1.0318582,0.77044785,1.6874118,0.9753058,\n",
      "\n",
      "a_weight2: \n",
      "-1.5261843,2.288457,-1.7856253,-1.715803,-1.4259417,-1.50811,2.4186714,-2.6426728,-1.6281725,-3.2672367,\n",
      "\n",
      "a_bias2: \n",
      "1.4025606,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,2,3,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noFLM_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noFLM_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ed36ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.1736 - acc: 0.8615 - val_loss: 0.1586 - val_acc: 0.8605\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.1564 - acc: 0.8615 - val_loss: 0.1302 - val_acc: 0.8605\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.1383 - acc: 0.8615 - val_loss: 0.1082 - val_acc: 0.8605\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.1182 - acc: 0.8615 - val_loss: 0.0902 - val_acc: 0.8605\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0995 - acc: 0.8785 - val_loss: 0.0770 - val_acc: 0.8931\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0839 - acc: 0.9279 - val_loss: 0.0672 - val_acc: 0.9577\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0715 - acc: 0.9545 - val_loss: 0.0600 - val_acc: 0.9516\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0617 - acc: 0.9494 - val_loss: 0.0550 - val_acc: 0.9456\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0539 - acc: 0.9446 - val_loss: 0.0516 - val_acc: 0.9424\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0480 - acc: 0.9409 - val_loss: 0.0493 - val_acc: 0.9378\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0434 - acc: 0.9380 - val_loss: 0.0476 - val_acc: 0.9376\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9382 - val_loss: 0.0459 - val_acc: 0.9384\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0369 - acc: 0.9392 - val_loss: 0.0444 - val_acc: 0.9394\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0344 - acc: 0.9404 - val_loss: 0.0431 - val_acc: 0.9409\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0324 - acc: 0.9414 - val_loss: 0.0422 - val_acc: 0.9416\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0308 - acc: 0.9422 - val_loss: 0.0415 - val_acc: 0.9425\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0295 - acc: 0.9429 - val_loss: 0.0410 - val_acc: 0.9431\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0285 - acc: 0.9436 - val_loss: 0.0405 - val_acc: 0.9437\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0277 - acc: 0.9442 - val_loss: 0.0401 - val_acc: 0.9443\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0270 - acc: 0.9447 - val_loss: 0.0396 - val_acc: 0.9447\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9465 - val_loss: 0.0392 - val_acc: 0.9467\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9471 - val_loss: 0.0390 - val_acc: 0.9470\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9485 - val_loss: 0.0387 - val_acc: 0.9491\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9497 - val_loss: 0.0385 - val_acc: 0.9497\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9502 - val_loss: 0.0384 - val_acc: 0.9500\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9505 - val_loss: 0.0383 - val_acc: 0.9502\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9506 - val_loss: 0.0382 - val_acc: 0.9503\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9508 - val_loss: 0.0381 - val_acc: 0.9505\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9509 - val_loss: 0.0381 - val_acc: 0.9506\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0237 - acc: 0.9510 - val_loss: 0.0380 - val_acc: 0.9508\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0236 - acc: 0.9511 - val_loss: 0.0380 - val_acc: 0.9508\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0235 - acc: 0.9511 - val_loss: 0.0380 - val_acc: 0.9509\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0234 - acc: 0.9512 - val_loss: 0.0380 - val_acc: 0.9510\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0233 - acc: 0.9512 - val_loss: 0.0380 - val_acc: 0.9510\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0233 - acc: 0.9513 - val_loss: 0.0380 - val_acc: 0.9510\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0232 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9510\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9513 - val_loss: 0.0381 - val_acc: 0.9511\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9514 - val_loss: 0.0381 - val_acc: 0.9511\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0231 - acc: 0.9514 - val_loss: 0.0381 - val_acc: 0.9511\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9514 - val_loss: 0.0382 - val_acc: 0.9511\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9514 - val_loss: 0.0381 - val_acc: 0.9512\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0230 - acc: 0.9514 - val_loss: 0.0382 - val_acc: 0.9512\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9512\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9514 - val_loss: 0.0382 - val_acc: 0.9512\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9512\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0229 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9513\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9515 - val_loss: 0.0382 - val_acc: 0.9514\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0228 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9513\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0383 - val_acc: 0.9514\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9514\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9514\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9514\n",
      "Epoch 59/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9515\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9514\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9516 - val_loss: 0.0384 - val_acc: 0.9515\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0384 - val_acc: 0.9514\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0227 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9515\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0385 - val_acc: 0.9516\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9515\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0386 - val_acc: 0.9515\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9517 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0226 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9516\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9516\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9517\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 0.9517\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0225 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 117/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0224 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9517\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9519 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0223 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0387 - val_acc: 0.9518\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9521 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9521 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9521 - val_loss: 0.0386 - val_acc: 0.9519\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0222 - acc: 0.9521 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0386 - val_acc: 0.9518\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9519\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0221 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9519\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9521 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0220 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 15s 952us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9518\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0385 - val_acc: 0.9517\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 15s 952us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9518\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0219 - acc: 0.9520 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0385 - val_acc: 0.9517\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 15s 952us/step - loss: 0.0219 - acc: 0.9519 - val_loss: 0.0384 - val_acc: 0.9517\n",
      "15396/15396 [==============================] - 10s 676us/step - loss: 0.0384 - acc: 0.9517\n",
      "\n",
      "Test Accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-1.1387593,-1.1369098,-0.918848,-1.8153266,-0.8935258,-1.13997,-1.4731684,-1.7909415,-1.4803032,-1.6373569,-1.9809884,-1.3630034,-0.9361459,-5.78333,-0.53442895,-1.3911338,-2.082007,-4.936007,-2.5162196,-4.1967373,-1.8071579,-1.1915222,-1.0896866,-2.0262504,-0.9877597,-1.2198961,-1.4931276,-1.7659172,-1.7531855,-1.9288249,-0.50619835,-0.16091985,0.30017477,-0.41182548,0.3799208,-0.04821401,-0.534679,-0.44265425,-0.56738514,-0.40662122,-1.3952572,-1.9977554,-2.6531887,0.1134726,-3.239504,-2.0642226,-1.4138966,0.013125884,-1.1729039,-0.3310936,\n",
      "\n",
      "a_bias1: \n",
      "0.85549504,1.228401,1.3712062,1.5127126,1.3222247,1.1830859,0.9870187,1.2525519,1.0087614,1.2241693,\n",
      "\n",
      "a_weight2: \n",
      "-1.8492403,-2.0587473,-2.3359597,-3.4475422,-2.292189,-2.012564,-1.9897199,-2.9342256,-2.0976121,-2.859445,\n",
      "\n",
      "a_bias2: \n",
      "4.046795,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,2,3,5,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_noPPS_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_noPPS_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2adb3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.2448 - acc: 0.9026 - val_loss: 0.2296 - val_acc: 0.9523\n",
      "Epoch 2/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.2162 - acc: 0.9338 - val_loss: 0.1869 - val_acc: 0.9221\n",
      "Epoch 3/300\n",
      "15396/15396 [==============================] - 15s 976us/step - loss: 0.1672 - acc: 0.9155 - val_loss: 0.1404 - val_acc: 0.9107\n",
      "Epoch 4/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.1189 - acc: 0.9085 - val_loss: 0.1013 - val_acc: 0.9082\n",
      "Epoch 5/300\n",
      "15396/15396 [==============================] - 15s 955us/step - loss: 0.0838 - acc: 0.9087 - val_loss: 0.0764 - val_acc: 0.9092\n",
      "Epoch 6/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0637 - acc: 0.9095 - val_loss: 0.0653 - val_acc: 0.9123\n",
      "Epoch 7/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0543 - acc: 0.9136 - val_loss: 0.0601 - val_acc: 0.9154\n",
      "Epoch 8/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0494 - acc: 0.9150 - val_loss: 0.0564 - val_acc: 0.9145\n",
      "Epoch 9/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0462 - acc: 0.9138 - val_loss: 0.0535 - val_acc: 0.9121\n",
      "Epoch 10/300\n",
      "15396/15396 [==============================] - 15s 977us/step - loss: 0.0438 - acc: 0.9122 - val_loss: 0.0513 - val_acc: 0.9127\n",
      "Epoch 11/300\n",
      "15396/15396 [==============================] - 15s 978us/step - loss: 0.0420 - acc: 0.9237 - val_loss: 0.0496 - val_acc: 0.9329\n",
      "Epoch 12/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0407 - acc: 0.9353 - val_loss: 0.0490 - val_acc: 0.9364\n",
      "Epoch 13/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0398 - acc: 0.9370 - val_loss: 0.0487 - val_acc: 0.9373\n",
      "Epoch 14/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0392 - acc: 0.9375 - val_loss: 0.0486 - val_acc: 0.9375\n",
      "Epoch 15/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0388 - acc: 0.9376 - val_loss: 0.0486 - val_acc: 0.9377\n",
      "Epoch 16/300\n",
      "15396/15396 [==============================] - 15s 955us/step - loss: 0.0385 - acc: 0.9377 - val_loss: 0.0484 - val_acc: 0.9378\n",
      "Epoch 17/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0382 - acc: 0.9377 - val_loss: 0.0485 - val_acc: 0.9377\n",
      "Epoch 18/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0381 - acc: 0.9375 - val_loss: 0.0485 - val_acc: 0.9374\n",
      "Epoch 19/300\n",
      "15396/15396 [==============================] - 15s 981us/step - loss: 0.0379 - acc: 0.9373 - val_loss: 0.0486 - val_acc: 0.9374\n",
      "Epoch 20/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0378 - acc: 0.9372 - val_loss: 0.0485 - val_acc: 0.9374\n",
      "Epoch 21/300\n",
      "15396/15396 [==============================] - 15s 973us/step - loss: 0.0377 - acc: 0.9372 - val_loss: 0.0486 - val_acc: 0.9372\n",
      "Epoch 22/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0376 - acc: 0.9371 - val_loss: 0.0487 - val_acc: 0.9372\n",
      "Epoch 23/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0375 - acc: 0.9371 - val_loss: 0.0487 - val_acc: 0.9371\n",
      "Epoch 24/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0375 - acc: 0.9370 - val_loss: 0.0487 - val_acc: 0.9371\n",
      "Epoch 25/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0374 - acc: 0.9370 - val_loss: 0.0487 - val_acc: 0.9370\n",
      "Epoch 26/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0374 - acc: 0.9369 - val_loss: 0.0486 - val_acc: 0.9370\n",
      "Epoch 27/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0373 - acc: 0.9369 - val_loss: 0.0487 - val_acc: 0.9369\n",
      "Epoch 28/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0373 - acc: 0.9368 - val_loss: 0.0487 - val_acc: 0.9369\n",
      "Epoch 29/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0373 - acc: 0.9368 - val_loss: 0.0488 - val_acc: 0.9369\n",
      "Epoch 30/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0372 - acc: 0.9367 - val_loss: 0.0489 - val_acc: 0.9367\n",
      "Epoch 31/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0372 - acc: 0.9366 - val_loss: 0.0488 - val_acc: 0.9367\n",
      "Epoch 32/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0372 - acc: 0.9366 - val_loss: 0.0489 - val_acc: 0.9367\n",
      "Epoch 33/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0372 - acc: 0.9366 - val_loss: 0.0488 - val_acc: 0.9367\n",
      "Epoch 34/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0372 - acc: 0.9366 - val_loss: 0.0489 - val_acc: 0.9366\n",
      "Epoch 35/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0372 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9366\n",
      "Epoch 36/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9366\n",
      "Epoch 37/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0490 - val_acc: 0.9366\n",
      "Epoch 38/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 39/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 40/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 41/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 42/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 43/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0371 - acc: 0.9365 - val_loss: 0.0491 - val_acc: 0.9364\n",
      "Epoch 44/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0371 - acc: 0.9364 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 45/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0490 - val_acc: 0.9364\n",
      "Epoch 46/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 47/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0491 - val_acc: 0.9364\n",
      "Epoch 48/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0491 - val_acc: 0.9364\n",
      "Epoch 49/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0491 - val_acc: 0.9364\n",
      "Epoch 50/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 51/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 52/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0491 - val_acc: 0.9364\n",
      "Epoch 53/300\n",
      "15396/15396 [==============================] - 15s 978us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 54/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 55/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 56/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 57/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0493 - val_acc: 0.9364\n",
      "Epoch 58/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9364\n",
      "Epoch 60/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0493 - val_acc: 0.9364\n",
      "Epoch 61/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0370 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9363\n",
      "Epoch 62/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 63/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0370 - acc: 0.9364 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 64/300\n",
      "15396/15396 [==============================] - 15s 975us/step - loss: 0.0370 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9366\n",
      "Epoch 65/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0370 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9366\n",
      "Epoch 66/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0370 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 67/300\n",
      "15396/15396 [==============================] - 15s 976us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 68/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 69/300\n",
      "15396/15396 [==============================] - 15s 948us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9366\n",
      "Epoch 70/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9366\n",
      "Epoch 71/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 72/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 73/300\n",
      "15396/15396 [==============================] - 15s 974us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 74/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0369 - acc: 0.9366 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 75/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 76/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 77/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 78/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 79/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 80/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 81/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9366\n",
      "Epoch 82/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 83/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 84/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 85/300\n",
      "15396/15396 [==============================] - 15s 955us/step - loss: 0.0369 - acc: 0.9367 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 86/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 87/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 88/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0369 - acc: 0.9368 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 89/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 90/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 91/300\n",
      "15396/15396 [==============================] - 15s 976us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 92/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 93/300\n",
      "15396/15396 [==============================] - 15s 982us/step - loss: 0.0369 - acc: 0.9373 - val_loss: 0.0494 - val_acc: 0.9365\n",
      "Epoch 94/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 95/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0369 - acc: 0.9368 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 96/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0369 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9376\n",
      "Epoch 97/300\n",
      "15396/15396 [==============================] - 15s 983us/step - loss: 0.0369 - acc: 0.9368 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 98/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0369 - acc: 0.9367 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 99/300\n",
      "15396/15396 [==============================] - 15s 983us/step - loss: 0.0369 - acc: 0.9369 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 100/300\n",
      "15396/15396 [==============================] - 15s 978us/step - loss: 0.0369 - acc: 0.9368 - val_loss: 0.0492 - val_acc: 0.9365\n",
      "Epoch 101/300\n",
      "15396/15396 [==============================] - 15s 974us/step - loss: 0.0368 - acc: 0.9365 - val_loss: 0.0492 - val_acc: 0.9365\n",
      "Epoch 102/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0368 - acc: 0.9367 - val_loss: 0.0492 - val_acc: 0.9375\n",
      "Epoch 103/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0368 - acc: 0.9367 - val_loss: 0.0492 - val_acc: 0.9376\n",
      "Epoch 104/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0368 - acc: 0.9372 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 105/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0368 - acc: 0.9368 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 106/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0368 - acc: 0.9370 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 107/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0368 - acc: 0.9366 - val_loss: 0.0492 - val_acc: 0.9376\n",
      "Epoch 108/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0368 - acc: 0.9370 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 109/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0368 - acc: 0.9368 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 110/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0368 - acc: 0.9373 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 111/300\n",
      "15396/15396 [==============================] - 15s 971us/step - loss: 0.0368 - acc: 0.9369 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 112/300\n",
      "15396/15396 [==============================] - 15s 949us/step - loss: 0.0368 - acc: 0.9366 - val_loss: 0.0491 - val_acc: 0.9376\n",
      "Epoch 113/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0368 - acc: 0.9368 - val_loss: 0.0492 - val_acc: 0.9365\n",
      "Epoch 114/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0368 - acc: 0.9369 - val_loss: 0.0492 - val_acc: 0.9365\n",
      "Epoch 115/300\n",
      "15396/15396 [==============================] - 15s 980us/step - loss: 0.0368 - acc: 0.9367 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 116/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0368 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9375\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0368 - acc: 0.9370 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 118/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0368 - acc: 0.9365 - val_loss: 0.0491 - val_acc: 0.9376\n",
      "Epoch 119/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0368 - acc: 0.9369 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 120/300\n",
      "15396/15396 [==============================] - 15s 945us/step - loss: 0.0367 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 121/300\n",
      "15396/15396 [==============================] - 15s 955us/step - loss: 0.0367 - acc: 0.9367 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 122/300\n",
      "15396/15396 [==============================] - 15s 950us/step - loss: 0.0367 - acc: 0.9370 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 123/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0367 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 124/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 125/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0367 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 126/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0367 - acc: 0.9366 - val_loss: 0.0491 - val_acc: 0.9365\n",
      "Epoch 127/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9376\n",
      "Epoch 128/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0367 - acc: 0.9369 - val_loss: 0.0490 - val_acc: 0.9365\n",
      "Epoch 129/300\n",
      "15396/15396 [==============================] - 15s 990us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 130/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 131/300\n",
      "15396/15396 [==============================] - 15s 974us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 132/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0367 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9365\n",
      "Epoch 133/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 134/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0489 - val_acc: 0.9365\n",
      "Epoch 135/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9365\n",
      "Epoch 136/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9365\n",
      "Epoch 137/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9365\n",
      "Epoch 138/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0488 - val_acc: 0.9365\n",
      "Epoch 139/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0487 - val_acc: 0.9365\n",
      "Epoch 140/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0487 - val_acc: 0.9365\n",
      "Epoch 141/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0366 - acc: 0.9365 - val_loss: 0.0487 - val_acc: 0.9365\n",
      "Epoch 142/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0486 - val_acc: 0.9366\n",
      "Epoch 143/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0486 - val_acc: 0.9365\n",
      "Epoch 144/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0486 - val_acc: 0.9365\n",
      "Epoch 145/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0486 - val_acc: 0.9365\n",
      "Epoch 146/300\n",
      "15396/15396 [==============================] - 15s 955us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0485 - val_acc: 0.9366\n",
      "Epoch 147/300\n",
      "15396/15396 [==============================] - 15s 954us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0485 - val_acc: 0.9365\n",
      "Epoch 148/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0484 - val_acc: 0.9366\n",
      "Epoch 149/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0365 - acc: 0.9365 - val_loss: 0.0484 - val_acc: 0.9366\n",
      "Epoch 150/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0364 - acc: 0.9365 - val_loss: 0.0484 - val_acc: 0.9366\n",
      "Epoch 151/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0364 - acc: 0.9365 - val_loss: 0.0484 - val_acc: 0.9365\n",
      "Epoch 152/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0364 - acc: 0.9364 - val_loss: 0.0483 - val_acc: 0.9366\n",
      "Epoch 153/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0364 - acc: 0.9364 - val_loss: 0.0483 - val_acc: 0.9366\n",
      "Epoch 154/300\n",
      "15396/15396 [==============================] - 15s 952us/step - loss: 0.0364 - acc: 0.9365 - val_loss: 0.0484 - val_acc: 0.9363\n",
      "Epoch 155/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0364 - acc: 0.9363 - val_loss: 0.0482 - val_acc: 0.9366\n",
      "Epoch 156/300\n",
      "15396/15396 [==============================] - 15s 991us/step - loss: 0.0364 - acc: 0.9363 - val_loss: 0.0482 - val_acc: 0.9363\n",
      "Epoch 157/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0363 - acc: 0.9364 - val_loss: 0.0483 - val_acc: 0.9363\n",
      "Epoch 158/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0483 - val_acc: 0.9363\n",
      "Epoch 159/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0482 - val_acc: 0.9363\n",
      "Epoch 160/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0482 - val_acc: 0.9363\n",
      "Epoch 161/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0481 - val_acc: 0.9363\n",
      "Epoch 162/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0480 - val_acc: 0.9363\n",
      "Epoch 163/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0363 - acc: 0.9363 - val_loss: 0.0480 - val_acc: 0.9363\n",
      "Epoch 164/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0362 - acc: 0.9363 - val_loss: 0.0480 - val_acc: 0.9363\n",
      "Epoch 165/300\n",
      "15396/15396 [==============================] - 15s 952us/step - loss: 0.0362 - acc: 0.9363 - val_loss: 0.0479 - val_acc: 0.9363\n",
      "Epoch 166/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0362 - acc: 0.9363 - val_loss: 0.0479 - val_acc: 0.9363\n",
      "Epoch 167/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0362 - acc: 0.9363 - val_loss: 0.0478 - val_acc: 0.9363\n",
      "Epoch 168/300\n",
      "15396/15396 [==============================] - 15s 994us/step - loss: 0.0362 - acc: 0.9363 - val_loss: 0.0478 - val_acc: 0.9363\n",
      "Epoch 169/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0362 - acc: 0.9364 - val_loss: 0.0478 - val_acc: 0.9363\n",
      "Epoch 170/300\n",
      "15396/15396 [==============================] - 15s 984us/step - loss: 0.0361 - acc: 0.9363 - val_loss: 0.0477 - val_acc: 0.9364\n",
      "Epoch 171/300\n",
      "15396/15396 [==============================] - 15s 990us/step - loss: 0.0361 - acc: 0.9363 - val_loss: 0.0477 - val_acc: 0.9363\n",
      "Epoch 172/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0361 - acc: 0.9363 - val_loss: 0.0477 - val_acc: 0.9364\n",
      "Epoch 173/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0361 - acc: 0.9363 - val_loss: 0.0476 - val_acc: 0.9364\n",
      "Epoch 174/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0361 - acc: 0.9364 - val_loss: 0.0477 - val_acc: 0.9363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0361 - acc: 0.9363 - val_loss: 0.0475 - val_acc: 0.9364\n",
      "Epoch 176/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0360 - acc: 0.9364 - val_loss: 0.0475 - val_acc: 0.9364\n",
      "Epoch 177/300\n",
      "15396/15396 [==============================] - 15s 954us/step - loss: 0.0360 - acc: 0.9363 - val_loss: 0.0474 - val_acc: 0.9364\n",
      "Epoch 178/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0360 - acc: 0.9364 - val_loss: 0.0474 - val_acc: 0.9364\n",
      "Epoch 179/300\n",
      "15396/15396 [==============================] - 15s 982us/step - loss: 0.0360 - acc: 0.9364 - val_loss: 0.0474 - val_acc: 0.9364\n",
      "Epoch 180/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0360 - acc: 0.9364 - val_loss: 0.0474 - val_acc: 0.9364\n",
      "Epoch 181/300\n",
      "15396/15396 [==============================] - 15s 982us/step - loss: 0.0360 - acc: 0.9364 - val_loss: 0.0473 - val_acc: 0.9364\n",
      "Epoch 182/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0359 - acc: 0.9364 - val_loss: 0.0473 - val_acc: 0.9363\n",
      "Epoch 183/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0359 - acc: 0.9364 - val_loss: 0.0473 - val_acc: 0.9363\n",
      "Epoch 184/300\n",
      "15396/15396 [==============================] - 15s 975us/step - loss: 0.0359 - acc: 0.9364 - val_loss: 0.0472 - val_acc: 0.9364\n",
      "Epoch 185/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0359 - acc: 0.9363 - val_loss: 0.0472 - val_acc: 0.9364\n",
      "Epoch 186/300\n",
      "15396/15396 [==============================] - 15s 954us/step - loss: 0.0359 - acc: 0.9364 - val_loss: 0.0473 - val_acc: 0.9363\n",
      "Epoch 187/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0359 - acc: 0.9363 - val_loss: 0.0471 - val_acc: 0.9364\n",
      "Epoch 188/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0359 - acc: 0.9364 - val_loss: 0.0472 - val_acc: 0.9364\n",
      "Epoch 189/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0471 - val_acc: 0.9364\n",
      "Epoch 190/300\n",
      "15396/15396 [==============================] - 15s 957us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0471 - val_acc: 0.9364\n",
      "Epoch 191/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0470 - val_acc: 0.9364\n",
      "Epoch 192/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0358 - acc: 0.9363 - val_loss: 0.0470 - val_acc: 0.9364\n",
      "Epoch 193/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0470 - val_acc: 0.9364\n",
      "Epoch 194/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0469 - val_acc: 0.9365\n",
      "Epoch 195/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0469 - val_acc: 0.9364\n",
      "Epoch 196/300\n",
      "15396/15396 [==============================] - 15s 990us/step - loss: 0.0358 - acc: 0.9364 - val_loss: 0.0469 - val_acc: 0.9364\n",
      "Epoch 197/300\n",
      "15396/15396 [==============================] - 15s 988us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0469 - val_acc: 0.9364\n",
      "Epoch 198/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0468 - val_acc: 0.9364\n",
      "Epoch 199/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0468 - val_acc: 0.9364\n",
      "Epoch 200/300\n",
      "15396/15396 [==============================] - 15s 980us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 201/300\n",
      "15396/15396 [==============================] - 15s 990us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0468 - val_acc: 0.9364\n",
      "Epoch 202/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 203/300\n",
      "15396/15396 [==============================] - 15s 988us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0468 - val_acc: 0.9364\n",
      "Epoch 204/300\n",
      "15396/15396 [==============================] - 15s 973us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 205/300\n",
      "15396/15396 [==============================] - 15s 975us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 206/300\n",
      "15396/15396 [==============================] - 15s 968us/step - loss: 0.0357 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 207/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0466 - val_acc: 0.9365\n",
      "Epoch 208/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 209/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0467 - val_acc: 0.9364\n",
      "Epoch 210/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0466 - val_acc: 0.9365\n",
      "Epoch 211/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 212/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 213/300\n",
      "15396/15396 [==============================] - 15s 973us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 214/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 215/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 216/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 217/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 218/300\n",
      "15396/15396 [==============================] - 15s 1000us/step - loss: 0.0356 - acc: 0.9364 - val_loss: 0.0465 - val_acc: 0.9365\n",
      "Epoch 219/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 220/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 221/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 222/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 223/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 224/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 225/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 226/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 227/300\n",
      "15396/15396 [==============================] - 15s 982us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 228/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 229/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0464 - val_acc: 0.9365\n",
      "Epoch 230/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 231/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 232/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "15396/15396 [==============================] - 15s 973us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 234/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 235/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 236/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 237/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9365\n",
      "Epoch 238/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0355 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9364\n",
      "Epoch 239/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9364\n",
      "Epoch 240/300\n",
      "15396/15396 [==============================] - 15s 1000us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 241/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9364\n",
      "Epoch 242/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 243/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 244/300\n",
      "15396/15396 [==============================] - 15s 972us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 245/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0463 - val_acc: 0.9364\n",
      "Epoch 246/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 247/300\n",
      "15396/15396 [==============================] - 15s 990us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9366\n",
      "Epoch 248/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9366\n",
      "Epoch 249/300\n",
      "15396/15396 [==============================] - 15s 996us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 250/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 251/300\n",
      "15396/15396 [==============================] - 15s 978us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 252/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 253/300\n",
      "15396/15396 [==============================] - 15s 970us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9365\n",
      "Epoch 254/300\n",
      "15396/15396 [==============================] - 15s 958us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 255/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 256/300\n",
      "15396/15396 [==============================] - 15s 964us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 257/300\n",
      "15396/15396 [==============================] - 15s 979us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0462 - val_acc: 0.9364\n",
      "Epoch 258/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 259/300\n",
      "15396/15396 [==============================] - 15s 988us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9365\n",
      "Epoch 260/300\n",
      "15396/15396 [==============================] - 15s 960us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 261/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0354 - acc: 0.9363 - val_loss: 0.0460 - val_acc: 0.9365\n",
      "Epoch 262/300\n",
      "15396/15396 [==============================] - 15s 953us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 263/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 264/300\n",
      "15396/15396 [==============================] - 15s 963us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 265/300\n",
      "15396/15396 [==============================] - 15s 975us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9365\n",
      "Epoch 266/300\n",
      "15396/15396 [==============================] - 15s 956us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 267/300\n",
      "15396/15396 [==============================] - 15s 976us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 268/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 269/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0354 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 270/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 271/300\n",
      "15396/15396 [==============================] - 15s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 272/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 273/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 274/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 275/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 276/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 277/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 278/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9365\n",
      "Epoch 279/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 280/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 281/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 282/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9365\n",
      "Epoch 283/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 284/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 285/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 286/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 287/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 288/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9365\n",
      "Epoch 289/300\n",
      "15396/15396 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 290/300\n",
      "15396/15396 [==============================] - 16s 1ms/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "15396/15396 [==============================] - 15s 971us/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 292/300\n",
      "15396/15396 [==============================] - 15s 961us/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0460 - val_acc: 0.9364\n",
      "Epoch 293/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 294/300\n",
      "15396/15396 [==============================] - 15s 962us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 295/300\n",
      "15396/15396 [==============================] - 15s 965us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 296/300\n",
      "15396/15396 [==============================] - 15s 966us/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 297/300\n",
      "15396/15396 [==============================] - 15s 969us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 298/300\n",
      "15396/15396 [==============================] - 15s 999us/step - loss: 0.0353 - acc: 0.9364 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 299/300\n",
      "15396/15396 [==============================] - 15s 967us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "Epoch 300/300\n",
      "15396/15396 [==============================] - 15s 959us/step - loss: 0.0353 - acc: 0.9363 - val_loss: 0.0459 - val_acc: 0.9364\n",
      "15396/15396 [==============================] - 11s 707us/step - loss: 0.0459 - acc: 0.9364\n",
      "\n",
      "Test Accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-2.2282238,1.5082263,-1.4550549,0.07871822,-2.2955728,-0.89525557,0.12615408,-1.4593712,-1.5934635,1.2826803,-6.444388,3.3276458,-1.9475616,0.30896083,-7.4476767,-0.9743872,0.21152054,-2.8847346,-1.9166577,1.6425736,-1.3569773,1.5544455,-1.0305976,0.21814531,-1.4208947,-0.71192527,0.1798074,-1.576084,-0.88443863,1.0235685,-0.74006397,0.6271373,-0.60346544,0.32966566,-0.706698,-0.30191416,-0.17539723,-0.5867099,-0.72436005,0.544213,0.44915223,0.099223435,-0.82716256,-1.6449171,0.55166364,-1.2782513,1.2106465,-0.2916362,-0.861184,1.02029,0.7001574,-0.00955768,-0.56719893,-1.1687741,0.8080586,-0.98685855,0.9651806,-0.20822862,-0.47568738,0.83285505,\n",
      "\n",
      "a_bias1: \n",
      "0.74395066,-0.7259866,0.75049734,1.4569955,0.71181655,0.9818493,-1.3561007,0.73863983,0.80046135,-0.8777117,\n",
      "\n",
      "a_weight2: \n",
      "-2.7678368,1.4442427,-1.6867114,-2.0754611,-2.9210782,-1.5928057,1.5264875,-1.9541576,-1.650517,1.406484,\n",
      "\n",
      "a_bias2: \n",
      "0.52815324,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 6\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Att.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,2,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights)\n",
    "\n",
    "model.save_weights(r'revision/att_model_allFeatures_nosamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Attrubute)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_AttTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/att_model_allFeatures_nosamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c4b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
