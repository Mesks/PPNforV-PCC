{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f20c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "plot_model(model,to_file='FeaturesPlots/model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7986a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.1925 - acc: 0.6941 - val_loss: 0.2073 - val_acc: 0.6940\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1639 - acc: 0.7103 - val_loss: 0.1660 - val_acc: 0.8205\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1208 - acc: 0.9292 - val_loss: 0.1217 - val_acc: 0.9210\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0825 - acc: 0.9195 - val_loss: 0.0901 - val_acc: 0.9186\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0586 - acc: 0.9168 - val_loss: 0.0723 - val_acc: 0.9149\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0459 - acc: 0.9147 - val_loss: 0.0631 - val_acc: 0.9156\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0391 - acc: 0.9166 - val_loss: 0.0576 - val_acc: 0.9175\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0348 - acc: 0.9179 - val_loss: 0.0538 - val_acc: 0.9182\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0317 - acc: 0.9319 - val_loss: 0.0510 - val_acc: 0.9385\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0295 - acc: 0.9401 - val_loss: 0.0490 - val_acc: 0.9403\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0278 - acc: 0.9410 - val_loss: 0.0477 - val_acc: 0.9408\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0266 - acc: 0.9413 - val_loss: 0.0467 - val_acc: 0.9411\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0257 - acc: 0.9415 - val_loss: 0.0460 - val_acc: 0.9414\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0251 - acc: 0.9417 - val_loss: 0.0456 - val_acc: 0.9415\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0246 - acc: 0.9418 - val_loss: 0.0452 - val_acc: 0.9416\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0242 - acc: 0.9419 - val_loss: 0.0449 - val_acc: 0.9417\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0240 - acc: 0.9420 - val_loss: 0.0447 - val_acc: 0.9418\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0237 - acc: 0.9421 - val_loss: 0.0445 - val_acc: 0.9418\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0235 - acc: 0.9422 - val_loss: 0.0443 - val_acc: 0.9419\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0234 - acc: 0.9422 - val_loss: 0.0442 - val_acc: 0.9419\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0233 - acc: 0.9423 - val_loss: 0.0441 - val_acc: 0.9420\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0232 - acc: 0.9423 - val_loss: 0.0440 - val_acc: 0.9421\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0231 - acc: 0.9424 - val_loss: 0.0440 - val_acc: 0.9422\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0230 - acc: 0.9426 - val_loss: 0.0439 - val_acc: 0.9425\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0230 - acc: 0.9427 - val_loss: 0.0439 - val_acc: 0.9426\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0229 - acc: 0.9429 - val_loss: 0.0438 - val_acc: 0.9429\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0229 - acc: 0.9431 - val_loss: 0.0438 - val_acc: 0.9430\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0228 - acc: 0.9432 - val_loss: 0.0438 - val_acc: 0.9431\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0228 - acc: 0.9433 - val_loss: 0.0438 - val_acc: 0.9431\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0228 - acc: 0.9433 - val_loss: 0.0437 - val_acc: 0.9432\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9434 - val_loss: 0.0437 - val_acc: 0.9433\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9435 - val_loss: 0.0437 - val_acc: 0.9433\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9435 - val_loss: 0.0437 - val_acc: 0.9433\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0227 - acc: 0.9435 - val_loss: 0.0437 - val_acc: 0.9434\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9436 - val_loss: 0.0437 - val_acc: 0.9434\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9436 - val_loss: 0.0437 - val_acc: 0.9434\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0226 - acc: 0.9436 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9435\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9437 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0226 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9438 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9436\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9436\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 177/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0438 - val_acc: 0.9437\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0225 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 293/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0436 - val_acc: 0.9437\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0224 - acc: 0.9439 - val_loss: 0.0436 - val_acc: 0.9437\n",
      "15354/15354 [==============================] - 12s 775us/step - loss: 0.0436 - acc: 0.9437\n",
      "\n",
      "Test Accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_allFeatures_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4345107c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_allFeatures_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35ec79e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.5900826,0.7789073,-0.4631772,0.61461014,-0.53145254,-0.5777704,0.48389786,-0.55607945,-0.54800445,-0.8040239,-1.3920724,1.4705355,-1.3641691,1.4304916,-1.1559026,-1.2960557,1.1264307,-1.3811178,-1.2470144,-1.6135243,-0.6770284,0.37193444,-0.7469931,0.53114384,-0.69298416,-0.6536249,0.6097996,-0.6379087,-0.6672146,-0.30642352,0.25087065,0.64150006,0.014606831,0.13603075,-0.7911398,-0.5421696,0.71801656,-0.5175149,-0.5473345,-1.193361,-1.1423151,0.6231394,-0.69070995,0.9008047,-0.13089076,-0.36864397,0.29351252,-0.343208,-0.32308143,-0.23717588,\n",
      "\n",
      "a_bias1: \n",
      "1.6562462,-1.5034757,1.5847926,-1.6831235,1.6409048,1.6651386,-1.6707897,1.6391828,1.6021428,1.6246109,\n",
      "\n",
      "a_weight2: \n",
      "-2.24646,2.220489,-2.1966429,2.3298783,-2.08547,-2.1216617,2.2567475,-2.1332924,-2.0517242,-2.2700918,\n",
      "\n",
      "a_bias2: \n",
      "0.8758933,"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")\n",
    "\n",
    "# print(\"\\n\\na_weight3: \")\n",
    "# for a in a_weight3:\n",
    "#     for b in a:\n",
    "#         print(b,end=\",\")\n",
    "        \n",
    "# print(\"\\n\\na_bias3: \")\n",
    "# for a in a_bias3:\n",
    "#         print(a,end=\",\")\n",
    "        \n",
    "# g_weight1=model.get_layer(index=0).get_weights()\n",
    "# g_weight2=model.get_layer(index=1).get_weights()\n",
    "        \n",
    "# print(g_weight1)\n",
    "# print(g_weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb842f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.models import Sequential, load_model\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# inp_num = 6\n",
    "\n",
    "# mmodel = Sequential()\n",
    "# mmodel.add(Dense(10, input_dim=inp_num, activation='sigmoid'))\n",
    "# mmodel.add(Dense(1,activation='sigmoid'))\n",
    "# mmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['acc'])\n",
    "# # mmodel.add(Dense(3, activation='softmax'))\n",
    "# # mmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), optimizer='Adam', metrics=['acc'])\n",
    "# mmodel.load_weights(r'weightANDlearningcurve/geo_model.h5')\n",
    "\n",
    "# data=np.array([0,0,1,1,0,0]).reshape(1,-1)\n",
    "# print(mmodel.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ea8529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.1926 - acc: 0.6939 - val_loss: 0.2107 - val_acc: 0.6952\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1660 - acc: 0.7407 - val_loss: 0.1721 - val_acc: 0.9331\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1245 - acc: 0.9232 - val_loss: 0.1282 - val_acc: 0.9164\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0863 - acc: 0.9166 - val_loss: 0.0950 - val_acc: 0.9164\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0616 - acc: 0.9055 - val_loss: 0.0757 - val_acc: 0.9019\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0484 - acc: 0.9026 - val_loss: 0.0660 - val_acc: 0.9019\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0415 - acc: 0.9097 - val_loss: 0.0601 - val_acc: 0.9096\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0372 - acc: 0.9113 - val_loss: 0.0558 - val_acc: 0.9134\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0340 - acc: 0.9175 - val_loss: 0.0525 - val_acc: 0.9393\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0317 - acc: 0.9395 - val_loss: 0.0502 - val_acc: 0.9393\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0300 - acc: 0.9395 - val_loss: 0.0486 - val_acc: 0.9393\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0288 - acc: 0.9395 - val_loss: 0.0475 - val_acc: 0.9393\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0279 - acc: 0.9395 - val_loss: 0.0467 - val_acc: 0.9393\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0273 - acc: 0.9395 - val_loss: 0.0462 - val_acc: 0.9393\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0268 - acc: 0.9395 - val_loss: 0.0458 - val_acc: 0.9393\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0265 - acc: 0.9395 - val_loss: 0.0455 - val_acc: 0.9393\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9395 - val_loss: 0.0453 - val_acc: 0.9393\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9395 - val_loss: 0.0451 - val_acc: 0.9393\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9395 - val_loss: 0.0450 - val_acc: 0.9393\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9395 - val_loss: 0.0449 - val_acc: 0.9393\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9395 - val_loss: 0.0448 - val_acc: 0.9393\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0254 - acc: 0.9395 - val_loss: 0.0447 - val_acc: 0.9393\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9395 - val_loss: 0.0446 - val_acc: 0.9393\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9395 - val_loss: 0.0445 - val_acc: 0.9393\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9395 - val_loss: 0.0445 - val_acc: 0.9393\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9395 - val_loss: 0.0444 - val_acc: 0.9393\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9395 - val_loss: 0.0444 - val_acc: 0.9393\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9395 - val_loss: 0.0444 - val_acc: 0.9393\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9395 - val_loss: 0.0444 - val_acc: 0.9393\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0443 - val_acc: 0.9393\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 21s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 177/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 15s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 15s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0441 - val_acc: 0.9393\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0441 - val_acc: 0.9393\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 293/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0442 - val_acc: 0.9393\n",
      "15354/15354 [==============================] - 12s 748us/step - loss: 0.0442 - acc: 0.9393\n",
      "\n",
      "Test Accuracy: 0.9393\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-1.295844,1.3716305,1.3321664,1.393904,-1.4477409,-1.323191,1.4139165,-1.4675984,-1.4067535,-1.3292463,-0.5681114,0.58752114,0.529029,0.5821765,-0.47258282,-0.5157724,0.67310834,-0.52774096,-0.62607235,-0.2996048,-0.3328491,0.36658266,0.35701987,0.19911233,-0.5073847,-0.504685,0.4718681,-0.37416187,-0.2105338,-0.8085013,-0.51572084,0.43326953,0.5570538,0.5566771,-0.42532703,-0.44409978,0.23457359,-0.3621828,-0.48899382,-0.46569726,\n",
      "\n",
      "a_bias1: \n",
      "1.6089115,-1.6476921,-1.6667804,-1.56918,1.664113,1.6818275,-1.7179482,1.4694169,1.5863576,1.6095641,\n",
      "\n",
      "a_weight2: \n",
      "-2.1504588,1.9929075,2.0707831,1.9701425,-2.1256924,-2.1027968,2.0485156,-2.0112967,-2.0997527,-2.011014,\n",
      "\n",
      "a_bias2: \n",
      "0.2057041,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 4\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[1,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_noMPD_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_noMPD_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73006ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1951 - acc: 0.6719 - val_loss: 0.2124 - val_acc: 0.6950\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1777 - acc: 0.6939 - val_loss: 0.1840 - val_acc: 0.6950\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1502 - acc: 0.7095 - val_loss: 0.1504 - val_acc: 0.7582\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1183 - acc: 0.8645 - val_loss: 0.1194 - val_acc: 0.9161\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0903 - acc: 0.9157 - val_loss: 0.0968 - val_acc: 0.9127\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0703 - acc: 0.9048 - val_loss: 0.0832 - val_acc: 0.9021\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0580 - acc: 0.9044 - val_loss: 0.0763 - val_acc: 0.9043\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0512 - acc: 0.9041 - val_loss: 0.0733 - val_acc: 0.9038\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0476 - acc: 0.9038 - val_loss: 0.0719 - val_acc: 0.9039\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0455 - acc: 0.9041 - val_loss: 0.0709 - val_acc: 0.9043\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0442 - acc: 0.9044 - val_loss: 0.0701 - val_acc: 0.9045\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0433 - acc: 0.9046 - val_loss: 0.0694 - val_acc: 0.9046\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0426 - acc: 0.9048 - val_loss: 0.0688 - val_acc: 0.9047\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0421 - acc: 0.9049 - val_loss: 0.0684 - val_acc: 0.9048\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0416 - acc: 0.9058 - val_loss: 0.0680 - val_acc: 0.9068\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0413 - acc: 0.9079 - val_loss: 0.0677 - val_acc: 0.9094\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0410 - acc: 0.9100 - val_loss: 0.0675 - val_acc: 0.9106\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0408 - acc: 0.9110 - val_loss: 0.0673 - val_acc: 0.9119\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0407 - acc: 0.9118 - val_loss: 0.0671 - val_acc: 0.9124\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0405 - acc: 0.9124 - val_loss: 0.0671 - val_acc: 0.9131\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0404 - acc: 0.9128 - val_loss: 0.0670 - val_acc: 0.9133\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9130 - val_loss: 0.0670 - val_acc: 0.9138\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9133 - val_loss: 0.0669 - val_acc: 0.9137\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0402 - acc: 0.9135 - val_loss: 0.0669 - val_acc: 0.9140\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9137 - val_loss: 0.0669 - val_acc: 0.9142\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0401 - acc: 0.9138 - val_loss: 0.0669 - val_acc: 0.9142\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9139 - val_loss: 0.0669 - val_acc: 0.9143\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9139 - val_loss: 0.0669 - val_acc: 0.9143\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9141 - val_loss: 0.0669 - val_acc: 0.9148\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9143 - val_loss: 0.0669 - val_acc: 0.9148\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0400 - acc: 0.9143 - val_loss: 0.0670 - val_acc: 0.9148\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9144 - val_loss: 0.0669 - val_acc: 0.9148\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9144 - val_loss: 0.0670 - val_acc: 0.9149\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9145 - val_loss: 0.0670 - val_acc: 0.9149\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9145 - val_loss: 0.0670 - val_acc: 0.9153\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9148 - val_loss: 0.0670 - val_acc: 0.9153\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9148 - val_loss: 0.0670 - val_acc: 0.9153\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9148 - val_loss: 0.0670 - val_acc: 0.9154\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9148 - val_loss: 0.0670 - val_acc: 0.9154\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9148 - val_loss: 0.0670 - val_acc: 0.9154\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9149 - val_loss: 0.0670 - val_acc: 0.9154\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9149 - val_loss: 0.0671 - val_acc: 0.9154\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9149 - val_loss: 0.0671 - val_acc: 0.9154\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0399 - acc: 0.9149 - val_loss: 0.0671 - val_acc: 0.9156\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9150 - val_loss: 0.0671 - val_acc: 0.9154\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9150 - val_loss: 0.0671 - val_acc: 0.9154\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9151 - val_loss: 0.0671 - val_acc: 0.9154\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9151 - val_loss: 0.0671 - val_acc: 0.9156\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9151 - val_loss: 0.0671 - val_acc: 0.9156\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9151 - val_loss: 0.0671 - val_acc: 0.9156\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9152 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9156\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9152 - val_loss: 0.0671 - val_acc: 0.9159\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9159\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9154 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9152 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9157\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9153 - val_loss: 0.0671 - val_acc: 0.9159\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9154 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9155 - val_loss: 0.0672 - val_acc: 0.9157\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9154 - val_loss: 0.0671 - val_acc: 0.9159\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9155 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9155 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0672 - val_acc: 0.9158\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9160\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0672 - val_acc: 0.9158\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9156 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9160\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9160\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9160\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9160\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9157 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9158 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9161\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9158 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0398 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9159 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9160 - val_loss: 0.0671 - val_acc: 0.9163\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9160 - val_loss: 0.0670 - val_acc: 0.9163\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9160 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0671 - val_acc: 0.9166\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9166\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9162 - val_loss: 0.0670 - val_acc: 0.9168\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9163 - val_loss: 0.0670 - val_acc: 0.9168\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9165 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9164 - val_loss: 0.0669 - val_acc: 0.9172\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9166 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9165 - val_loss: 0.0669 - val_acc: 0.9168\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9165 - val_loss: 0.0669 - val_acc: 0.9172\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9167 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0397 - acc: 0.9168 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9168 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0669 - val_acc: 0.9175\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0668 - val_acc: 0.9175\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0668 - val_acc: 0.9175\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9171 - val_loss: 0.0668 - val_acc: 0.9175\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0668 - val_acc: 0.9175\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9170 - val_loss: 0.0668 - val_acc: 0.9175\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9171 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0668 - val_acc: 0.9178\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0667 - val_acc: 0.9178\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0667 - val_acc: 0.9178\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0396 - acc: 0.9174 - val_loss: 0.0667 - val_acc: 0.9178\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9175 - val_loss: 0.0667 - val_acc: 0.9178\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0396 - acc: 0.9176 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9176 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0396 - acc: 0.9176 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9176 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9176 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9177 - val_loss: 0.0667 - val_acc: 0.9180\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9177 - val_loss: 0.0666 - val_acc: 0.9183\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0395 - acc: 0.9179 - val_loss: 0.0666 - val_acc: 0.9185\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9180 - val_loss: 0.0666 - val_acc: 0.9182\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0395 - acc: 0.9180 - val_loss: 0.0666 - val_acc: 0.9185\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9180 - val_loss: 0.0666 - val_acc: 0.9185\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0395 - acc: 0.9180 - val_loss: 0.0666 - val_acc: 0.9185\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9180 - val_loss: 0.0666 - val_acc: 0.9185\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9181 - val_loss: 0.0666 - val_acc: 0.9187\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0665 - val_acc: 0.9187\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0666 - val_acc: 0.9187\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0665 - val_acc: 0.9187\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0665 - val_acc: 0.9187\n",
      "Epoch 177/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0665 - val_acc: 0.9187\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0395 - acc: 0.9182 - val_loss: 0.0665 - val_acc: 0.9187\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9183 - val_loss: 0.0665 - val_acc: 0.9188\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9184 - val_loss: 0.0665 - val_acc: 0.9188\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9184 - val_loss: 0.0665 - val_acc: 0.9188\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9184 - val_loss: 0.0664 - val_acc: 0.9188\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9184 - val_loss: 0.0664 - val_acc: 0.9189\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9186 - val_loss: 0.0664 - val_acc: 0.9188\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9187 - val_loss: 0.0664 - val_acc: 0.9191\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9187 - val_loss: 0.0664 - val_acc: 0.9191\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9187 - val_loss: 0.0664 - val_acc: 0.9191\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9187 - val_loss: 0.0664 - val_acc: 0.9191\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9187 - val_loss: 0.0663 - val_acc: 0.9191\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9188 - val_loss: 0.0663 - val_acc: 0.9193\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9189 - val_loss: 0.0663 - val_acc: 0.9193\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9189 - val_loss: 0.0663 - val_acc: 0.9193\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9189 - val_loss: 0.0663 - val_acc: 0.9193\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0394 - acc: 0.9189 - val_loss: 0.0663 - val_acc: 0.9193\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9189 - val_loss: 0.0663 - val_acc: 0.9194\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9190 - val_loss: 0.0663 - val_acc: 0.9194\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9190 - val_loss: 0.0662 - val_acc: 0.9194\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9190 - val_loss: 0.0662 - val_acc: 0.9194\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9190 - val_loss: 0.0662 - val_acc: 0.9194\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9191 - val_loss: 0.0662 - val_acc: 0.9194\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9191 - val_loss: 0.0662 - val_acc: 0.9196\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0662 - val_acc: 0.9196\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0662 - val_acc: 0.9196\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0662 - val_acc: 0.9196\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0662 - val_acc: 0.9196\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 15s 997us/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0661 - val_acc: 0.9196\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9192 - val_loss: 0.0661 - val_acc: 0.9196\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0393 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9196\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9196\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9197\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9197\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0393 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9197\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9193 - val_loss: 0.0661 - val_acc: 0.9197\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9193 - val_loss: 0.0660 - val_acc: 0.9196\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9199\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9199\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9198\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9198\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9198\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9199\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0660 - val_acc: 0.9199\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9194 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0659 - val_acc: 0.9199\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9195 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0392 - acc: 0.9196 - val_loss: 0.0659 - val_acc: 0.9200\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9196 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9196 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9196 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0392 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9201\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9202\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9202\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9202\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0658 - val_acc: 0.9202\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9197 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9202\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9203\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9203\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9203\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0657 - val_acc: 0.9203\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9198 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0391 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0656 - val_acc: 0.9203\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9203\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9203\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9203\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9203\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9204\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 293/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9200 - val_loss: 0.0655 - val_acc: 0.9205\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9199 - val_loss: 0.0654 - val_acc: 0.9205\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9200 - val_loss: 0.0654 - val_acc: 0.9205\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0390 - acc: 0.9200 - val_loss: 0.0654 - val_acc: 0.9205\n",
      "15354/15354 [==============================] - 12s 761us/step - loss: 0.0654 - acc: 0.9205\n",
      "\n",
      "Test Accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.82856274,-1.421014,2.096789,-2.469351,-2.014434,-2.5727239,-1.87438,-1.2982218,-0.604569,-2.2587905,-0.5897007,-1.0283772,1.4987825,-1.4566293,-0.94181675,-1.24539,-1.8414526,-1.2164552,-0.6959537,-1.1719025,-0.89940774,-2.388879,-0.48120996,0.2968213,-2.4093227,-0.81943995,1.6250992,-1.6270287,-1.5608367,-1.4383755,-0.86514026,0.53190154,1.8166553,-1.7739702,0.43993855,-0.8780083,-2.4171789,0.30429015,-0.13869753,-0.14844358,\n",
      "\n",
      "a_bias1: \n",
      "1.1775391,0.9755717,-0.8386388,0.70961547,0.6219927,0.49151036,0.94096816,1.1079215,1.2522259,0.6127696,\n",
      "\n",
      "a_weight2: \n",
      "-1.5166143,-1.9908054,2.6262863,-1.7310684,-1.7767453,-1.2760499,-2.3628402,-1.7539595,-1.7137336,-1.5042986,\n",
      "\n",
      "a_bias2: \n",
      "2.0325925,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 4\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_noCBF_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_noCBF_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70ca5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.1925 - acc: 0.6940 - val_loss: 0.2083 - val_acc: 0.6947\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1709 - acc: 0.6940 - val_loss: 0.1749 - val_acc: 0.6947\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1355 - acc: 0.8139 - val_loss: 0.1349 - val_acc: 0.9361\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0975 - acc: 0.9325 - val_loss: 0.1006 - val_acc: 0.9143\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0684 - acc: 0.9042 - val_loss: 0.0794 - val_acc: 0.9040\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0517 - acc: 0.9044 - val_loss: 0.0693 - val_acc: 0.9040\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0435 - acc: 0.9044 - val_loss: 0.0637 - val_acc: 0.9040\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0387 - acc: 0.9063 - val_loss: 0.0595 - val_acc: 0.9159\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0353 - acc: 0.9271 - val_loss: 0.0565 - val_acc: 0.9314\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0328 - acc: 0.9327 - val_loss: 0.0544 - val_acc: 0.9331\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0309 - acc: 0.9334 - val_loss: 0.0530 - val_acc: 0.9334\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0296 - acc: 0.9336 - val_loss: 0.0521 - val_acc: 0.9335\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0287 - acc: 0.9336 - val_loss: 0.0515 - val_acc: 0.9335\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0280 - acc: 0.9337 - val_loss: 0.0512 - val_acc: 0.9336\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0276 - acc: 0.9337 - val_loss: 0.0510 - val_acc: 0.9336\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0272 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9336\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0270 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0268 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0266 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0265 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0265 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9336\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9336\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0262 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0511 - val_acc: 0.9337\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.0260 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0510 - val_acc: 0.9337\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0509 - val_acc: 0.9337\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0259 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0507 - val_acc: 0.9337\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0507 - val_acc: 0.9337\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0507 - val_acc: 0.9337\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0507 - val_acc: 0.9336\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0258 - acc: 0.9338 - val_loss: 0.0506 - val_acc: 0.9336\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0506 - val_acc: 0.9336\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0506 - val_acc: 0.9336\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0506 - val_acc: 0.9336\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0505 - val_acc: 0.9336\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0505 - val_acc: 0.9336\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9338 - val_loss: 0.0504 - val_acc: 0.9336\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9338 - val_loss: 0.0504 - val_acc: 0.9336\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0256 - acc: 0.9338 - val_loss: 0.0503 - val_acc: 0.9337\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9338 - val_loss: 0.0503 - val_acc: 0.9337\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9338 - val_loss: 0.0503 - val_acc: 0.9337\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9339 - val_loss: 0.0502 - val_acc: 0.9337\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9339 - val_loss: 0.0502 - val_acc: 0.9338\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9340 - val_loss: 0.0501 - val_acc: 0.9340\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9341 - val_loss: 0.0501 - val_acc: 0.9340\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9343 - val_loss: 0.0500 - val_acc: 0.9342\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9344 - val_loss: 0.0500 - val_acc: 0.9345\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9346 - val_loss: 0.0500 - val_acc: 0.9345\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9346 - val_loss: 0.0499 - val_acc: 0.9347\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9349 - val_loss: 0.0498 - val_acc: 0.9350\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0254 - acc: 0.9351 - val_loss: 0.0498 - val_acc: 0.9350\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9352 - val_loss: 0.0497 - val_acc: 0.9353\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9354 - val_loss: 0.0497 - val_acc: 0.9355\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9356 - val_loss: 0.0496 - val_acc: 0.9355\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0253 - acc: 0.9357 - val_loss: 0.0496 - val_acc: 0.9357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9359 - val_loss: 0.0495 - val_acc: 0.9358\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9360 - val_loss: 0.0495 - val_acc: 0.9360\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0252 - acc: 0.9361 - val_loss: 0.0494 - val_acc: 0.9360\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9363 - val_loss: 0.0494 - val_acc: 0.9362\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0252 - acc: 0.9364 - val_loss: 0.0493 - val_acc: 0.9364\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9365 - val_loss: 0.0493 - val_acc: 0.9365\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9366 - val_loss: 0.0492 - val_acc: 0.9365\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9367 - val_loss: 0.0492 - val_acc: 0.9367\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9367\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9368\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9369 - val_loss: 0.0490 - val_acc: 0.9368\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9370 - val_loss: 0.0490 - val_acc: 0.9369\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9370 - val_loss: 0.0489 - val_acc: 0.9370\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9371 - val_loss: 0.0489 - val_acc: 0.9370\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9371 - val_loss: 0.0489 - val_acc: 0.9370\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9372 - val_loss: 0.0488 - val_acc: 0.9371\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9372 - val_loss: 0.0488 - val_acc: 0.9371\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9373 - val_loss: 0.0487 - val_acc: 0.9371\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9373 - val_loss: 0.0487 - val_acc: 0.9372\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9373 - val_loss: 0.0487 - val_acc: 0.9372\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9373 - val_loss: 0.0486 - val_acc: 0.9373\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9374 - val_loss: 0.0486 - val_acc: 0.9373\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9374 - val_loss: 0.0486 - val_acc: 0.9373\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0486 - val_acc: 0.9373\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0485 - val_acc: 0.9373\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0485 - val_acc: 0.9373\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0485 - val_acc: 0.9374\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0484 - val_acc: 0.9374\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9376 - val_loss: 0.0484 - val_acc: 0.9374\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9376 - val_loss: 0.0484 - val_acc: 0.9374\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0484 - val_acc: 0.9374\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0484 - val_acc: 0.9371\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9375 - val_loss: 0.0484 - val_acc: 0.9372\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9374 - val_loss: 0.0483 - val_acc: 0.9372\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9374 - val_loss: 0.0483 - val_acc: 0.9372\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9373 - val_loss: 0.0483 - val_acc: 0.9372\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9373 - val_loss: 0.0483 - val_acc: 0.9370\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9372 - val_loss: 0.0483 - val_acc: 0.9370\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9373 - val_loss: 0.0483 - val_acc: 0.9371\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9372 - val_loss: 0.0482 - val_acc: 0.9371\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9372 - val_loss: 0.0482 - val_acc: 0.9371\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9372 - val_loss: 0.0482 - val_acc: 0.9370\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9372 - val_loss: 0.0482 - val_acc: 0.9370\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9370\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9369\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9369\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9369\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9369\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9371 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9368\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0481 - val_acc: 0.9367\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9370 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9369 - val_loss: 0.0482 - val_acc: 0.9367\n",
      "15354/15354 [==============================] - 11s 738us/step - loss: 0.0482 - acc: 0.9367\n",
      "\n",
      "Test Accuracy: 0.9367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.4942238,-0.44646066,-0.4619281,-1.2009137,-0.5520075,0.60190696,-0.44057143,-0.9300643,-1.1852005,0.44341946,-1.6394073,-1.6592599,-1.7359452,-1.6747706,-1.5585438,1.7170956,-1.5453565,-1.8096927,-1.7781183,1.5948883,-1.0368524,-0.09476593,-0.680482,2.0099936,-1.0408032,1.5635912,-0.36867577,-2.7394533,-3.6579757,-0.1305134,-0.09028414,-0.9055324,-0.29725707,-4.829847,-0.14269313,-0.43035954,-0.69422543,1.0650403,1.4063447,1.323396,\n",
      "\n",
      "a_bias1: \n",
      "1.3597258,1.1779181,1.3062432,1.2052305,1.3227687,-1.1104517,1.2894887,1.1152706,1.0888325,-1.3047765,\n",
      "\n",
      "a_weight2: \n",
      "-2.0531278,-1.9574717,-1.9813257,-2.8519611,-1.9008535,2.434931,-1.9160799,-2.3830857,-2.6353679,2.5294714,\n",
      "\n",
      "a_bias2: \n",
      "1.5345296,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 4\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_noOEF_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_noOEF_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9635a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 20s 1ms/step - loss: 0.1932 - acc: 0.6895 - val_loss: 0.2081 - val_acc: 0.6943\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.1730 - acc: 0.6941 - val_loss: 0.1770 - val_acc: 0.6943\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.1431 - acc: 0.7237 - val_loss: 0.1419 - val_acc: 0.7830\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.1105 - acc: 0.9095 - val_loss: 0.1109 - val_acc: 0.9409\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 19s 1ms/step - loss: 0.0832 - acc: 0.9400 - val_loss: 0.0888 - val_acc: 0.9329\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0643 - acc: 0.9212 - val_loss: 0.0750 - val_acc: 0.9137\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0523 - acc: 0.9123 - val_loss: 0.0664 - val_acc: 0.9125\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0447 - acc: 0.9161 - val_loss: 0.0610 - val_acc: 0.9210\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0398 - acc: 0.9280 - val_loss: 0.0573 - val_acc: 0.9311\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0364 - acc: 0.9342 - val_loss: 0.0547 - val_acc: 0.9347\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0338 - acc: 0.9360 - val_loss: 0.0528 - val_acc: 0.9356\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0319 - acc: 0.9365 - val_loss: 0.0513 - val_acc: 0.9359\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0305 - acc: 0.9367 - val_loss: 0.0504 - val_acc: 0.9360\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0294 - acc: 0.9368 - val_loss: 0.0496 - val_acc: 0.9361\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0286 - acc: 0.9368 - val_loss: 0.0491 - val_acc: 0.9362\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0279 - acc: 0.9368 - val_loss: 0.0488 - val_acc: 0.9362\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0275 - acc: 0.9368 - val_loss: 0.0485 - val_acc: 0.9362\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0271 - acc: 0.9368 - val_loss: 0.0483 - val_acc: 0.9362\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0268 - acc: 0.9368 - val_loss: 0.0482 - val_acc: 0.9362\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0266 - acc: 0.9368 - val_loss: 0.0481 - val_acc: 0.9362\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0264 - acc: 0.9368 - val_loss: 0.0479 - val_acc: 0.9362\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0262 - acc: 0.9368 - val_loss: 0.0479 - val_acc: 0.9362\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0261 - acc: 0.9368 - val_loss: 0.0478 - val_acc: 0.9362\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0260 - acc: 0.9368 - val_loss: 0.0477 - val_acc: 0.9362\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0259 - acc: 0.9368 - val_loss: 0.0476 - val_acc: 0.9362\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0258 - acc: 0.9368 - val_loss: 0.0475 - val_acc: 0.9362\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9368 - val_loss: 0.0475 - val_acc: 0.9362\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0257 - acc: 0.9368 - val_loss: 0.0474 - val_acc: 0.9362\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0256 - acc: 0.9368 - val_loss: 0.0473 - val_acc: 0.9362\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0255 - acc: 0.9368 - val_loss: 0.0472 - val_acc: 0.9362\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9368 - val_loss: 0.0472 - val_acc: 0.9362\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9368 - val_loss: 0.0471 - val_acc: 0.9362\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9368 - val_loss: 0.0470 - val_acc: 0.9362\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9368 - val_loss: 0.0469 - val_acc: 0.9362\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0253 - acc: 0.9368 - val_loss: 0.0468 - val_acc: 0.9362\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9368 - val_loss: 0.0468 - val_acc: 0.9362\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9369 - val_loss: 0.0467 - val_acc: 0.9362\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9368 - val_loss: 0.0466 - val_acc: 0.9362\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9369 - val_loss: 0.0466 - val_acc: 0.9362\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9369 - val_loss: 0.0465 - val_acc: 0.9362\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0251 - acc: 0.9369 - val_loss: 0.0464 - val_acc: 0.9362\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9369 - val_loss: 0.0464 - val_acc: 0.9362\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9369 - val_loss: 0.0463 - val_acc: 0.9362\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9368 - val_loss: 0.0463 - val_acc: 0.9362\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9369 - val_loss: 0.0462 - val_acc: 0.9363\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9369 - val_loss: 0.0462 - val_acc: 0.9363\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0249 - acc: 0.9369 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9370 - val_loss: 0.0461 - val_acc: 0.9364\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9371 - val_loss: 0.0460 - val_acc: 0.9365\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9373 - val_loss: 0.0460 - val_acc: 0.9367\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9376 - val_loss: 0.0459 - val_acc: 0.9373\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9380 - val_loss: 0.0459 - val_acc: 0.9377\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0248 - acc: 0.9383 - val_loss: 0.0459 - val_acc: 0.9377\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9385 - val_loss: 0.0459 - val_acc: 0.9381\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9388 - val_loss: 0.0458 - val_acc: 0.9385\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9390 - val_loss: 0.0458 - val_acc: 0.9388\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9393 - val_loss: 0.0458 - val_acc: 0.9388\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9395 - val_loss: 0.0458 - val_acc: 0.9391\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9397 - val_loss: 0.0457 - val_acc: 0.9394\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9399 - val_loss: 0.0457 - val_acc: 0.9394\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0247 - acc: 0.9399 - val_loss: 0.0457 - val_acc: 0.9397\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9401 - val_loss: 0.0457 - val_acc: 0.9397\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9402 - val_loss: 0.0457 - val_acc: 0.9399\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9404 - val_loss: 0.0457 - val_acc: 0.9399\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9404 - val_loss: 0.0456 - val_acc: 0.9399\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9405 - val_loss: 0.0456 - val_acc: 0.9401\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9406 - val_loss: 0.0456 - val_acc: 0.9402\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9407 - val_loss: 0.0456 - val_acc: 0.9402\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9407 - val_loss: 0.0456 - val_acc: 0.9402\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9408 - val_loss: 0.0456 - val_acc: 0.9404\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9408 - val_loss: 0.0456 - val_acc: 0.9404\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9409 - val_loss: 0.0456 - val_acc: 0.9404\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9409 - val_loss: 0.0455 - val_acc: 0.9405\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9410 - val_loss: 0.0455 - val_acc: 0.9405\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9410 - val_loss: 0.0455 - val_acc: 0.9405\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9410 - val_loss: 0.0455 - val_acc: 0.9407\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9411 - val_loss: 0.0455 - val_acc: 0.9407\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0246 - acc: 0.9411 - val_loss: 0.0455 - val_acc: 0.9407\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9411 - val_loss: 0.0455 - val_acc: 0.9406\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9411 - val_loss: 0.0455 - val_acc: 0.9408\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9412 - val_loss: 0.0455 - val_acc: 0.9407\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9412 - val_loss: 0.0455 - val_acc: 0.9408\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9412 - val_loss: 0.0455 - val_acc: 0.9408\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9413 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9413 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9413 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9413 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9413 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0455 - val_acc: 0.9409\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9409\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9409\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9409\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9409\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9409\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9414 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9415 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9411\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0245 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0244 - acc: 0.9417 - val_loss: 0.0454 - val_acc: 0.9412\n",
      "15354/15354 [==============================] - 12s 750us/step - loss: 0.0454 - acc: 0.9412\n",
      "\n",
      "Test Accuracy: 0.9412\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.50057477,-0.69561183,0.6557979,-0.9069935,-0.58719724,-0.67514414,-0.38725027,-0.35711756,-0.40938288,-0.88295764,-1.5031918,-1.5328213,1.4345624,-1.5027584,-1.4504861,-1.5741382,-1.6315821,-1.3586533,-1.4481329,-1.4298806,-1.0599743,-0.94445854,0.9389331,-0.63878417,-0.9841735,-0.84173447,-1.1468085,-1.2753092,-1.1883692,-0.7378931,-0.8369839,-1.169548,1.1504332,-1.6188565,-0.9758886,-1.1529994,-0.69221026,-0.6340284,-0.7102781,-1.5448472,\n",
      "\n",
      "a_bias1: \n",
      "1.5543334,1.7350049,-1.6184772,1.50319,1.4922016,1.5412456,1.7252853,1.576176,1.6072465,1.571457,\n",
      "\n",
      "a_weight2: \n",
      "-2.4581642,-2.5618098,3.760627,-2.3773313,-2.3336868,-2.4017785,-2.5993443,-2.435203,-2.5166948,-2.3974345,\n",
      "\n",
      "a_bias2: \n",
      "2.7539406,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 4\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,3,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_noFLM_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_noFLM_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2ec803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1934 - acc: 0.6941 - val_loss: 0.2127 - val_acc: 0.6941\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1729 - acc: 0.7000 - val_loss: 0.1821 - val_acc: 0.7493\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1370 - acc: 0.9034 - val_loss: 0.1420 - val_acc: 0.9448\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0994 - acc: 0.9187 - val_loss: 0.1066 - val_acc: 0.8981\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0714 - acc: 0.8968 - val_loss: 0.0825 - val_acc: 0.8967\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0539 - acc: 0.8968 - val_loss: 0.0679 - val_acc: 0.9033\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0436 - acc: 0.9185 - val_loss: 0.0595 - val_acc: 0.9321\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0376 - acc: 0.9373 - val_loss: 0.0545 - val_acc: 0.9404\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0338 - acc: 0.9405 - val_loss: 0.0513 - val_acc: 0.9415\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0313 - acc: 0.9412 - val_loss: 0.0493 - val_acc: 0.9418\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0295 - acc: 0.9413 - val_loss: 0.0480 - val_acc: 0.9419\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0282 - acc: 0.9414 - val_loss: 0.0471 - val_acc: 0.9419\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0274 - acc: 0.9414 - val_loss: 0.0465 - val_acc: 0.9419\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0267 - acc: 0.9414 - val_loss: 0.0461 - val_acc: 0.9419\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0263 - acc: 0.9415 - val_loss: 0.0458 - val_acc: 0.9419\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0260 - acc: 0.9415 - val_loss: 0.0456 - val_acc: 0.9419\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0257 - acc: 0.9415 - val_loss: 0.0455 - val_acc: 0.9419\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9415 - val_loss: 0.0453 - val_acc: 0.9419\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0254 - acc: 0.9415 - val_loss: 0.0452 - val_acc: 0.9420\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0252 - acc: 0.9415 - val_loss: 0.0451 - val_acc: 0.9420\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0251 - acc: 0.9415 - val_loss: 0.0450 - val_acc: 0.9420\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9415 - val_loss: 0.0450 - val_acc: 0.9420\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0250 - acc: 0.9416 - val_loss: 0.0449 - val_acc: 0.9420\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0249 - acc: 0.9416 - val_loss: 0.0448 - val_acc: 0.9420\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9416 - val_loss: 0.0447 - val_acc: 0.9420\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0248 - acc: 0.9416 - val_loss: 0.0446 - val_acc: 0.9421\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9416 - val_loss: 0.0446 - val_acc: 0.9421\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0247 - acc: 0.9416 - val_loss: 0.0445 - val_acc: 0.9421\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9416 - val_loss: 0.0444 - val_acc: 0.9421\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0246 - acc: 0.9416 - val_loss: 0.0443 - val_acc: 0.9421\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0443 - val_acc: 0.9421\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0245 - acc: 0.9416 - val_loss: 0.0442 - val_acc: 0.9421\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0441 - val_acc: 0.9421\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0441 - val_acc: 0.9421\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0244 - acc: 0.9416 - val_loss: 0.0440 - val_acc: 0.9421\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9416 - val_loss: 0.0440 - val_acc: 0.9421\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9416 - val_loss: 0.0439 - val_acc: 0.9421\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0243 - acc: 0.9416 - val_loss: 0.0439 - val_acc: 0.9422\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9417 - val_loss: 0.0438 - val_acc: 0.9422\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9417 - val_loss: 0.0438 - val_acc: 0.9423\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0242 - acc: 0.9418 - val_loss: 0.0437 - val_acc: 0.9426\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0242 - acc: 0.9421 - val_loss: 0.0437 - val_acc: 0.9429\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9425 - val_loss: 0.0437 - val_acc: 0.9432\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9429 - val_loss: 0.0437 - val_acc: 0.9437\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9432 - val_loss: 0.0436 - val_acc: 0.9439\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9435 - val_loss: 0.0436 - val_acc: 0.9442\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0241 - acc: 0.9437 - val_loss: 0.0436 - val_acc: 0.9443\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0241 - acc: 0.9439 - val_loss: 0.0436 - val_acc: 0.9445\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9441 - val_loss: 0.0436 - val_acc: 0.9447\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9443 - val_loss: 0.0435 - val_acc: 0.9448\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9445 - val_loss: 0.0435 - val_acc: 0.9450\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9445 - val_loss: 0.0435 - val_acc: 0.9450\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9446 - val_loss: 0.0435 - val_acc: 0.9451\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0240 - acc: 0.9447 - val_loss: 0.0435 - val_acc: 0.9453\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9448 - val_loss: 0.0435 - val_acc: 0.9453\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9449 - val_loss: 0.0435 - val_acc: 0.9454\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0240 - acc: 0.9450 - val_loss: 0.0435 - val_acc: 0.9454\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9450 - val_loss: 0.0435 - val_acc: 0.9454\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9450 - val_loss: 0.0435 - val_acc: 0.9453\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 15s 1ms/step - loss: 0.0239 - acc: 0.9450 - val_loss: 0.0435 - val_acc: 0.9454\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9451 - val_loss: 0.0435 - val_acc: 0.9454\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9451 - val_loss: 0.0435 - val_acc: 0.9455\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9451 - val_loss: 0.0435 - val_acc: 0.9455\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9451 - val_loss: 0.0435 - val_acc: 0.9456\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9456\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9456\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9456\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 15s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9456\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9452 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0239 - acc: 0.9453 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9457\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0435 - val_acc: 0.9458\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9458\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9454 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 18s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0238 - acc: 0.9455 - val_loss: 0.0436 - val_acc: 0.9459\n",
      "15354/15354 [==============================] - 11s 735us/step - loss: 0.0436 - acc: 0.9459\n",
      "\n",
      "Test Accuracy: 0.9459\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.80455256,0.3031507,-0.47928935,-0.5806617,-0.62186265,0.42176643,-0.98664474,0.6768777,-0.3701626,0.5802003,-1.4142972,1.1133622,-1.2387223,-1.3753422,-1.2757181,1.3010061,-1.4227165,1.3460217,-1.0670004,1.3287574,-0.53727096,1.0760974,-0.96269417,-0.8250807,-0.7754965,1.0192771,-0.35564744,0.6697327,-1.0161769,0.83291245,-1.4071016,0.4915112,-0.5835831,-0.7575397,-0.9695984,0.44173503,-2.140747,1.1277405,-0.6422484,0.72527415,\n",
      "\n",
      "a_bias1: \n",
      "1.687396,-1.8737473,1.8302389,1.8469259,1.8458159,-1.8367783,1.6501355,-1.7968379,1.8915614,-1.776964,\n",
      "\n",
      "a_weight2: \n",
      "-2.5078123,2.0677612,-2.555755,-2.5843408,-2.4479768,2.043091,-2.5709012,2.128886,-2.470867,2.0457191,\n",
      "\n",
      "a_bias2: \n",
      "0.22681466,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 4\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,3,5,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights, sample_weight=sample_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_noPPS_withsamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_noPPS_withsamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96991ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.2444 - acc: 0.4521 - val_loss: 0.2433 - val_acc: 0.6671\n",
      "Epoch 2/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.2179 - acc: 0.7156 - val_loss: 0.2157 - val_acc: 0.7256\n",
      "Epoch 3/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1791 - acc: 0.8455 - val_loss: 0.1772 - val_acc: 0.8741\n",
      "Epoch 4/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.1416 - acc: 0.8778 - val_loss: 0.1401 - val_acc: 0.8790\n",
      "Epoch 5/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.1110 - acc: 0.8803 - val_loss: 0.1106 - val_acc: 0.8798\n",
      "Epoch 6/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0887 - acc: 0.8835 - val_loss: 0.0901 - val_acc: 0.8879\n",
      "Epoch 7/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0742 - acc: 0.8972 - val_loss: 0.0769 - val_acc: 0.9008\n",
      "Epoch 8/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0648 - acc: 0.9044 - val_loss: 0.0681 - val_acc: 0.9085\n",
      "Epoch 9/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0586 - acc: 0.9098 - val_loss: 0.0622 - val_acc: 0.9090\n",
      "Epoch 10/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0542 - acc: 0.9092 - val_loss: 0.0582 - val_acc: 0.9116\n",
      "Epoch 11/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0513 - acc: 0.9228 - val_loss: 0.0554 - val_acc: 0.9262\n",
      "Epoch 12/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0492 - acc: 0.9275 - val_loss: 0.0534 - val_acc: 0.9273\n",
      "Epoch 13/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0477 - acc: 0.9261 - val_loss: 0.0520 - val_acc: 0.9250\n",
      "Epoch 14/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0466 - acc: 0.9254 - val_loss: 0.0510 - val_acc: 0.9249\n",
      "Epoch 15/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0458 - acc: 0.9245 - val_loss: 0.0502 - val_acc: 0.9239\n",
      "Epoch 16/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0452 - acc: 0.9246 - val_loss: 0.0495 - val_acc: 0.9242\n",
      "Epoch 17/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0447 - acc: 0.9252 - val_loss: 0.0491 - val_acc: 0.9247\n",
      "Epoch 18/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0443 - acc: 0.9257 - val_loss: 0.0486 - val_acc: 0.9253\n",
      "Epoch 19/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0440 - acc: 0.9261 - val_loss: 0.0484 - val_acc: 0.9256\n",
      "Epoch 20/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0438 - acc: 0.9264 - val_loss: 0.0481 - val_acc: 0.9259\n",
      "Epoch 21/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0436 - acc: 0.9266 - val_loss: 0.0478 - val_acc: 0.9261\n",
      "Epoch 22/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0434 - acc: 0.9268 - val_loss: 0.0477 - val_acc: 0.9263\n",
      "Epoch 23/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0433 - acc: 0.9270 - val_loss: 0.0475 - val_acc: 0.9265\n",
      "Epoch 24/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0432 - acc: 0.9273 - val_loss: 0.0474 - val_acc: 0.9268\n",
      "Epoch 25/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0431 - acc: 0.9275 - val_loss: 0.0472 - val_acc: 0.9270\n",
      "Epoch 26/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0430 - acc: 0.9277 - val_loss: 0.0471 - val_acc: 0.9271\n",
      "Epoch 27/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0429 - acc: 0.9278 - val_loss: 0.0470 - val_acc: 0.9273\n",
      "Epoch 28/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0429 - acc: 0.9279 - val_loss: 0.0470 - val_acc: 0.9274\n",
      "Epoch 29/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0428 - acc: 0.9280 - val_loss: 0.0470 - val_acc: 0.9274\n",
      "Epoch 30/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0428 - acc: 0.9281 - val_loss: 0.0469 - val_acc: 0.9275\n",
      "Epoch 31/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0428 - acc: 0.9281 - val_loss: 0.0468 - val_acc: 0.9275\n",
      "Epoch 32/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0427 - acc: 0.9282 - val_loss: 0.0468 - val_acc: 0.9276\n",
      "Epoch 33/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0427 - acc: 0.9282 - val_loss: 0.0467 - val_acc: 0.9276\n",
      "Epoch 34/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0427 - acc: 0.9283 - val_loss: 0.0469 - val_acc: 0.9276\n",
      "Epoch 35/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0427 - acc: 0.9283 - val_loss: 0.0467 - val_acc: 0.9277\n",
      "Epoch 36/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0427 - acc: 0.9283 - val_loss: 0.0467 - val_acc: 0.9277\n",
      "Epoch 37/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9283 - val_loss: 0.0468 - val_acc: 0.9277\n",
      "Epoch 38/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9283 - val_loss: 0.0466 - val_acc: 0.9277\n",
      "Epoch 39/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9284 - val_loss: 0.0466 - val_acc: 0.9277\n",
      "Epoch 40/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0426 - acc: 0.9284 - val_loss: 0.0466 - val_acc: 0.9277\n",
      "Epoch 41/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9284 - val_loss: 0.0466 - val_acc: 0.9278\n",
      "Epoch 42/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9284 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 43/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9285 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 44/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0426 - acc: 0.9285 - val_loss: 0.0466 - val_acc: 0.9278\n",
      "Epoch 45/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0426 - acc: 0.9285 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 46/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9285 - val_loss: 0.0466 - val_acc: 0.9278\n",
      "Epoch 47/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9285 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 48/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9285 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 49/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9286 - val_loss: 0.0466 - val_acc: 0.9280\n",
      "Epoch 50/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9286 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 51/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9286 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 52/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9287 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 53/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9286 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 54/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9287 - val_loss: 0.0466 - val_acc: 0.9280\n",
      "Epoch 55/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9287 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 56/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9288 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 57/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9286 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 58/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9289 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 59/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9287 - val_loss: 0.0464 - val_acc: 0.9280\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9289 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 61/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9288 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 62/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 63/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 64/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9289 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 65/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9288 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 66/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 67/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 68/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 69/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 70/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 71/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 72/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9280\n",
      "Epoch 73/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 74/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 75/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 76/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 77/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 78/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 79/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 80/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 81/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 82/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 83/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 84/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 85/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 86/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 87/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0462 - val_acc: 0.9301\n",
      "Epoch 88/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9295 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 89/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9290 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 90/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 91/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0465 - val_acc: 0.9280\n",
      "Epoch 92/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 93/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9291 - val_loss: 0.0463 - val_acc: 0.9301\n",
      "Epoch 94/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 95/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 96/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 97/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 98/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 99/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 100/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 101/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9301\n",
      "Epoch 102/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 103/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0425 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 104/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 105/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 106/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 107/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 108/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 109/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 110/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 111/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 112/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 113/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 114/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0425 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 115/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9292 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 116/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 117/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 118/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 120/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 121/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 122/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 123/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9301\n",
      "Epoch 124/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9286\n",
      "Epoch 125/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 126/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9292 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 127/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 128/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 129/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 130/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 131/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 132/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9301\n",
      "Epoch 133/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 134/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 135/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 136/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 137/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 138/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 139/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 140/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 141/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 142/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 143/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 144/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 145/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 146/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 147/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 148/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9301\n",
      "Epoch 149/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 150/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 151/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 152/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 153/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 154/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 155/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 156/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 157/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 158/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 159/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 160/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 161/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 162/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 163/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 164/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 165/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 166/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9286\n",
      "Epoch 167/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9292 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 168/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 169/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 170/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 171/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 172/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 173/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 174/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 175/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 176/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9299 - val_loss: 0.0465 - val_acc: 0.9281\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9301\n",
      "Epoch 178/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 179/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 180/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 181/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 182/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 183/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 184/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9292 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 185/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 186/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 187/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 188/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 189/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 190/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 191/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9298 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 192/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9292 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 193/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 194/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 195/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 196/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 197/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 198/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 199/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 200/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 201/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 202/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 203/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 204/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 205/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 206/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 207/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 208/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 209/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 210/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9281\n",
      "Epoch 211/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 212/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 213/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 214/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 215/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 216/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 217/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 218/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 219/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9298 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 220/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 221/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 222/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 223/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 224/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 225/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 226/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 227/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 228/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 229/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 230/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 231/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 232/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 233/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 234/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 236/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 237/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 238/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 239/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 240/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 241/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 242/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 243/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 244/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 245/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 246/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9299 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 247/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 248/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 249/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 250/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 251/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 252/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 253/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 254/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 255/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 256/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 257/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 258/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 259/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 260/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 261/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 262/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 263/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 264/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 265/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 266/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 267/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 268/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 269/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 270/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 271/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 272/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 273/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 274/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 275/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 276/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 277/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 278/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 279/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 280/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 281/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 282/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 283/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 284/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0464 - val_acc: 0.9281\n",
      "Epoch 285/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 286/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9296 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 287/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9300 - val_loss: 0.0464 - val_acc: 0.9281\n",
      "Epoch 288/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 289/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 290/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 291/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 292/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9302\n",
      "Epoch 294/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 295/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0464 - val_acc: 0.9287\n",
      "Epoch 296/300\n",
      "15354/15354 [==============================] - 17s 1ms/step - loss: 0.0424 - acc: 0.9293 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 297/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9295 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 298/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0463 - val_acc: 0.9287\n",
      "Epoch 299/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9294 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "Epoch 300/300\n",
      "15354/15354 [==============================] - 16s 1ms/step - loss: 0.0424 - acc: 0.9297 - val_loss: 0.0462 - val_acc: 0.9287\n",
      "15354/15354 [==============================] - 12s 752us/step - loss: 0.0462 - acc: 0.9287\n",
      "\n",
      "Test Accuracy: 0.9287\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAJoCAYAAACa8MCMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABe0klEQVR4nO3dd3wUdf7H8fdkk2waSaghtCRIEQRBwAJRwUIUFAXlB6KnoJ4eh+UQLKfYQE88VBRR8O5QsYMKomePUkRBBETlAAlC6MEQShohZff7+yNmYUkCATYZmLyej8c8sjs75bPfmWTf+U5ZyxhjBAAA4BBBdhcAAAAQSIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQboALTp0+XZVlatmyZ3aUctV69eqlXr152l+EYe/fuVYMGDTRjxoxyr3377bcaMmSIWrRoIbfbrcjISJ122mkaPXq0fv31VxuqrR5TpkzR9OnTq2XZL7/8spo2bar8/PxqWT5qJ8IN4DBTpkzRlClT7C7DMcaOHasmTZpo8ODBfuMffPBBnXfeedq0aZMefPBBff7555ozZ45uuukmpaamql27dvJ4PDZVHVjVGW6GDh2qyMhITZgwoVqWj9op2O4CAFTOGKP9+/crPDy8yvO0b9++GiuyV3FxsSzLUnBwzfzp2r17t/71r3/p2WeflWVZvvHvvPOO/vGPf2j48OGaMmWK32u9e/fWqFGjam3APNptFBwcrL/85S967LHHdN999ykiIqKaK0RtQM8NcBzWrVuna6+9Vo0aNZLb7Va7du304osv+k2zf/9+jR49Wp07d1ZMTIzq1aun7t2768MPPyy3PMuydPvtt+ull15Su3bt5Ha79dprr/kOk82bN09//etf1aBBA9WvX19XXXWVtm/f7reMQw9Lbdy4UZZl6emnn9bEiROVlJSkqKgode/eXd9//325Gv7zn/+oTZs2crvdat++vd5++20NGzZMiYmJVWqTt99+W927d1dUVJSioqLUuXNnvfzyy77XExMTNWzYsHLzHVr3/PnzZVmW3njjDY0ePVpNmzaV2+3WqlWrZFmW3zLLfPbZZ7IsSx999JFvXFW2UWWmT5+ukpKScr02jz/+uBo0aFAu9JSxLEu33XabXC6X3/ivvvpKF110kaKjoxUREaHk5GR9/fXX5eb/9ttvddFFF6lOnTqKiIhQjx499Mknn5SrzbIszZ07V7fccovq16+v6Oho3XDDDcrPz9eOHTs0aNAgxcbGKj4+XnfffbeKi4v9llFUVKTHH39cp556qtxutxo2bKgbb7xRO3fu9E2TmJioVatWacGCBbIsS5Zl+faFyrbRb7/9puDgYI0fP77ce/vmm29kWZbee+8937jrrrtOOTk5FR76A46JAVDOq6++aiSZpUuXVjrNqlWrTExMjOnYsaN5/fXXzZdffmlGjx5tgoKCzKOPPuqbbu/evWbYsGHmjTfeMHPnzjWff/65ufvuu01QUJB57bXX/JYpyTRt2tScfvrp5u233zZz5841//vf/3z1tGzZ0txxxx3miy++MNOmTTN169Y1F1xwgd8yevbsaXr27Ol7np6ebiSZxMREc+mll5o5c+aYOXPmmI4dO5q6deuavXv3+qb917/+ZSSZq6++2nz88cfmrbfeMm3atDEJCQkmISHhiO320EMPGUnmqquuMu+995758ssvzcSJE81DDz3kmyYhIcEMHTq03LyH1j1v3jxfewwcONB89NFH5uOPPza7du0yZ5xxhklOTi63jEGDBplGjRqZ4uLio9pGlbnwwgvNWWed5Tdu27ZtRpIZMmTIEec/2BtvvGEsyzL9+/c3s2fPNv/973/N5Zdfblwul/nqq698082fP9+EhISYrl27mpkzZ5o5c+aYlJQUY1mWmTFjhm+6sn0iKSnJjB492nz55Zfmn//8p3G5XGbIkCGmS5cu5vHHHzepqanmvvvuM5LMM88845vf4/GYSy+91ERGRpqxY8ea1NRUM23aNNO0aVPTvn17s2/fPmOMMT/++KNp2bKlOeOMM8zixYvN4sWLzY8//miMOfw2GjBggGnRooUpKSnxa4f/+7//M02aNPFtozLt2rUzV1111VG1KVAZwg1QgaqEm0suucQ0a9bMZGdn+42//fbbTVhYmNm9e3eF85WUlJji4mJz8803mzPOOMPvNUkmJiam3Lxl9YwYMcJv/IQJE4wkk5GR4RtXWbjp2LGj3wfNDz/8YCSZd955xxhT+mHXuHFjc/bZZ/utY9OmTSYkJOSI4WbDhg3G5XKZ66677rDTHW24Of/888tN+/zzzxtJZu3atb5xu3fvNm6324wePdo37li3UZmIiAgzfPhwv3Hff/+9kWT+/ve/l5u+bNuWDV6v1xhjTH5+vqlXr57p16+f3/Qej8d06tTJL0Cdc845plGjRiY3N9dvuR06dDDNmjXzLbNsn7jjjjv8ltm/f38jyUycONFvfOfOnU2XLl18z9955x0jycyaNctvuqVLlxpJZsqUKb5xp512mt+2KXO4bVT22gcffOAbt23bNhMcHGzGjh1bbvrrrrvOxMXFlRsPHAsOSwHHYP/+/fr66681YMAARUREqKSkxDf07dtX+/fv9zvk89577yk5OVlRUVEKDg5WSEiIXn75Za1Zs6bcsi+88ELVrVu3wvVeccUVfs9PP/10SdKmTZuOWPNll13md5jk0HnXrl3rO5RxsBYtWig5OfmIy09NTZXH49Ftt912xGmPxtVXX11u3HXXXSe32+13kus777yjwsJC3XjjjZKOfhsdau/evdq3b58aNWpU5Vrr16+vkJAQ3zBr1ixJ0qJFi7R7924NHTrUrw6v16tLL71US5cuVX5+vvLz87VkyRINHDhQUVFRvuW6XC5df/312rp1q9auXeu3zssvv9zvebt27SSVbu9Dxx+8n3z88ceKjY1Vv379/Grq3LmzGjdurPnz51f5fVe0jXr16qVOnTr5HQJ86aWXZFmWbr311nLTN2rUSJmZmSopKanyeoHKEG6AY7Br1y6VlJRo8uTJfh9mISEh6tu3ryQpKytLkjR79mwNGjRITZs21ZtvvqnFixdr6dKluummm7R///5yy46Pj690vfXr1/d77na7JUkFBQVHrPlI8+7atUuSFBcXV27eisYdquw8jWbNmh1x2qNRUXvUq1dPV1xxhV5//XXfFUnTp0/XWWedpdNOO03S0W2jipS1S1hYmN/45s2bS6o4UM6fP19Lly7VSy+95Df+999/lyQNHDiwXC3//Oc/ZYzR7t27tWfPHhljKnzPTZo08b2vQ9viYKGhoZWOP3h/+/3337V3716FhoaWq2nHjh2HbZtDVbbP3nnnnfr666+1du1aFRcX6z//+Y8GDhyoxo0bl5s2LCzMdwI9cLy4Wgo4BnXr1vX9N11ZT0VSUpIk6c0331RSUpJmzpzpd/JpYWFhhfNVdIJqTSgLP2UfxAfbsWPHEedv2LChJGnr1q2+AFCRsLCwCt97VlaWGjRoUG58Ze1x44036r333lNqaqpatGihpUuXaurUqb7Xj2YbVaSsPXbv3u03vkmTJjrttNOUmpqq/fv3+4Wfzp07S5Ly8vL85il7X5MnT9Y555xT4fri4uJUXFysoKAgZWRklHu97MTxitroWJSdlP75559X+HqdOnWqvKzKttG1116r++67Ty+++KLOOecc7dixo9JtsXv3brndbr8eK+BYEW6AYxAREaELLrhAK1as0Omnn+77b7kilmUpNDTU7wNgx44dFV4tZae2bduqcePGevfddzVq1Cjf+M2bN2vRokW+noPKpKSkyOVyaerUqerevXul0yUmJuqXX37xG5eWlqa1a9ce1Qd3SkqKmjZtqldffVUtWrRQWFiYhgwZ4nv9aLZRRUJDQ9WyZUutX7++3GtjxozRtddeq1GjRunFF188YiBNTk5WbGysVq9erdtvv/2w6zz77LM1e/ZsPf30075bAHi9Xr355ptq1qyZ2rRpc1TvozKXX365ZsyYIY/Ho7PPPvuw07rd7ir1Dh4qLCxMt956q1544QUtWrRInTt3rvQQ54YNGxx9GwPULMINcBhz587Vxo0by43v27evJk2apHPPPVfnnXee/vrXvyoxMVG5ubn67bff9N///ldz586VVPohMnv2bI0YMUIDBw7Uli1b9Nhjjyk+Pl7r1q2r4XdUuaCgII0dO1Z/+ctfNHDgQN10003au3evxo4dq/j4eAUFHf4odmJioh544AE99thjKigo0JAhQxQTE6PVq1crKytLY8eOlSRdf/31+tOf/qQRI0bo6quv1qZNmzRhwgRfz09VuVwu3XDDDZo4caKio6N11VVXKSYmxm+aqm6jyvTq1UufffZZufFDhgzRqlWr9I9//EM///yzhg0bptatW8vr9WrLli164403JB3o/YiKitLkyZM1dOhQ7d69WwMHDlSjRo20c+dO/fzzz9q5c6ev12n8+PHq3bu3LrjgAt19990KDQ3VlClT9L///U/vvPNOwHr2rrnmGr311lvq27ev/va3v+mss85SSEiItm7dqnnz5unKK6/UgAEDJEkdO3bUjBkzNHPmTLVs2VJhYWHq2LFjldYzYsQITZgwQcuXL9e0adMqnMbr9eqHH37QzTffHJD3BnC1FFCBsitRKhvS09ONMaVXIt10002madOmJiQkxDRs2ND06NHDPP74437Le/LJJ01iYqJxu92mXbt25j//+Y955JFHzKG/gpLMbbfdVmk9h169VXZFyrx583zjKrta6qmnniq3XEnmkUce8Rv373//27Rq1cqEhoaaNm3amFdeecVceeWV5a7sqszrr79uzjzzTBMWFmaioqLMGWecYV599VXf616v10yYMMG0bNnShIWFmW7dupm5c+dWerXUe++9V+m60tLSfNskNTW1wmmquo0q8vXXXxtJ5ocffqjw9W+++cYMHjzYNGvWzISEhJiIiAjTvn1789e//tUsW7as3PQLFiwwl112malXr54JCQkxTZs2NZdddlm597hw4UJz4YUXmsjISBMeHm7OOecc89///tdvmsr2ibL9aufOnX7jhw4daiIjI/3GFRcXm6efftp06tTJt71OPfVU85e//MWsW7fON93GjRtNSkqKqVOnjpHku3KuKtvIGGN69epl6tWr57u8/FBl7bx8+fLDLgeoKssYY2oyTAE4uezdu1dt2rRR//799e9//9vucmrc6aefruTkZL/zeVB1mZmZSkhI0B133FHpVyxcf/312rBhg7777rsarg5ORbgB4LNjxw794x//0AUXXKD69etr06ZNevbZZ/Xrr79q2bJlviuRapPPP/9cAwYM0Lp16wJ+JZiTbd26VRs2bNBTTz2luXPnKi0tTU2bNi033fr169WuXTvNnTtX5557rg2Vwom4FByAj9vt1saNGzVixAj17t1bd955p+Li4jR//vxaGWwk6dJLL9VTTz2l9PR0u0s5qUybNk29evXSqlWr9NZbb1UYbKTSE9ZfeOEFgg0Cip4bAADgKPTcAAAARyHcAAAARyHcAAAAR6l1N/Hzer3avn276tSpY9tt7gEAwNExxig3N1dNmjQ54k1Fa1242b59+2G/9wYAAJy4tmzZcsTbMtS6cFN2O/QtW7YoOjra5moAAEBV5OTkqHnz5lX6UtdaF27KDkVFR0cTbgAAOMlU5ZQSTigGAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAACOQrgBAiwvL0/GmMNOk5ubK4/HU+Vl5uTkqLi4+HhLOy65ubnat2/fUc1jjFFWVtYR2+N4ZGVlHVVb2qW4WCop8So7O7tK0+fk5ByxvXNzc//Y3w48LmOM0e+//37YtjfGKDMzU16vt2pv4hhkZWX59l1jSocTUXZ2dpX2b6/XW2G7GmO0Y8eOSts7Ly9POTk5ftNnZGT47bv5+flV3j8kqaCgQHv27Kny9JUvR8rNLX1cWFioVatWadWqVSooKPBNU1RUpMzMzCotzxgpP/+4yzoute5bwU90mZleNWwYpCp86elhlZSU7lx5eVJentHevcXKzi7W3r1FyskpUn5+kYqKilRcXKTi4hJ5vUYej1der/njsTno8YHxBw+l01T8mtfrlTHGb/B6yx57/cZ5PKWPPR6v8vK2aN++HYqISJJUoMLC7QoJSVBwcH15PAXKz9+g4uJsWZZLUVEt5XY3kGVZMsaosPB37du3WR6PVx6PVPnf6yCFhSXIsiwVFKTLmBJJMfJ6W6ikZLuM2f1H+1tyuaIVGtpCxcUZKinZJansj7P54/GBP2TGGO3bt0wFBUsVFtZRMTHXq7h4u4wpVlBQpEJCklRSkqn8/C9VUPCdXK4miozsI8ty+/7gH/x3sexxcfEqFRYuUFBQA4WFXS7LilBIiGRZpdvYsqTQ0NIhKEh+yzr4w6SiZR+somnLfpaUbFFh4WeSQuR295NlNVBwsBQSIhUVlU7ncpUOllX63Ov1qqBgnoqL1yokpI3c7l4q+3+qovWX7fMHf+Pvwb8HFT0uKFiiwsIf5XI1UUREiiwrtML3dbhxluU/SPpjXy3dh7xe+R4bU9rOZe/b6z247vKPywavN1R5ec0kvSljVsnt7iK3+0xJVrntVDr9Zu3b94UsK1SW1VehofX+GF/6u21ZksuVocLCzyW5JJ0paYkkS0FBfRUWVl/FxQtUXPybXK6WCg7uJa/XJY+ndBtFREiWZbRv33cqKlqj4OAERURcKGOCfe1z6D5gWaX7l2VZKipqLq83UmFh6ZKK/mibsjYzf7SLkcfzk0pKlikoqKGCgy9VUVGYpNIagoIO7DMu14F1Hfx7W5V99sDvYuXbuKLAcfAor3eLvN6vJLkVFHS5pHqVTO+VMV9JSpfUWtK5Kt2nvbKsBTJmg1yulrKsniopCVJYWOn7LCrKUknJ55I8Cg7ureDgeHk836q4OE2W1UzSRbKsHHm9n0kqUlDQRXK5Wvja6NDPA49HKioqmz5fLlcvBQW1PGSfKw3U0oG2DgqSpHAVFbVUaOhuBQVtV2GhkcfTRFIDhYevVGHhB/J6ywJTtIKC+srrdcmyPpcxuxQU1E1BQZ0VHCwFB5f9vhu/34WCAik6OkZ79jxTfqPVEMtU579UJ6CcnBzFxMQoOztb0dHRdpfjM2nSJD3xxH+UmblWERH9ddllo9WtW4wuu6y1WrUK1v790rp1BVqyZL1WrEjTpk27tGtXtnJzs5Wfv1cFBdkqLMxWcfFeeTzZMiZb0l5J+ZLs/Y8fAHAyiZZkSap6L9KhLCteXu/2gFUkHd3nN+HmBLBjxw7Fx8dX8modSc0kZag0rARGUJBblhWioKBQWVawLCvoj/+YrQp+lr528PjSIaiCcaXPg4KCyi3rcPNYlqWgIEt16sQpOjpeu3dvkMsVpqio5srL26iioly5XCGqXz9JkZH1VVJSqJ07f1NBwYFu3oiIeqpfP0lud6iCgsr+yyz/3j2eImVmbpAxRnFxpyg42K19+7K0d+8mNWjQVDExjf/479EoJ2eXsrI2q27deNWt29jXq3BwL8PB66hbN05du16sr756U5s2rVJ8fJLCwiKUm7tHv/++UbGxDdWqVSclJ1+p9et/0m+//eS3vIoe16kTq549r9TGjWu0evVSGWNUVFT631vZLlxYKO3fX/rf5aG9EIc+r2g9B0/n//5KB7c7TD179tO+fblasuQreTwlKi4u7b1wu0v/K/R4DvynWDZfkyZJOvvsFC1b9pUyMtLLLVsq/x92Rf+tHzqu7M9W/fqNde65V2j16iVKT1912Pd2qIPXf+hQ+p+u5duPDt6f9u8vbe+wMP8eh4qGst6ewsJ8ZWevV1JSO3Xvfr2WL/9ae/bsqHAblfaChevMM/vJsnK1Zs3X2rfPI2Pk+2+5dPlunXFGHwUFFWrDhkVKSjpfHo9X//vf58rNLVHDhklKTu6tFSu+1o4dG3w9JEVFpT1+xkiNGjXXOedcqp9/XqCtW9MOu9+U9WKVlJQoK2uDiosLVL9+S4WFRfra50Cblc4UG9tAPXteodWrV2jt2hWKiChdVklJ6f5SUnLgsXSgjQ/dR470+NDfy6OdJiwsXBdeeJlycvbou+++lsdTUsmyjBITW+n88y/WN9+kavv2zb5pGjZMUuvWF2rlyrnKykpXSEhpz7nXK0VGhuiMMy5WcLBby5d/poKCQtWt21xnnHGpNm36RhkZa2WMS2eeeYHq1InVt99+on37Cnztc+indGnvW5DOOutcNWjQRF999bHy8/PK7cNut397ezxSXl62MjJ+U1RUfdWv30JRUUHKytqo3bt3KTa2tc444yJ1736BwsIs/fLLN/rf/76XyyUlJJyh+PhO+vnnD7V37y7f73/ZdgsKOtALGRUlNW4cpVGj7lAgEW4O40QMN9OmvaFbbrlBUkcNGvSSfvvtH1q7doUKCnLl9eb5TRsUFK2YmHaqW7eRYmNjFRMTo7p1Y1SvXowaNoxVgwYxatgwRo0axSg+PlaxsZEKC3MrNDTUN7hcLr+ufwAATnRH8/nNOTcngLffTpUkRUdfprff7iGX6xNJpecsLFv2s7Zv362EhCZq2bKJoqOjCSYAABwG4cZmxhh9//2XkqQLLkjxdXNLUlBQkM466wybKgMA4OTEpeA2++WXlSoo+F1ShG66qYfd5QAAcNIj3NjE4/HorbfSNHDgPZKkoKBeSklx21wVAAAnPw5L2WD27Nm69to/qbCw7AZJITrzzDsVFmZrWQAAOAI9NzWsqKhII0eO+iPYBCsioqc6dvxREydeYndpAAA4Aj03Nezll1/Wli2bJMWrVavftGJFhKKi7K4KAADnoOemBhUXF+uRRx7/49kYvfEGwQYAgEAj3NSghQsXaufO7ZLq6+qr/6xzzrG7IgAAnIdwU4Nef/1DSZJl9dM//8mVUQAAVAfCTQ0xxui//y0NN+3bX6lTTrG5IAAAHIpwU0N++eUX7d69SVKYhgzpbXc5AAA4FuGmhrz99vt/POqtAQMiba0FAAAnI9zUgJycHE2Z8qIkqUGDP6ldO5sLAgDAwQg3NeC++15UXt4eSafq//7vavGl3gAAVB9u4leNPv98rv70pzu1a9dqSVKzZg/qoYdcR5gLAAAcD8JNNfn111/Vv/8AFRbmSJKaNLlMK1cOVmysvXUBAOB0HJaqBl6vVwMHDvwj2Jyn0aMztG3bx4qNJUsCAFDd+LStBpmZmVq1atUfz95Xr16NbK0HAIDahJ6balBYWPjHI7ekRkpIsLMaAABqF8JNNfAPNyLcAABQgwg31eDgcFOvnhQdbWs5AADUKoSbalBUVPTHIze9NgAA1DDCTTU4uOcmMdHOSgAAqH0IN9Xg4HBDzw0AADWLcFMNDoSbUHpuAACoYYSbakDPDQAA9iHcVAPOuQEAwD6Em2qQk0PPDQAAdiHcVIO9ew+Em7p1bS0FAIBah3BTDfbtK73PjcvltrkSAABqH8JNNdi3r7TnhnADAEDNI9xUA8INAAD2IdxUg7JwExwcanMlAADUPoSbalBQUBpuQkLouQEAoKYRbqrB/v1lPTeEGwAAahrhphrQcwMAgH0IN9WgsLD0UvDQUMINAAA1jXBTDcoOSxFuAACoeYSbalD23VJuN+EGAICaRripBkVFZT03XAoOAEBNI9xUg7Kem7Awem4AAKhptoebKVOmKCkpSWFhYeratasWLlx42OnfeustderUSREREYqPj9eNN96oXbt21VC1VVNczGEpAADsYmu4mTlzpkaOHKkxY8ZoxYoVOu+889SnTx9t3ry5wum//fZb3XDDDbr55pu1atUqvffee1q6dKn+/Oc/13Dlh1cWbui5AQCg5tkabiZOnKibb75Zf/7zn9WuXTs999xzat68uaZOnVrh9N9//70SExN15513KikpSeeee67+8pe/aNmyZTVc+eGVhZvwcMINAAA1zbZwU1RUpOXLlyslJcVvfEpKihYtWlThPD169NDWrVv16aefyhij33//Xe+//74uu+yyStdTWFionJwcv6G6lZSU3ueGcAMAQM2zLdxkZWXJ4/EoLi7Ob3xcXJx27NhR4Tw9evTQW2+9pcGDBys0NFSNGzdWbGysJk+eXOl6xo8fr5iYGN/QvHnzgL6PitBzAwCAfWw/odiyLL/nxphy48qsXr1ad955px5++GEtX75cn3/+udLT0zV8+PBKl3///fcrOzvbN2zZsiWg9VfE4ykNNxERhBsAAGpasF0rbtCggVwuV7lemszMzHK9OWXGjx+v5ORk3XPPPZKk008/XZGRkTrvvPP0+OOPKz4+vtw8bre7xq9aOhBuuM8NAAA1zbaem9DQUHXt2lWpqal+41NTU9WjR48K59m3b5+CgvxLdrlckkp7fE4UZeEmMpKeGwAAapqth6VGjRqladOm6ZVXXtGaNWt01113afPmzb7DTPfff79uuOEG3/T9+vXT7NmzNXXqVG3YsEHfffed7rzzTp111llq0qSJXW+jHK+XcAMAgF1sOywlSYMHD9auXbs0btw4ZWRkqEOHDvr000+VkJAgScrIyPC7582wYcOUm5urF154QaNHj1ZsbKwuvPBC/fOf/7TrLVSIcAMAgH0scyIdz6kBOTk5iomJUXZ2tqKjowO+fK/X6ztU9s47mbrmmoYBXwcAALXN0Xx+2361lNMUFRX5HtepQ88NAAA1jXATYGVfmikRbgAAsAPhJsD8ww2XggMAUNMINwF2INyEKDy84psRAgCA6kO4CbAD4catGr53IAAAEOEm4PbvPxBuwsJsLQUAgFqJcBNg+/YRbgAAsBPhJsByc8suBSfcAABgB8JNgOXlcc4NAAB2ItwEWFm4sSy3gmhdAABqHB+/AXZwuAEAADWPcBNg+fml4SYoiBv4AQBgB8JNgJWFG5eLnhsAAOxAuAmwskvBCTcAANiDcBNgZeEmOJhwAwCAHQg3AVZQUHqfG8INAAD2INwEWEEBPTcAANiJcBNgZeEmJIRwAwCAHQg3AVb2xZkhIVwKDgCAHQg3AXYg3NBzAwCAHQg3AVZYWBpu3HyxFAAAtiDcBFhBQYEkye0Ot7kSAABqJ8JNgOXn75EkRUbWtbkSAABqJ8JNgO3bt1uSVKdOPZsrAQCgdiLcBNi+faU9N9HR9NwAAGAHwk2A7d9f2nMTFUW4AQDADoSbACssLO254bAUAAD2INwEUHFxsYqLcyVJderQcwMAgB0INwG0d+9e3+OoqFjb6gAAoDYj3ATQnj17/ngUrdDQYFtrAQCgtiLcBNDu3bv/eFRXwWQbAABsQbgJoAM9N/UINwAA2IRwE0AHwg09NwAA2IVwE0AHDkvRcwMAgF0INwFEzw0AAPYj3AQQJxQDAGA/wk0AcUIxAAD2I9wE0MGHpVwuW0sBAKDWItwEECcUAwBgP8JNAHFCMQAA9iPcBBAnFAMAYD/CTQBxQjEAAPYj3ARIQUGB9u/f/8czem4AALAL4SZADvTauCRFE24AALAJ4SZAIiIi9OSTTyo6+kFJFpeCAwBgE8JNgMTGxuq+++5TZOSjkkTPDQAANiHcBFhJSelPwg0AAPYg3ASYx1P6k3ADAIA9CDcBRs8NAAD2ItwEGOEGAAB7EW4CjHADAIC9CDcBRrgBAMBehJsA8npLB0nc5wYAAJsQbgKo7EopiZ4bAADsQrgJIMINAAD2I9wEUNn5NhLhBgAAuxBuAohwAwCA/Qg3AXRwuOGEYgAA7EG4CaCycBMUVDoAAICax0dwAHGPGwAA7Ee4CaCycMMhKQAA7EO4CSB6bgAAsB/hJoDK7nNDuAEAwD6EmwCi5wYAAPsRbgKIcAMAgP1sDzdTpkxRUlKSwsLC1LVrVy1cuPCw0xcWFmrMmDFKSEiQ2+3WKaecoldeeaWGqj08wg0AAPaz9WN45syZGjlypKZMmaLk5GT961//Up8+fbR69Wq1aNGiwnkGDRqk33//XS+//LJatWqlzMxMlRx89zwbEW4AALCfZYwxdq387LPPVpcuXTR16lTfuHbt2ql///4aP358uek///xzXXPNNdqwYYPq1at3TOvMyclRTEyMsrOzFR0dfcy1V+S776Rzz5Vat5bS0gK6aAAAarWj+fy27bBUUVGRli9frpSUFL/xKSkpWrRoUYXzfPTRR+rWrZsmTJigpk2bqk2bNrr77rtVUFBQ6XoKCwuVk5PjN1QX7nMDAID9bDuAkpWVJY/Ho7i4OL/xcXFx2rFjR4XzbNiwQd9++63CwsL0wQcfKCsrSyNGjNDu3bsrPe9m/PjxGjt2bMDrrwiHpQAAsJ/tJxRbluX33BhTblwZr9cry7L01ltv6ayzzlLfvn01ceJETZ8+vdLem/vvv1/Z2dm+YcuWLQF/D2W4zw0AAPaz7WO4QYMGcrlc5XppMjMzy/XmlImPj1fTpk0VExPjG9euXTsZY7R161a1bt263Dxut1tutzuwxVeCnhsAAOxnW89NaGiounbtqtTUVL/xqamp6tGjR4XzJCcna/v27crLy/ONS0tLU1BQkJo1a1at9VYF4QYAAPvZelhq1KhRmjZtml555RWtWbNGd911lzZv3qzhw4dLKj2kdMMNN/imv/baa1W/fn3deOONWr16tb755hvdc889uummmxQeHm7X2/Ah3AAAYD9bP4YHDx6sXbt2ady4ccrIyFCHDh306aefKiEhQZKUkZGhzZs3+6aPiopSamqq7rjjDnXr1k3169fXoEGD9Pjjj9v1FvwQbgAAsJ+t97mxQ3Xe5+btt6XrrpMuukj66quALhoAgFrtpLjPjRPRcwMAgP0INwFEuAEAwH6EmwDiPjcAANiPcBNA9NwAAGA/wk0AEW4AALAf4SaACDcAANiPcBNAhBsAAOxHuAmgsnDjctlbBwAAtRnhJoDouQEAwH6EmwDiUnAAAOxHuAkgem4AALAf4SaACDcAANiPcBNAhBsAAOxHuAkgwg0AAPYj3AQQ4QYAAPsRbgKI+9wAAGA/wk0A0XMDAID9CDcBxH1uAACwH+EmgOi5AQDAfoSbACLcAABgP8JNABFuAACwH+EmgAg3AADYj3ATQIQbAADsR7gJIO5zAwCA/Qg3AUTPDQAA9iPcBBD3uQEAwH7HFG5ee+01ffLJJ77n9957r2JjY9WjRw9t2rQpYMWdbOi5AQDAfscUbp544gmFh4dLkhYvXqwXXnhBEyZMUIMGDXTXXXcFtMCTCeEGAAD7HdPH8JYtW9SqVStJ0pw5czRw4EDdeuutSk5OVq9evQJZ30mFcAMAgP2OqecmKipKu3btkiR9+eWXuvjiiyVJYWFhKigoCFx1JxnCDQAA9jumj+HevXvrz3/+s8444wylpaXpsssukyStWrVKiYmJgazvpMKl4AAA2O+Yem5efPFFde/eXTt37tSsWbNUv359SdLy5cs1ZMiQgBZ4MqHnBgAA+1nGGGN3ETUpJydHMTExys7OVnR0dECX3batlJYmLVwonXtuQBcNAECtdjSf38fUc/P555/r22+/9T1/8cUX1blzZ1177bXas2fPsSzSEei5AQDAfscUbu655x7l5ORIklauXKnRo0erb9++2rBhg0aNGhXQAk8mhBsAAOx3TB/D6enpat++vSRp1qxZuvzyy/XEE0/oxx9/VN++fQNa4MmEcAMAgP2OqecmNDRU+/btkyR99dVXSklJkSTVq1fP16NTGxFuAACw3zF9DJ977rkaNWqUkpOT9cMPP2jmzJmSpLS0NDVr1iygBZ5MCDcAANjvmHpuXnjhBQUHB+v999/X1KlT1bRpU0nSZ599pksvvTSgBZ5MuM8NAAD241LwAIqMlPbtkzZskJKSArpoAABqtaP5/D7mAygej0dz5szRmjVrZFmW2rVrpyuvvFKuWtxt4fGU/uSwFAAA9jmmj+HffvtNffv21bZt29S2bVsZY5SWlqbmzZvrk08+0SmnnBLoOk8KnHMDAID9jumcmzvvvFOnnHKKtmzZoh9//FErVqzQ5s2blZSUpDvvvDPQNZ4UjKHnBgCAE8ExfQwvWLBA33//verVq+cbV79+fT355JNKTk4OWHEnk7JgIxFuAACw0zH13LjdbuXm5pYbn5eXp9DQ0OMu6mRUdkhKItwAAGCnYwo3l19+uW699VYtWbJExhgZY/T9999r+PDhuuKKKwJd40mBcAMAwInhmMLN888/r1NOOUXdu3dXWFiYwsLC1KNHD7Vq1UrPPfdcgEs8ORwcbmrxBWMAANjumPoYYmNj9eGHH+q3337TmjVrZIxR+/bt1apVq0DXd9Kg5wYAgBNDlT+Gj/Rt3/Pnz/c9njhx4jEXdLIqO6HYsqSgY+oPAwAAgVDlcLNixYoqTWdZ1jEXc7I79VS7KwAAAFUON/PmzavOOk56cXHSmjV2VwEAADiAAgAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHMX2cDNlyhQlJSUpLCxMXbt21cKFC6s033fffafg4GB17ty5egsEAAAnFVvDzcyZMzVy5EiNGTNGK1as0Hnnnac+ffpo8+bNh50vOztbN9xwgy666KIaqhQAAJwsLGOMsWvlZ599trp06aKpU6f6xrVr1079+/fX+PHjK53vmmuuUevWreVyuTRnzhz99NNPVV5nTk6OYmJilJ2drejo6OMpHwAA1JCj+fy2reemqKhIy5cvV0pKit/4lJQULVq0qNL5Xn31Va1fv16PPPJIdZcIAABOQsF2rTgrK0sej0dxcXF+4+Pi4rRjx44K51m3bp3+/ve/a+HChQoOrlrphYWFKiws9D3Pyck59qIBAMAJz/YTii3L8ntujCk3TpI8Ho+uvfZajR07Vm3atKny8sePH6+YmBjf0Lx58+OuGQAAnLhsCzcNGjSQy+Uq10uTmZlZrjdHknJzc7Vs2TLdfvvtCg4OVnBwsMaNG6eff/5ZwcHBmjt3boXruf/++5Wdne0btmzZUi3vBwAAnBhsOywVGhqqrl27KjU1VQMGDPCNT01N1ZVXXllu+ujoaK1cudJv3JQpUzR37ly9//77SkpKqnA9brdbbrc7sMUDAIATlm3hRpJGjRql66+/Xt26dVP37t3173//W5s3b9bw4cMllfa6bNu2Ta+//rqCgoLUoUMHv/kbNWqksLCwcuMBAEDtZWu4GTx4sHbt2qVx48YpIyNDHTp00KeffqqEhARJUkZGxhHveQMAAHAwW+9zYwfucwMAwMnnpLjPDQAAQHUg3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3ARI8bbN+t9d1+nr4ZfYXQoAALVasN0FOMWGnE3qGPu2IiOk3P37ZYWF2V0SAAC1Ej03AZLU+iwFeaX8UGnHqiV2lwMAQK1FuAmQ0GC3EgtCJUnrVi+0uRoAAGovwk0AtVI9SdK6zT/ZWwgAALUY4SaAWkc2lySt25VmcyUAANRehJsAat2onSRp3f7tNlcCAEDtRbgJoNZJ3SRJ61x77S0EAIBajHATQK1PO0+S9FuMR95dWTZXAwBA7US4CaDEJqfJ5ZUKQqSMlYvsLgcAgFqJcBNAIa4QJe0PlyStW7vY5moAAKidCDcB1jqogSRp3faVNlcCAEDtRLgJsFPCm0iSNuRusbkSAABqJ8JNgDWLKb3XzbYiTigGAMAOtoebKVOmKCkpSWFhYeratasWLqz8qwtmz56t3r17q2HDhoqOjlb37t31xRdf1GC1R9a0QUtJ0jaTbXMlAADUTraGm5kzZ2rkyJEaM2aMVqxYofPOO099+vTR5s2bK5z+m2++Ue/evfXpp59q+fLluuCCC9SvXz+tWLGihiuvXNP4tpKkbcEFNlcCAEDtZBljjF0rP/vss9WlSxdNnTrVN65du3bq37+/xo8fX6VlnHbaaRo8eLAefvjhKk2fk5OjmJgYZWdnKzo6+pjqPpy0DUvV9o2zFFUo5T60TwoPD/g6AACobY7m89u2npuioiItX75cKSkpfuNTUlK0aFHV7hHj9XqVm5urevXqVTpNYWGhcnJy/Ibq1KTpqZKkPLeUs3Ftta4LAACUZ1u4ycrKksfjUVxcnN/4uLg47dixo0rLeOaZZ5Sfn69BgwZVOs348eMVExPjG5o3b35cdR9JlLuOootKm3Xbxl+qdV0AAKA8208otizL77kxpty4irzzzjt69NFHNXPmTDVq1KjS6e6//35lZ2f7hi1bqv8S7abFYZKkbdvpuQEAoKYF27XiBg0ayOVyleulyczMLNebc6iZM2fq5ptv1nvvvaeLL774sNO63W653e7jrvdoNFUdrdE+bdu5vkbXCwAAbOy5CQ0NVdeuXZWamuo3PjU1VT169Kh0vnfeeUfDhg3T22+/rcsuu6y6yzwmTUNL71K8LXurzZUAAFD72NZzI0mjRo3S9ddfr27duql79+7697//rc2bN2v48OGSSg8pbdu2Ta+//rqk0mBzww03aNKkSTrnnHN8vT7h4eGKiYmx7X0cqmlUvFS4Stv2Ve3cIQAAEDi2hpvBgwdr165dGjdunDIyMtShQwd9+umnSkhIkCRlZGT43fPmX//6l0pKSnTbbbfptttu840fOnSopk+fXtPlV6ppbAvpd2lbyR67SwEAoNax9T43dqju+9xI0ocfPKn+v9yvblmhWjq5sFrWAQBAbXJS3OfGyZo2by9J2uYukmpXdgQAwHaEm2rQNOl0SdLvkVLJzt9trgYAgNqFcFMNGtVtLpdX8gZJO9JX2l0OAAC1CuGmGriCXIrfHyJJ2rb5fzZXAwBA7UK4qSZNvZGSpG071tlcCQAAtQvhppo0DYqVJG3bvdHWOgAAqG0IN9WkaXjp911ty91ucyUAANQuhJtq0jS6mSRpW2GWzZUAAFC7EG6qSdMGSZKkbSbb5koAAKhdCDfVpGl8W0nStuACmysBAKB2IdxUk6aJHSVJ2yI9MoV8BQMAADWFcFNNmrboIEnKD5VyNqfZXA0AALUH4aaaRLqjFFNkSZK2pf9iczUAANQehJtq1LQoTJK0bduvNlcCAEDtQbipRk1V+pXs23aut7kSAABqD8JNNWoaWl+StG3vZpsrAQCg9iDcVKOE6BaSpI1522yuBACA2oNwU41aNm4nSdrg5S7FAADUFMJNNTol8QxJ0vrQfJsrAQCg9iDcVKNT2iVLkrbUMSrK+t3magAAqB0IN9UormGSIoolb5C0adUiu8sBAKBWINxUI8uy1HJ/uCRp/YZlNlcDAEDtQLipZi1VT5K0IWO1zZUAAFA7EG6q2SkRTSVJ6/dusLkSAABqB8JNNTulfitJ0obCHTZXAgBA7UC4qWYtm5Z+O/h6a6+9hQAAUEsQbqrZKa3PliStjyySKSmxuRoAAJyPcFPNEtt1V4hH2hcqbVq50O5yAABwPMJNNQsNDVfH3AhJ0o8rPrW5GgAAnI9wUwO6BDeTJP24+XubKwEAwPkINzWgS4PTJUk/5q6zuRIAAJyPcFMDzmjbU5K0PCRLxhibqwEAwNkINzXg9LP6KcgrZYZ7lPH7b3aXAwCAoxFuakBEkwS12xssSfrxhw9trgYAAGcj3NSQLp5GkqSl6xbYXAkAAM5GuKkh58eUnlT82S6umAIAoDoRbmrIZd1vkCQtdWdpR26GzdUAAOBchJsaEn9Rf5253ZIkffLNNJurAQDAuQg3NSU8XP1KWkqS/vvTuzYXAwCAcxFualC/tldIklIL1yh7f7bN1QAA4EyEmxrU6dJhardT2ufyaNriF+0uBwAARyLc1CCrY0eNXh8nSXru26dU7Cm2uSIAAJyHcFOTLEvXXXqP4vKkrd69envlW3ZXBACA4xBualjYjbdo5I+hkqS7PxmpzPxMmysCAMBZCDc1LTpad7W/WR1/l7JKsnXrR7fIa7x2VwUAgGMQbmzgfvARvf5VHQV7pA/TPtJf/vsXAg4AAAFCuLFDXJw6//05vf6BFOSVpq2Ypn7v9NOOvB12VwYAwEmPcGOXG2/UkFb99eZsyV0ifbruU536wqkaO3+sfs/73e7qAAA4aVnGGGN3ETUpJydHMTExys7OVnR0tL3FFBRIl16q//36jYYOkH6MLx0dZAUpuXmyzm1xrno076FuTbopLjJOlmXZWy8AADY5ms9vwo3dcnOlP/9Z3vfe1fvtpYk9Q7WkUVG5yaJCo9SybkslxCQoPipecVFxahjRUDFhMYp2RyvGHaOYsBhFhEQoPDhc4SHhvp/BQcE2vDEAAAKHcHMYJ1y4kSRjpNdek8aMkbZvV3qsNDdJ+q59lL5LCNK60FwZHftmCg4KVkhQiIKDguUKcpX+tFyVPrdkKcgKkmVZsmTJsv54/sfjo/l58HIkyciool3u4F6psmkPHl/RuIPHHzru4HUeXFOgHVxXQJZ3EtQoSV7j9RskVWmf8BqvjDEyMn6PjTGyLEsuy6UgK8i335TtKwfvN8fzu3Cog/eLQ/elivatiuavjJGRx+tRibdEJd4SeYxHlqzS30dXiIKsozsr4Gi349HsS0e7bI/xyOP1yGM8VVrWobUcOk1FtR5pmorWU7afeI3X9/jg/ats3yobDt2/yvatg+c7+PWyOoKDghUcFFxuGx6u5qN5rWydZbWcjOqG1dXkvpMDukzCzWGckOGmTEGB9NZbpUFn0SLJW/qhUeiSNsZK6+tJW6Kl3+u7taO+W1nRwcoOD1JOqFfZwR5lu4pVYHm0zypRoVX+jw4AADUhPqyhtt8X2Pu4EW4O44QONwfLyZEWL5YWLpRWrpR++03asEHav79Ks3staX+wVBAsFYRIJUGSx/rjZ9DhnxtLMn8so+yxsf54Lv9xVflZthzroD3t4P9TDt4BjVV+fEXjDh5/6DhTyePjdby/KE6qwWWkoD+Gsu1alf2hbPogU7oPHPzYa5UfrIOmKyv94MfHWn9ZvZWNq8p+U5Vt4TJSsFdyeUsfS6W/Y8VBR7ctjna7V/eyy96Py1v573JltRw6TUW1HmmaytZz6P5Str9ZOvC3yGuV/s07eP+S/OeVKt/vvJb/38qq1Hy0rx1cQ9m6TzaRETG69eu9AV3m0Xx+czLGiSo6WrrkktKhjNcr7dkjZWWVDrt2lQ779pX2+uzf7/sZVFCgiP37FVFYKHk8/oPXW37coa8ZUzpIx/czEMuwGzVQAzVQgx01VPf7q87lx8VV37KrgHBzMgkKkurXLx3atrW7GgAATkjc5wYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADgK4QYAADiK7eFmypQpSkpKUlhYmLp27aqFCxcedvoFCxaoa9euCgsLU8uWLfXSSy/VUKUAAOBkYGu4mTlzpkaOHKkxY8ZoxYoVOu+889SnTx9t3ry5wunT09PVt29fnXfeeVqxYoUeeOAB3XnnnZo1a1YNVw4AAE5UljH2fa3q2WefrS5dumjq1Km+ce3atVP//v01fvz4ctPfd999+uijj7RmzRrfuOHDh+vnn3/W4sWLq7TOo/nKdAAAcGI4ms9v23puioqKtHz5cqWkpPiNT0lJ0aJFiyqcZ/HixeWmv+SSS7Rs2TIVFxdXOE9hYaFycnL8BgAA4FzBdq04KytLHo9HcXFxfuPj4uK0Y8eOCufZsWNHhdOXlJQoKytL8fHx5eYZP368xo4dW248IQcAgJNH2ed2VQ442RZuyliW5ffcGFNu3JGmr2h8mfvvv1+jRo3yPd+2bZvat2+v5s2bH2vJAADAJrm5uYqJiTnsNLaFmwYNGsjlcpXrpcnMzCzXO1OmcePGFU4fHBys+vXrVziP2+2W2+32PY+KitKWLVtUp06dw4aoY5GTk6PmzZtry5YtnM9zBLTV0aG9qo62Ojq0V9XRVlVXHW1ljFFubq6aNGlyxGltCzehoaHq2rWrUlNTNWDAAN/41NRUXXnllRXO0717d/33v//1G/fll1+qW7duCgkJqdJ6g4KC1KxZs2MvvAqio6PZ8auItjo6tFfV0VZHh/aqOtqq6gLdVkfqsSlj66Xgo0aN0rRp0/TKK69ozZo1uuuuu7R582YNHz5cUukhpRtuuME3/fDhw7Vp0yaNGjVKa9as0SuvvKKXX35Zd999t11vAQAAnGBsPedm8ODB2rVrl8aNG6eMjAx16NBBn376qRISEiRJGRkZfve8SUpK0qeffqq77rpLL774opo0aaLnn39eV199tV1vAQAAnGBsP6F4xIgRGjFiRIWvTZ8+vdy4nj176scff6zmqo6N2+3WI4884neODypGWx0d2qvqaKujQ3tVHW1VdXa3la038QMAAAg0279bCgAAIJAINwAAwFEINwAAwFEINwAAwFEINwEyZcoUJSUlKSwsTF27dtXChQvtLumE8Oijj8qyLL+hcePGvteNMXr00UfVpEkThYeHq1evXlq1apWNFdecb775Rv369VOTJk1kWZbmzJnj93pV2qawsFB33HGHGjRooMjISF1xxRXaunVrDb6LmnGktho2bFi5/eycc87xm6a2tNX48eN15plnqk6dOmrUqJH69++vtWvX+k3DvnVAVdqL/avU1KlTdfrpp/tuzNe9e3d99tlnvtdPpP2KcBMAM2fO1MiRIzVmzBitWLFC5513nvr06eN3j57a7LTTTlNGRoZvWLlype+1CRMmaOLEiXrhhRe0dOlSNW7cWL1791Zubq6NFdeM/Px8derUSS+88EKFr1elbUaOHKkPPvhAM2bM0Lfffqu8vDxdfvnl8ng8NfU2asSR2kqSLr30Ur/97NNPP/V7vba01YIFC3Tbbbfp+++/V2pqqkpKSpSSkqL8/HzfNOxbB1SlvST2L0lq1qyZnnzySS1btkzLli3ThRdeqCuvvNIXYE6o/crguJ111llm+PDhfuNOPfVU8/e//92mik4cjzzyiOnUqVOFr3m9XtO4cWPz5JNP+sbt37/fxMTEmJdeeqmGKjwxSDIffPCB73lV2mbv3r0mJCTEzJgxwzfNtm3bTFBQkPn8889rrPaadmhbGWPM0KFDzZVXXlnpPLW1rYwxJjMz00gyCxYsMMawbx3Joe1lDPvX4dStW9dMmzbthNuv6Lk5TkVFRVq+fLlSUlL8xqekpGjRokU2VXViWbdunZo0aaKkpCRdc8012rBhgyQpPT1dO3bs8Gs7t9utnj171vq2q0rbLF++XMXFxX7TNGnSRB06dKiV7Td//nw1atRIbdq00S233KLMzEzfa7W5rbKzsyVJ9erVk8S+dSSHtlcZ9i9/Ho9HM2bMUH5+vrp3737C7VeEm+OUlZUlj8dT7pvM4+Liyn2DeW109tln6/XXX9cXX3yh//znP9qxY4d69OihXbt2+dqHtiuvKm2zY8cOhYaGqm7dupVOU1v06dNHb731lubOnatnnnlGS5cu1YUXXqjCwkJJtbetjDEaNWqUzj33XHXo0EES+9bhVNReEvvXwVauXKmoqCi53W4NHz5cH3zwgdq3b3/C7Ve2f/2CU1iW5ffcGFNuXG3Up08f3+OOHTuqe/fuOuWUU/Taa6/5Tsij7Sp3LG1TG9tv8ODBvscdOnRQt27dlJCQoE8++URXXXVVpfM5va1uv/12/fLLL/r222/Lvca+VV5l7cX+dUDbtm31008/ae/evZo1a5aGDh2qBQsW+F4/UfYrem6OU4MGDeRyucqlzszMzHIJFlJkZKQ6duyodevW+a6aou3Kq0rbNG7cWEVFRdqzZ0+l09RW8fHxSkhI0Lp16yTVzra644479NFHH2nevHlq1qyZbzz7VsUqa6+K1Ob9KzQ0VK1atVK3bt00fvx4derUSZMmTTrh9ivCzXEKDQ1V165dlZqa6jc+NTVVPXr0sKmqE1dhYaHWrFmj+Ph4JSUlqXHjxn5tV1RUpAULFtT6tqtK23Tt2lUhISF+02RkZOh///tfrW+/Xbt2acuWLYqPj5dUu9rKGKPbb79ds2fP1ty5c5WUlOT3OvuWvyO1V0Vq8/51KGOMCgsLT7z9KqCnJ9dSM2bMMCEhIebll182q1evNiNHjjSRkZFm48aNdpdmu9GjR5v58+ebDRs2mO+//95cfvnlpk6dOr62efLJJ01MTIyZPXu2WblypRkyZIiJj483OTk5Nlde/XJzc82KFSvMihUrjCQzceJEs2LFCrNp0yZjTNXaZvjw4aZZs2bmq6++Mj/++KO58MILTadOnUxJSYldb6taHK6tcnNzzejRo82iRYtMenq6mTdvnunevbtp2rRprWyrv/71ryYmJsbMnz/fZGRk+IZ9+/b5pmHfOuBI7cX+dcD9999vvvnmG5Oenm5++eUX88ADD5igoCDz5ZdfGmNOrP2KcBMgL774oklISDChoaGmS5cufpcR1maDBw828fHxJiQkxDRp0sRcddVVZtWqVb7XvV6veeSRR0zjxo2N2+02559/vlm5cqWNFdecefPmGUnlhqFDhxpjqtY2BQUF5vbbbzf16tUz4eHh5vLLLzebN2+24d1Ur8O11b59+0xKSopp2LChCQkJMS1atDBDhw4t1w61pa0qaidJ5tVXX/VNw751wJHai/3rgJtuusn3OdewYUNz0UUX+YKNMSfWfmUZY0xg+4IAAADswzk3AADAUQg3AADAUQg3AADAUQg3AADAUQg3AADAUQg3AADAUQg3AADAUQg3AGq9+fPny7Is7d271+5SAAQA4QYAADgK4QYAADgK4QaA7YwxmjBhglq2bKnw8HB16tRJ77//vqQDh4w++eQTderUSWFhYTr77LO1cuVKv2XMmjVLp512mtxutxITE/XMM8/4vV5YWKh7771XzZs3l9vtVuvWrfXyyy/7TbN8+XJ169ZNERER6tGjh9auXVu9bxxAtSDcALDdgw8+qFdffVVTp07VqlWrdNddd+lPf/qTFixY4Jvmnnvu0dNPP62lS5eqUaNGuuKKK1RcXCypNJQMGjRI11xzjVauXKlHH31UDz30kKZPn+6b/4YbbtCMGTP0/PPPa82aNXrppZcUFRXlV8eYMWP0zDPPaNmyZQoODtZNN91UI+8fQGDxxZkAbJWfn68GDRpo7ty56t69u2/8n//8Z+3bt0+33nqrLrjgAs2YMUODBw+WJO3evVvNmjXT9OnTNWjQIF133XXauXOnvvzyS9/89957rz755BOtWrVKaWlpatu2rVJTU3XxxReXq2H+/Pm64IIL9NVXX+miiy6SJH366ae67LLLVFBQoLCwsGpuBQCBRM8NAFutXr1a+/fvV+/evRUVFeUbXn/9da1fv9433cHBp169emrbtq3WrFkjSVqzZo2Sk5P9lpucnKx169bJ4/Hop59+ksvlUs+ePQ9by+mnn+57HB8fL0nKzMw87vcIoGYF210AgNrN6/VKkj755BM1bdrU7zW32+0XcA5lWZak0nN2yh6XObhTOjw8vEq1hISElFt2WX0ATh703ACwVfv27eV2u7V582a1atXKb2jevLlvuu+//973eM+ePUpLS9Opp57qW8a3337rt9xFixapTZs2crlc6tixo7xer985PACci54bALaqU6eO7r77bt11113yer0699xzlZOTo0WLFikqKkoJCQmSpHHjxql+/fqKi4vTmDFj1KBBA/Xv31+SNHr0aJ155pl67LHHNHjwYC1evFgvvPCCpkyZIklKTEzU0KFDddNNN+n5559Xp06dtGnTJmVmZmrQoEF2vXUA1YRwA8B2jz32mBo1aqTx48drw4YNio2NVZcuXfTAAw/4Dgs9+eST+tvf/qZ169apU6dO+uijjxQaGipJ6tKli9599109/PDDeuyxxxQfH69x48Zp2LBhvnVMnTpVDzzwgEaMGKFdu3apRYsWeuCBB+x4uwCqGVdLATihlV3JtGfPHsXGxtpdDoCTAOfcAAAARyHcAAAAR+GwFAAAcBR6bgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKME213Aicrj8ai4uNjuMnAcQkNDFRREfgeA2oZwcwhjjHbs2KG9e/faXQqOU1BQkJKSkhQaGmp3KQCAGmQZY4zdRZxIMjIytHfvXjVq1EgRERGyLMvuknAMvF6vtm/frpCQELVo0YLtCAC1CD03B/F4PL5gU79+fbvLwXFq2LChtm/frpKSEoWEhNhdDgCghnBCwkHKzrGJiIiwuRIEQtnhKI/HY3MlAICaRLipAIcwnIHtCAC1E+EGAAA4CuEG5SQmJuq5554LyLLmz58vy7K4+gwAUGM4odghevXqpc6dOwcklCxdulSRkZHHXxQAADYg3NQSxhh5PB4FBx95kzds2LAGKgIAoHpwWMoBhg0bpgULFmjSpEmyLEuWZWn69OmyLEtffPGFunXrJrfbrYULF2r9+vW68sorFRcXp6ioKJ155pn66quv/JZ36GEpy7I0bdo0DRgwQBEREWrdurU++uijY6531qxZOu200+R2u5WYmKhnnnnG7/UpU6aodevWCgsLU1xcnAYOHOh77f3331fHjh0VHh6u+vXr6+KLL1Z+fv4x1wIAcB56bo7EGGnfPnvWHREhVeGKn0mTJiktLU0dOnTQuHHjJEmrVq2SJN177716+umn1bJlS8XGxmrr1q3q27evHn/8cYWFhem1115Tv379tHbtWrVo0aLSdYwdO1YTJkzQU089pcmTJ+u6667Tpk2bVK9evaN6S8uXL9egQYP06KOPavDgwVq0aJFGjBih+vXra9iwYVq2bJnuvPNOvfHGG+rRo4d2796thQsXSiq9weKQIUM0YcIEDRgwQLm5uVq4cKG4DyUAwI+BT0FBgVm9erUpKCg4MDIvz5jSiFPzQ15elWvv2bOn+dvf/uZ7Pm/ePCPJzJkz54jztm/f3kyePNn3PCEhwTz77LO+55LMgw8+eFCT5BnLssxnn312xGWX1bFnzx5jjDHXXnut6d27t98099xzj2nfvr0xxphZs2aZ6Ohok5OTU25Zy5cvN5LMxo0bj7heYyrZngAAx+OwlMN169bN73l+fr7uvfdetW/fXrGxsYqKitKvv/6qzZs3H3Y5p59+uu9xZGSk6tSpo8zMzKOuZ82aNUpOTvYbl5ycrHXr1snj8ah3795KSEhQy5Ytdf311+utt97Svj96zjp16qSLLrpIHTt21P/93//pP//5j/bs2XPUNQAAnI1wcyQREVJenj1DAO6UfOhVT/fcc49mzZqlf/zjH1q4cKF++ukndezYUUVFRYddzqFfX2BZlrxe71HXY4wpd3M9c9BhpTp16ujHH3/UO++8o/j4eD388MPq1KmT9u7dK5fLpdTUVH322Wdq3769Jk+erLZt2yo9Pf2o6wAAOBfn3ByJZUknwWXRoaGhVfqagYULF2rYsGEaMGCAJCkvL08bN26s5uoOaN++vb799lu/cYsWLVKbNm3kcrkkScHBwbr44ot18cUX65FHHlFsbKzmzp2rq666SpZlKTk5WcnJyXr44YeVkJCgDz74QKNGjaqx9wAAOLERbhwiMTFRS5Ys0caNGxUVFVVpr0qrVq00e/Zs9evXT5Zl6aGHHjqmHphjNXr0aJ155pl67LHHNHjwYC1evFgvvPCCpkyZIkn6+OOPtWHDBp1//vmqW7euPv30U3m9XrVt21ZLlizR119/rZSUFDVq1EhLlizRzp071a5duxqrHwBw4uOwlEPcfffdcrlcat++vRo2bFjpOTTPPvus6tatqx49eqhfv3665JJL1KVLlxqrs0uXLnr33Xc1Y8YMdejQQQ8//LDGjRunYcOGSZJiY2M1e/ZsXXjhhWrXrp1eeuklvfPOOzrttNMUHR2tb775Rn379lWbNm304IMP6plnnlGfPn1qrH4AwInPMgef8FDL7d+/X+np6UpKSlJYWJjd5eA4sT0BoHai5wYAADgK4QbHZfjw4YqKiqpwGD58uN3lAQBqIQ5LHYTDGEcvMzNTOTk5Fb4WHR2tRo0a1XBFB7A9AaB24mopHJdGjRrZGmAAADgUh6UAAICjEG4AAICjEG4AAICjEG4AAICjEG4AAICjEG4AAICjEG4QEBs3bpRlWfrpp5/sLgUAUMsRbhyiV69eGjlyZMCWN2zYMPXv3z9gywMAoKYQbgAAgKMQbo7AGKP8onxbhqp+M8awYcO0YMECTZo0SZZlybIsbdy4UatXr1bfvn0VFRWluLg4XX/99crKyvLN9/7776tjx44KDw9X/fr1dfHFFys/P1+PPvqoXnvtNX344Ye+5c2fP/+o227BggU666yz5Ha7FR8fr7///e8qKSk54volaf78+TrrrLMUGRmp2NhYJScna9OmTUddAwCg9uHrF45gX/E+RY2PsmXdeffnKTI08ojTTZo0SWlpaerQoYPGjRsnSfJ4POrZs6duueUWTZw4UQUFBbrvvvs0aNAgzZ07VxkZGRoyZIgmTJigAQMGKDc3VwsXLpQxRnfffbfWrFmjnJwcvfrqq5KkevXqHVXt27ZtU9++fTVs2DC9/vrr+vXXX3XLLbcoLCxMjz766GHXX1JSov79++uWW27RO++8o6KiIv3www+yLOvoGxEAUOsQbhwgJiZGoaGhioiIUOPGjSVJDz/8sLp06aInnnjCN90rr7yi5s2bKy0tTXl5eSopKdFVV12lhIQESVLHjh1904aHh6uwsNC3vKM1ZcoUNW/eXC+88IIsy9Kpp56q7du367777tPDDz+sjIyMSte/e/duZWdn6/LLL9cpp5wiSWrXrt0x1QEAqH0IN0cQERKhvPvzbFv3sVq+fLnmzZunqKjyvU7r169XSkqKLrroInXs2FGXXHKJUlJSNHDgQNWtW/d4SvZZs2aNunfv7tfbkpycrLy8PG3dulWdOnWqdP316tXTsGHDdMkll6h37966+OKLNWjQIMXHxwekNgCAs3HOzRFYlqXI0EhbhuM5DOP1etWvXz/99NNPfsO6det0/vnny+VyKTU1VZ999pnat2+vyZMnq23btkpPTw9IuxljytVfdg6RZVlHXP+rr76qxYsXq0ePHpo5c6batGmj77//PiC1AQCcjXDjEKGhofJ4PL7nXbp00apVq5SYmKhWrVr5DZGRpefxWJal5ORkjR07VitWrFBoaKg++OCDCpd3tNq3b69Fixb5nRS9aNEi1alTR02bNj3i+iXpjDPO0P33369FixapQ4cOevvtt4+5HgBA7UG4cYjExEQtWbJEGzduVFZWlm677Tbt3r1bQ4YM0Q8//KANGzboyy+/1E033SSPx6MlS5boiSee0LJly7R582bNnj1bO3fu9J3bkpiYqF9++UVr165VVlaWiouLj6qeESNGaMuWLbrjjjv066+/6sMPP9QjjzyiUaNGKSgo6LDrT09P1/3336/Fixdr06ZN+vLLL5WWlsZ5NwCAqjHwKSgoMKtXrzYFBQV2l3LU1q5da8455xwTHh5uJJn09HSTlpZmBgwYYGJjY014eLg59dRTzciRI43X6zWrV682l1xyiWnYsKFxu92mTZs2ZvLkyb7lZWZmmt69e5uoqCgjycybN++w609PTzeSzIoVK3zj5s+fb84880wTGhpqGjdubO677z5TXFxsjDGHXf+OHTtM//79TXx8vAkNDTUJCQnm4YcfNh6P56ja5GTengCAY2cZU8WbqdQC+/fvV3p6upKSkhQWFmZ3OThObE8AqJ04LAUAAByFcIMqeeKJJxQVFVXh0KdPH7vLAwDAh/vcoEqGDx+uQYMGVfhaeHh4DVcDAEDlCDeoknr16h31VzAAAGAHDksBAABHIdwAAABHIdwAAABHIdwAAABHIdwAAABHIdygnMTERD333HN2lwEAwDHhUnCH6NWrlzp37hyQULJ06VLfN4cDAHCyIdzUEsYYeTweBQcfeZM3bNiwBioCAKB6cFjqCIyR8vPtGar6labDhg3TggULNGnSJFmWJcuyNH36dFmWpS+++ELdunWT2+3WwoULtX79el155ZWKi4tTVFSUzjzzTH311Vd+yzv0sJRlWZo2bZoGDBigiIgItW7dWh999FGVavN4PLr55puVlJSk8PBwtW3bVpMmTSo33SuvvKLTTjtNbrdb8fHxuv32232v7d27V7feeqvi4uIUFhamDh066OOPP65a4wAAah16bo5g3z4pKsqedeflSVU5OjRp0iSlpaWpQ4cOGjdunCRp1apVkqR7771XTz/9tFq2bKnY2Fht3bpVffv21eOPP66wsDC99tpr6tevn9auXasWLVpUuo6xY8dqwoQJeuqppzR58mRdd9112rRp0xHvWuz1etWsWTO9++67atCggRYtWqRbb71V8fHxvq9zmDp1qkaNGqUnn3xSffr0UXZ2tr777jvf/H369FFubq7efPNNnXLKKVq9erVcLldVmhAAUBsZ+BQUFJjVq1ebgoIC37i8PGNK+1BqfsjLq3rtPXv2NH/72998z+fNm2ckmTlz5hxx3vbt25vJkyf7nickJJhnn33W91ySefDBBw9qkzxjWZb57LPPql7gQUaMGGGuvvpq3/MmTZqYMWPGVDjtF198YYKCgszatWuPej0VbU8AgPPRc3MEERGlPSh2rft4devWze95fn6+xo4dq48//ljbt29XSUmJCgoKtHnz5sMu5/TTT/c9joyMVJ06dZSZmVmlGl566SVNmzZNmzZtUkFBgYqKitS5c2dJUmZmprZv366LLrqownl/+uknNWvWTG3atKnSugAAINwcgWVV7dDQierQq57uueceffHFF3r66afVqlUrhYeHa+DAgSoqKjrsckJCQvyeW5Ylr9d7xPW/++67uuuuu/TMM8+oe/fuqlOnjp566iktWbJE0pG/UZxvHAcAHC3CjUOEhobK4/EccbqFCxdq2LBhGjBggCQpLy9PGzdurLa6Fi5cqB49emjEiBG+cevXr/c9rlOnjhITE/X111/rggsuKDf/6aefrq1btyotLY3eGwBAlXC1lEMkJiZqyZIl2rhxo7KysirtVWnVqpVmz56tn376ST///LOuvfbaKvXAHKtWrVpp2bJl+uKLL5SWlqaHHnpIS5cu9Zvm0Ucf1TPPPKPnn39e69at048//qjJkydLknr27Knzzz9fV199tVJTU5Wenq7PPvtMn3/+ebXVDAA4uRFuHOLuu++Wy+VS+/bt1bBhw0rPoXn22WdVt25d9ejRQ/369dMll1yiLl26VFtdw4cP11VXXaXBgwfr7LPP1q5du/x6cSRp6NCheu655zRlyhSddtppuvzyy7Vu3Trf67NmzdKZZ56pIUOGqH379rr33nur1EsFAKidLGOqejcV59u/f7/S09OVlJSksLAwu8vBcWJ7AkDtRM8NAABwFMINjsvw4cMVFRVV4TB8+HC7ywMA1EIcljoIhzGOXmZmpnJycip8LTo6Wo0aNarhig5gewJA7cSl4DgujRo1sjXAAABwKA5LAQAARyHcAAAARyHcAAAARyHcAAAARyHcAAAARyHcAAAARyHcOESvXr00cuTIgC1v2LBh6t+/f8CWBwBATSHcAAAARyHcHIExRvn5+bYMVb159LBhw7RgwQJNmjRJlmXJsixt3LhRq1evVt++fRUVFaW4uDhdf/31ysrK8s33/vvvq2PHjgoPD1f9+vV18cUXKz8/X48++qhee+01ffjhh77lzZ8//4h13HfffWrTpo0iIiLUsmVLPfTQQyouLvab5qOPPlK3bt0UFhamBg0a6KqrrvK9VlhYqHvvvVfNmzeX2+1W69at9fLLL1dtQwEA8AfuUHwE+/btU1RUlC3rzsvLU2Rk5BGnmzRpktLS0tShQweNGzdOkuTxeNSzZ0/dcsstmjhxogoKCnTfffdp0KBBmjt3rjIyMjRkyBBNmDBBAwYMUG5urhYuXChjjO6++26tWbNGOTk5evXVVyVJ9erVO2IdderU0fTp09WkSROtXLlSt9xyi+rUqaN7771XkvTJJ5/oqquu0pgxY/TGG2+oqKhIn3zyiW/+G264QYsXL9bzzz+vTp06KT093S+MAQBQFXy31EEq+i6i/Pz8Ez7cSKXn3HTu3FnPPfecJOnhhx/WkiVL9MUXX/im2bp1q5o3b661a9cqLy9PXbt21caNG5WQkFBuecOGDdPevXs1Z86cY67/qaee0syZM7Vs2TJJUo8ePdSyZUu9+eab5aZNS0tT27ZtlZqaqosvvviY13kwvlsKAGonem6OICIiQnl5ebat+1gtX75c8+bNqzCYrV+/XikpKbrooovUsWNHXXLJJUpJSdHAgQNVt27dY17n+++/r+eee06//fab8vLyVFJSoujoaN/rP/30k2655ZYK5/3pp5/kcrnUs2fPY14/AAAS4eaILMuqcu/JicTr9apfv3765z//We61+Ph4uVwupaamatGiRfryyy81efJkjRkzRkuWLFFSUtJRr+/777/XNddco7Fjx+qSSy5RTEyMZsyYoWeeecY3TXh4eKXzH+41AACOBicUO0RoaKg8Ho/veZcuXbRq1SolJiaqVatWfkNZWLMsS8nJyRo7dqxWrFih0NBQffDBBxUu70i+++47JSQkaMyYMerWrZtat26tTZs2+U1z+umn6+uvv65w/o4dO8rr9WrBggVH+9YBAPBDuHGIxMRELVmyRBs3blRWVpZuu+027d69W0OGDNEPP/ygDRs26Msvv9RNN90kj8ejJUuW6IknntCyZcu0efNmzZ49Wzt37lS7du18y/vll1+0du1aZWVllbvq6VCtWrXS5s2bNWPGDK1fv17PP/+8LyiVeeSRR/TOO+/okUce0Zo1a7Ry5UpNmDDBt76hQ4fqpptu0pw5c5Senq758+fr3XffrZ4GAwA4l4FPQUGBWb16tSkoKLC7lKO2du1ac84555jw8HAjyaSnp5u0tDQzYMAAExsba8LDw82pp55qRo4cabxer1m9erW55JJLTMOGDY3b7TZt2rQxkydP9i0vMzPT9O7d20RFRRlJZt68eUes4Z577jH169c3UVFRZvDgwebZZ581MTExftPMmjXLdO7c2YSGhpoGDRqYq666yvdaQUGBueuuu0x8fLwJDQ01rVq1Mq+88soxt8nJvD0BAMeOq6UOwtU1zsL2BIDaicNSAADAUQg3qJInnnhCUVFRFQ59+vSxuzwAAHy4FBxVMnz4cA0aNKjC17iMGwBwIiHcoErq1atXpa9gAADAbhyWqgDnWDsD2xEAaifCzUFCQkIklX5ZJk5+RUVFkiSXy2VzJQCAmsRhqYO4XC7FxsYqMzNTUul3O1mWZXNVOBZer1c7d+5URESEgoPZzQGgNuGv/iEaN24sSb6Ag5NXUFCQWrRoQUAFgFqGm/hVwuPxHPErB3BiCw0NVVAQR14BoLYh3AAAAEfh31oAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAo/w/qer4LqYpxGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_weight1: \n",
      "-0.67399067,0.50909793,0.022662448,0.9193549,0.2166787,-0.2100528,0.5129407,-0.21426986,0.41747746,-0.655299,-1.4519026,1.3726337,1.2068471,1.3610357,1.1309224,1.0691906,1.2752515,-1.24461,1.1794627,-1.3289676,-0.5625085,0.51934004,0.6719403,0.6085034,0.6793117,0.6224293,0.63876945,-0.59538275,0.7378121,-0.52657616,-0.46334982,0.39758855,0.33983263,0.29238543,0.43219027,0.48020673,0.40341502,-0.58985835,0.2685273,-0.41543847,-0.2607696,0.30327103,0.4064742,0.5654712,0.23225951,0.37771717,0.28177357,-0.07804623,0.41614693,-0.38725558,\n",
      "\n",
      "a_bias1: \n",
      "1.9814434,-1.9140483,-2.1854274,-1.9624641,-1.9653329,-2.186319,-1.9529504,1.9731166,-1.9977309,1.9363022,\n",
      "\n",
      "a_weight2: \n",
      "-2.4342096,1.4378068,1.5885017,1.555816,1.2161385,1.5132118,1.4034138,-2.3900192,1.3526103,-2.442052,\n",
      "\n",
      "a_bias2: \n",
      "-1.0171825,"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 300\n",
    "batchs = 128\n",
    "splits = 0.2\n",
    "lr        = 1e-5\n",
    "input_dim = 5\n",
    "opt = Adam(learning_rate=lr,weight_decay=1e-5/128)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"extraFeatures_Geo.csv\", header=None)\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,1,3,5,6,8,9]]## 'MPD','CBF','CUD','OEF','CUC','FLM','PPS','Label','tempRDCost','bestRDCost'\n",
    "Y = XY[:,[7]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "cost=x_train[:,[input_dim,input_dim+1]]\n",
    "x_train=x_train[:,0:input_dim]\n",
    "x_test=x_test[:,0:input_dim]\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train_flatten = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flatten), y=y_train_flatten)\n",
    "class_weights = dict(zip(np.unique(y_train_flatten),class_weights))\n",
    "# cost_max = np.max(cost[:,0])\n",
    "# cost_min = np.min(cost[:,0])\n",
    "# cost_average = np.average(cost[:,0])\n",
    "# sample_weightss = np.array((cost[:,0]-cost_min)/(cost_max-cost_min))\n",
    "# sample_weightss = np.array(cost[:,0]/cost_average)\n",
    "sample_num=np.size(y_train,0)\n",
    "cost_sum=0\n",
    "cost_num=0\n",
    "cost_difference = []\n",
    "for sample in np.concatenate([cost,y_train],axis=1):\n",
    "    cost_difference_value = sample[0]-sample[1]\n",
    "    if (sample[2]==0)&(cost_difference_value!=0):\n",
    "        cost_difference.append(0)\n",
    "    elif (sample[2]==0)&(cost_difference_value==0):\n",
    "        cost_difference.append(1)\n",
    "    elif (sample[2]==1)&(cost_difference_value<=0):\n",
    "        cost_difference.append(0)\n",
    "    else:\n",
    "        cost_difference.append(cost_difference_value)\n",
    "        cost_sum+=cost_difference_value\n",
    "        cost_num+=1\n",
    "sample_weights = np.array(cost_difference)\n",
    "cost_average=cost_sum/cost_num\n",
    "for i in range(sample_num):\n",
    "    if (y_train[i]==1)&(sample_weights[i]!=0):\n",
    "        sample_weights[i]=sample_weights[i]/cost_average\n",
    "    if sample_weights[i]>1:\n",
    "        sample_weights[i]=1\n",
    "    elif sample_weights[i]<0:\n",
    "        sample_weights[i]=0\n",
    "\n",
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights)\n",
    "\n",
    "model.save_weights(r'revision/geo_model_allFeatures_nosamplewight.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])\n",
    "\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('Learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/P_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('revision/geo_model_allFeatures_nosamplewight.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)\n",
    "    \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "a_weight1=model.get_weights()[0]\n",
    "a_bias1=model.get_weights()[1]\n",
    "a_weight2=model.get_weights()[2]\n",
    "a_bias2=model.get_weights()[3]\n",
    "# a_weight3=model.get_weights()[4]\n",
    "# a_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\na_weight1: \")\n",
    "for a in a_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias1: \")\n",
    "for a in a_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_weight2: \")\n",
    "for a in a_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias2: \")\n",
    "for a in a_bias2:\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f92cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
